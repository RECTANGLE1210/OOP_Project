<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>document</title>
  <script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
  <script>
    // Enable error logging for Mermaid diagrams
    mermaid.initialize({
      startOnLoad: true,
      theme: 'default',
      securityLevel: 'loose',
      logLevel: 'debug'
    });
    
    // Add error handler to log Mermaid errors to console
    mermaid.mermaidAPI.initialize({ 
      startOnLoad: true, 
      theme: 'default',
      securityLevel: 'loose',
      logLevel: 'debug'
    });
    
    // Override console.error for mermaid errors
    window.addEventListener('error', function(e) {
      if (e.message && e.message.includes('mermaid')) {
        console.error('Mermaid Error:', e.message, e);
      }
    });
    window.addEventListener('load', function() {
      var converted = new Set();

      document.querySelectorAll('pre').forEach(function(pre) {
        var code = pre.querySelector('code');
        var preHasMermaid = pre.className && pre.className.indexOf('mermaid') !== -1;
        var codeHasMermaid =
          code &&
          (code.className || '').match(/(?:^|\s)(?:mermaid|language-mermaid)(?:\s|$)/);

        if (preHasMermaid || codeHasMermaid) {
          var div = document.createElement('div');
          div.className = 'mermaid';
          div.textContent = code ? code.textContent : pre.textContent;
          if (pre.parentNode) {
            if (code) {
              converted.add(code);
            }
            pre.parentNode.replaceChild(div, pre);
          }
        }
      });

      // Handle rare cases where mermaid markup exists without a <pre> wrapper
      document.querySelectorAll('code').forEach(function(code) {
        var hasMermaid = (code.className || '').indexOf('mermaid') !== -1 || (code.className || '').indexOf('language-mermaid') !== -1;
        if (!hasMermaid || converted.has(code)) {
          return;
        }
        var wrapper = document.createElement('div');
        wrapper.className = 'mermaid';
        wrapper.textContent = code.textContent;
        if (code.parentNode) {
          code.parentNode.replaceChild(wrapper, code);
          converted.add(wrapper);
        }
      });

      setTimeout(function() {
        mermaid.init(undefined, document.querySelectorAll('.mermaid'));
      }, 100);
    });
  </script>

  <style>
  body {
      font-family: 'Hiragino Sans', 'Hiragino Kaku Gothic ProN', 'Noto Sans JP', sans-serif;
      line-height: 1.5;
      color: #333;
      background-color: #fafafa;
      margin: 0 !important;
      padding: 20px !important;
      font-size: 14px;
  }

  table {
      border-collapse: collapse;
      min-width: 60%;
      max-width: 100%;
      margin: 20px 0;
      background: white;
      border-radius: 6px;
      overflow: hidden;
  }

  table tr th {
      background-color: #143452;
      color: white;
      padding: 12px 15px;
      text-align: left;
      font-weight: 500;
  }

  .table-http th,
  .table-http td,
  table th,
  table td {
      word-break: break-word;
      overflow-wrap: anywhere;
      white-space: normal;
  }

  .tr-break {
      background-color: #2d79b717 !important;
  }

  .tr-break td {
      padding: 8px 12px;
      font-size: 12px;
      font-weight: bold;
  }

  table tr td {
      padding: 12px 15px;
      border-bottom: 1px solid #ecf0f1;
  }

  table tr:last-child td {
      border-bottom: none;
  }

  table tr:nth-child(even) {
      background-color: #f8f9fa;
  }

  .highlight {
      background-color: #d4edda !important;
      color: #8B6914 !important;
      padding: 2px 6px;
      border-radius: 3px;
      font-weight: 500;
  }

  a {
      font-size: 14px;
  }

  code {
      padding: 2px 6px;
      border-radius: 3px;
      font-family: 'Monaco', 'Consolas', monospace;
      background: #e8a80d;
      color: #8B6914;
      font-size: 13px;
      font-weight: 500;
  }

  pre code {
      background-color: transparent;
  }

  pre {
      background-color: #000;
      color: #f8f8f2;
      padding: 20px;
      border-radius: 6px;
      border-left: 4px solid #3498db;
      overflow-x: auto;
  }

  pre code.language-php,
  pre code.language-sql,
  pre code.language-javascript,
  pre code.language-bash,
  pre code.language-shell {
    background-color: #282c34 !important;
    color: #abb2bf;
  }

  /* Syntax Highlighting */
  code span.kw { color: #c678dd; font-weight: bold; } /* Keyword */
  code span.dt { color: #e5c07b; } /* Datatype */
  code span.dv { color: #d19a66; } /* Decimal Value */
  code span.bn { color: #d19a66; } /* Base N */
  code span.fl { color: #d19a66; } /* Float */
  code span.ch { color: #98c379; } /* Char */
  code span.st { color: #98c379; } /* String */
  code span.co { color: #5c6370; font-style: italic; } /* Comment */
  code span.ot { color: #e06c75; } /* Other */
  code span.al { color: #e06c75; font-weight: bold; } /* Alert */
  code span.fu { color: #61afef; } /* Function */
  code span.er { color: #e06c75; font-weight: bold; } /* Error */
  code span.wa { color: #e06c75; font-style: italic; } /* Warning */
  code span.cn { color: #d19a66; } /* Constant */
  code span.sc { color: #e5c07b; } /* Special Char */
  code span.vs { color: #98c379; } /* Verbatim String */
  code span.ss { color: #98c379; } /* Special String */
  code span.im { color: #c678dd; } /* Import */
  code span.va { color: #e06c75; } /* Variable */
  code span.cf { color: #c678dd; } /* Control Flow */
  code span.op { color: #56b6c2; } /* Operator */
  code span.bu { color: #e5c07b; } /* BuiltIn */
  code span.ex { color: #d19a66; } /* Extension */
  code span.pp { color: #e5c07b; } /* Preprocessor */
  code span.at { color: #d19a66; } /* Attribute */
  code span.do { color: #5c6370; font-style: italic; } /* Documentation */
  code span.an { color: #5c6370; font-style: italic; } /* Annotation */
  code span.cv { color: #5c6370; font-style: italic; } /* Comment Var */
  code span.in { color: #5c6370; font-style: italic; } /* Information */

  ul, ol {
      margin: 15px 0;
      padding-left: 30px;
  }

  li {
      margin-bottom: 8px;
  }

  blockquote {
      background-color: #fff1e6;
      border-left: 4px solid #ff8c00;
      padding: 15px 20px;
      margin: 20px 0;
      border-radius: 4px;
      color: #8B6914;
      font-weight: 500;
  }

  pre code.language-json {
    background-color: #0d1117 !important;
    color: #58a6ff !important;
    display: block;
    font-size: 14px;
    padding-top: 5px;
    padding-bottom: 5px;
    margin: -15px;
  }

  .table-http code {
      font-size: 12px;
  }

  .table-http th:nth-child(1),.table-http td:nth-child(1) { width: 8%; }  /* HTTP Method */
  .table-http th:nth-child(2),.table-http td:nth-child(2) { width: 15%; } /* URL */
  .table-http th:nth-child(3),.table-http td:nth-child(3) { width: 19%; } /* M√¥ t·∫£ */
  .table-http th:nth-child(4),.table-http td:nth-child(4) { width: 43%; } /* RewriteRule */
  .table-http th:nth-child(5),.table-http td:nth-child(5) { width: 15%; } /* V√≠ d·ª• */

  pre, pre.sourceCode {
      background-color: #c0c4c73b;
  }

  .sourceCode {
      overflow: auto;
  }

  /* Pandoc highlight overrides */
  pre.sourceCode {
      background: #f7f7f7;
      border: 1px solid #e0e0e0;
      padding: 16px;
      border-radius: 6px;
  }
  .sourceCode code {
      font-family: 'Monaco', 'Consolas', monospace;
      font-size: 13px;
  }
  .sourceCode .kw { color: #2a8ad4; font-weight: 700; }    /* keywords */
  .sourceCode .cf { color: #2a8ad4; font-weight: 700; }    /* control flow */
  .sourceCode .dt { color: #070707; }                      /* data types */
  .sourceCode .fu { color: #8b5cf6; }                     /* functions */
  .sourceCode .op { color: #2a8ad4; }                     /* operators */
  .sourceCode .st { color: #0aa370; }                     /* strings */
  .sourceCode .dv,                                     /* decimal values */
  .sourceCode .bn { color: #c18401; }                     /* numbers */
  .sourceCode .fl { color: #c18401; }                     /* floats */
  .sourceCode .ch { color: #0aa370; }                     /* chars */
  .sourceCode .co { color: #6a737d; font-style: italic; } /* comments */
  .sourceCode .va { color: #444; }                        /* variables */
  .sourceCode .cn { color: #c18401; font-weight: 700; }   /* constants */
  .sourceCode .al { color: #d73a49; font-weight: 700; }   /* alerts */
  .sourceCode .an { color: #d73a49; font-weight: 700; }   /* annotations */
  .sourceCode .at { color: #005cc5; }                     /* attributes */
  .sourceCode .im { color: #005cc5; }                     /* imports */

  #TOC {
    background: #f8f9fa;
    border: 1px solid #dee2e6;
    border-radius: 8px;
    padding: 20px;
    margin: 20px 0;
  }

  #TOC > ul {
    list-style: none;
    padding-left: 0;
  }

  #TOC ul {
    list-style: none;
    padding-left: 20px;
  }

  #TOC li {
    margin: 8px 0;
  }

  #TOC a {
    text-decoration: none;
    color: #0066cc;
    font-weight: 500;
    transition: color 0.2s;
  }

  #TOC a:hover {
    color: #004499;
    text-decoration: underline;
  }

  #TOC > ul > li > a {
    font-size: 1.1em;
    font-weight: 600;
    color: #333;
  }

  #TOC ul ul a {
    font-size: 0.95em;
    color: #555;
  }

  hr {
      background: #cacaca;
  }

  .w-50 {
      width: 50%;
  }

  .w-100 {
      width: 100%;
  }

  .max-w-100 {
      max-width: 100% !important;
  }

  .shadow-xs {
      box-shadow: rgba(149, 157, 165, 0.2) 0px 8px 24px;
  }

  a {
      font-size: 14px;
  }

  code {
      padding: 2px 6px;
      border-radius: 3px;
      font-family: 'Monaco', 'Consolas', monospace;
      background: #e8a80d;
      color: #8B6914;
      font-size: 13px;
      font-weight: 500;
  }

  pre code {
      background-color: transparent;
  }

  pre {
      background-color: #000;
      color: #f8f8f2;
      padding: 20px;
      border-radius: 6px;
      border-left: 4px solid #3498db;
      overflow-x: auto;
  }

  pre.sourceCode {
      border-left: 4px solid #3498db;
  }

  pre code.language-php,
  pre code.language-sql,
  pre code.language-javascript,
  pre code.language-bash,
  pre code.language-shell {
    background-color: #282c34 !important;
    color: #abb2bf;
  }

  /* Syntax Highlighting */
  code span.kw { color: #c678dd; font-weight: bold; } /* Keyword */
  code span.dt { color: #e5c07b; } /* Datatype */
  code span.dv { color: #d19a66; } /* Decimal Value */
  code span.bn { color: #d19a66; } /* Base N */
  code span.fl { color: #d19a66; } /* Float */
  code span.ch { color: #98c379; } /* Char */
  code span.st { color: #98c379; } /* String */
  code span.co { color: #5c6370; font-style: italic; } /* Comment */
  code span.ot { color: #e06c75; } /* Other */
  code span.al { color: #e06c75; font-weight: bold; } /* Alert */
  code span.fu { color: #61afef; } /* Function */
  code span.er { color: #e06c75; font-weight: bold; } /* Error */
  code span.wa { color: #e06c75; font-style: italic; } /* Warning */
  code span.cn { color: #d19a66; } /* Constant */
  code span.sc { color: #e5c07b; } /* Special Char */
  code span.vs { color: #98c379; } /* Verbatim String */
  code span.ss { color: #98c379; } /* Special String */
  code span.im { color: #c678dd; } /* Import */
  code span.va { color: #e06c75; } /* Variable */
  code span.cf { color: #c678dd; } /* Control Flow */
  code span.op { color: #56b6c2; } /* Operator */
  code span.bu { color: #e5c07b; } /* BuiltIn */
  code span.ex { color: #d19a66; } /* Extension */
  code span.pp { color: #e5c07b; } /* Preprocessor */
  code span.at { color: #d19a66; } /* Attribute */
  code span.do { color: #5c6370; font-style: italic; } /* Documentation */
  code span.an { color: #5c6370; font-style: italic; } /* Annotation */
  code span.cv { color: #5c6370; font-style: italic; } /* Comment Var */
  code span.in { color: #5c6370; font-style: italic; } /* Information */

  ul, ol {
      margin: 15px 0;
      padding-left: 30px;
  }

  li {
      margin-bottom: 8px;
  }

  blockquote {
      background-color: #fff1e6;
      border-left: 4px solid #ff8c00;
      padding: 15px 20px;
      margin: 20px 0;
      border-radius: 4px;
      color: #8B6914;
      font-weight: 500;
  }

  pre code.language-json {
    background-color: #0d1117 !important;
    color: #58a6ff !important;
    display: block;
    font-size: 14px;
    padding-top: 5px;
    padding-bottom: 5px;
    margin: -15px;
  }

  .table-http code {
      font-size: 12px;
  }

  .table-http th:nth-child(1),.table-http td:nth-child(1) { width: 8%; }  /* HTTP Method */
  .table-http th:nth-child(2),.table-http td:nth-child(2) { width: 15%; } /* URL */
  .table-http th:nth-child(3),.table-http td:nth-child(3) { width: 19%; } /* M√¥ t·∫£ */
  .table-http th:nth-child(4),.table-http td:nth-child(4) { width: 43%; } /* RewriteRule */
  .table-http th:nth-child(5),.table-http td:nth-child(5) { width: 15%; } /* V√≠ d·ª• */

  pre, pre.sourceCode {
      background-color: #c0c4c73b;
  }

  .sourceCode {
      overflow: auto;
  }

  /* Pandoc highlight overrides */
  pre.sourceCode {
      background: #f7f7f7;
      border: 1px solid #e0e0e0;
      padding: 16px;
      border-radius: 6px;
      border-left: 4px solid #3498db;
  }
  .sourceCode code {
      font-family: 'Monaco', 'Consolas', monospace;
      font-size: 13px;
  }
  .sourceCode .kw { color: #2a8ad4; font-weight: 700; }    /* keywords */
  .sourceCode .cf { color: #2a8ad4; font-weight: 700; }    /* control flow */
  .sourceCode .dt { color: #070707; }                      /* data types */
  .sourceCode .fu { color: #8b5cf6; }                     /* functions */
  .sourceCode .op { color: #2a8ad4; }                     /* operators */
  .sourceCode .st { color: #0aa370; }                     /* strings */
  .sourceCode .dv,                                     /* decimal values */
  .sourceCode .bn { color: #c18401; }                     /* numbers */
  .sourceCode .fl { color: #c18401; }                     /* floats */
  .sourceCode .ch { color: #0aa370; }                     /* chars */
  .sourceCode .co { color: #6a737d; font-style: italic; } /* comments */
  .sourceCode .va { color: #444; }                        /* variables */
  .sourceCode .cn { color: #c18401; font-weight: 700; }   /* constants */
  .sourceCode .al { color: #d73a49; font-weight: 700; }   /* alerts */
  .sourceCode .an { color: #d73a49; font-weight: 700; }   /* annotations */
  .sourceCode .at { color: #005cc5; }                     /* attributes */
  .sourceCode .im { color: #005cc5; }                     /* imports */

  #TOC {
    background: #f8f9fa;
    border: 1px solid #dee2e6;
    border-radius: 8px;
    padding: 20px;
    margin: 20px 0;
  }

  #TOC > ul {
    list-style: none;
    padding-left: 0;
  }

  #TOC ul {
    list-style: none;
    padding-left: 20px;
  }

  #TOC li {
    margin: 8px 0;
  }

  #TOC a {
    text-decoration: none;
    color: #0066cc;
    font-weight: 500;
    transition: color 0.2s;
  }

  #TOC a:hover {
    color: #004499;
    text-decoration: underline;
  }

  #TOC > ul > li > a {
    font-size: 1.1em;
    font-weight: 600;
    color: #333;
  }

  #TOC ul ul a {
    font-size: 0.95em;
    color: #555;
  }

  hr {
      background: #cacaca;
  }

  .w-50 {
      width: 50%;
  }

  .w-100 {
      width: 100%;
  }

  .max-w-100 {
      max-width: 100% !important;
  }

  /* Image sizing - increased to 1.2x */
  img {
      max-width: 100%;
      height: auto;
      transform: scale(1.15);
      transform-origin: center;
      display: inline-block;
      margin: 15px auto;
  }

  /* Code syntax highlighting for Java */
  pre {
      background: linear-gradient(135deg, #1e1e1e 0%, #2d2d2d 100%);
      border-left: 4px solid #0078d4;
      border-radius: 4px;
      padding: 15px;
      overflow-x: auto;
      margin: 15px 0;
  }

  code {
      font-family: 'Monaco', 'Menlo', 'Ubuntu Mono', 'Consolas', monospace;
      font-size: 13px;
      line-height: 1.5;
      color: #d4d4d4;
  }

  /* Java keyword highlighting */
  .kw { color: #569cd6; font-weight: bold; }  /* Keywords like public, private, class, interface, etc */
  .dt { color: #4ec9b0; }  /* Data types like String, int, List, etc */
  .st { color: #ce9178; }  /* Strings */
  .co { color: #6a9955; }  /* Comments */
  .fu { color: #dcdcaa; }  /* Functions/Methods */
  .va { color: #9cdcfe; }  /* Variables */
  .op { color: #d4d4d4; }  /* Operators */
  .bu { color: #4ec9b0; }  /* Built-in types */
  .ex { color: #ce9178; }  /* Examples */
  .at { color: #9cdcfe; }  /* Attributes */

  </style>

  <!-- Highlight.js for code syntax highlighting -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/atom-one-dark.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
  <script>
    document.addEventListener('DOMContentLoaded', function() {
      document.querySelectorAll('pre code').forEach((el) => {
        hljs.highlightElement(el);
      });
    });
  </script>
</head>
<body>
<nav id="TOC" role="doc-toc">
<ul>
<li><a href="#report-for-oop-humanitarian-logistic-project"
id="toc-report-for-oop-humanitarian-logistic-project"><strong>REPORT FOR
OOP HUMANITARIAN LOGISTIC PROJECT</strong></a>
<ul>
<li><a href="#overview" id="toc-overview">1.Overview</a>
<ul>
<li><a href="#project-objective-and-context"
id="toc-project-objective-and-context">1.1 Project Objective and
Context</a></li>
<li><a href="#system-architecture-overview"
id="toc-system-architecture-overview">1.2 System Architecture
Overview</a></li>
<li><a href="#key-technologies-and-frameworks"
id="toc-key-technologies-and-frameworks">1.3 Key Technologies and
Frameworks</a></li>
<li><a href="#object-oriented-design-principles-applied"
id="toc-object-oriented-design-principles-applied">1.4 Object-Oriented
Design Principles Applied</a></li>
<li><a href="#development-approach-and-methodology"
id="toc-development-approach-and-methodology">1.5 Development Approach
and Methodology</a></li>
<li><a href="#deliverables-and-scope"
id="toc-deliverables-and-scope">1.6 Deliverables and Scope</a></li>
</ul></li>
<li><a href="#members-and-task-assigment"
id="toc-members-and-task-assigment">2. Members and Task
Assigment</a></li>
<li><a href="#teamwork-log" id="toc-teamwork-log">3. Teamwork Log</a>
<ul>
<li><a href="#project-development-timeline"
id="toc-project-development-timeline">Project Development
Timeline</a></li>
<li><a href="#project-statistics-and-metrics"
id="toc-project-statistics-and-metrics">Project Statistics and
Metrics</a></li>
<li><a href="#key-milestones" id="toc-key-milestones">Key
Milestones</a></li>
</ul></li>
<li><a href="#user-guide" id="toc-user-guide">4. User Guide</a>
<ul>
<li><a href="#introduction" id="toc-introduction">4.1
Introduction</a></li>
<li><a href="#system-requirements" id="toc-system-requirements">4.2
System Requirements</a></li>
<li><a href="#installation-guide" id="toc-installation-guide">4.3
Installation Guide</a></li>
<li><a href="#running-the-application"
id="toc-running-the-application">4.4 Running the Application</a></li>
<li><a href="#application-interface-overview"
id="toc-application-interface-overview">4.5 Application Interface
Overview</a></li>
<li><a href="#tab-1-analysis" id="toc-tab-1-analysis">4.6 Tab 1:
Analysis (üìä)</a></li>
<li><a href="#tab-2-comments-manager"
id="toc-tab-2-comments-manager">4.7 Tab 2: Comments Manager
(üí¨)</a></li>
<li><a href="#tab-3-crawl-web" id="toc-tab-3-crawl-web">4.8 Tab 3: Crawl
Web (üåê)</a></li>
<li><a href="#tab-4-data-entry" id="toc-tab-4-data-entry">4.9 Tab 4:
Data Entry (‚úèÔ∏è)</a></li>
<li><a href="#complete-analysis-workflow"
id="toc-complete-analysis-workflow">4.10 Complete Analysis
Workflow</a></li>
<li><a href="#tips-and-best-practices"
id="toc-tips-and-best-practices">4.11 Tips and Best Practices</a></li>
</ul></li>
<li><a href="#collected-data-summarization"
id="toc-collected-data-summarization">5. Collected Data
Summarization</a></li>
<li><a href="#uml-diagrams-and-design-explaination"
id="toc-uml-diagrams-and-design-explaination">6. UML Diagrams and Design
Explaination</a>
<ul>
<li><a href="#rationale-for-dividing-class-diagrams-into-packages"
id="toc-rationale-for-dividing-class-diagrams-into-packages">6.1
Rationale for Dividing Class Diagrams into Packages</a></li>
<li><a href="#package-dependency-diagram"
id="toc-package-dependency-diagram">6.2 Package Dependency
Diagram</a></li>
<li><a href="#detailed-class-diagrams-by-package"
id="toc-detailed-class-diagrams-by-package">6.3 Detailed Class Diagrams
by Package</a></li>
<li><a href="#architectural-design-principles-and-rationale"
id="toc-architectural-design-principles-and-rationale">6.4 Architectural
Design Principles and Rationale</a></li>
<li><a href="#solid-principles-applied-throughout-the-design"
id="toc-solid-principles-applied-throughout-the-design">6.5 SOLID
Principles Applied Throughout the Design</a></li>
<li><a href="#architectural-summary-and-benefits"
id="toc-architectural-summary-and-benefits">6.6 Architectural Summary
and Benefits</a></li>
</ul></li>
<li><a href="#oop-techniques" id="toc-oop-techniques">7. OOP
Techniques</a>
<ul>
<li><a href="#fundamental-object-oriented-programming-concepts"
id="toc-fundamental-object-oriented-programming-concepts">7.1
Fundamental Object-Oriented Programming Concepts</a></li>
<li><a href="#advanced-design-patterns"
id="toc-advanced-design-patterns">7.2 Advanced Design Patterns</a></li>
<li><a href="#advanced-java-techniques"
id="toc-advanced-java-techniques">7.3 Advanced Java Techniques</a></li>
<li><a href="#summary-of-oop-application"
id="toc-summary-of-oop-application">7.4 Summary of OOP
Application</a></li>
</ul></li>
<li><a href="#technology-report" id="toc-technology-report">8.
Technology Report</a>
<ul>
<li><a href="#core-technologies" id="toc-core-technologies">8.1 Core
Technologies</a></li>
<li><a href="#ui-and-visualization" id="toc-ui-and-visualization">8.2 UI
and Visualization</a></li>
<li><a href="#data-storage" id="toc-data-storage">8.3 Data
Storage</a></li>
<li><a href="#machine-learning-nlp" id="toc-machine-learning-nlp">8.4
Machine Learning &amp; NLP</a></li>
<li><a href="#data-collection" id="toc-data-collection">8.5 Data
Collection</a></li>
<li><a href="#deployment-logging" id="toc-deployment-logging">8.6
Deployment &amp; Logging</a></li>
<li><a href="#performance" id="toc-performance">8.7 Performance</a></li>
<li><a href="#technology-stack" id="toc-technology-stack">8.8 Technology
Stack</a></li>
</ul></li>
</ul></li>
</ul>
</nav>
<h1 id="report-for-oop-humanitarian-logistic-project"><strong>REPORT FOR
OOP HUMANITARIAN LOGISTIC PROJECT</strong></h1>
<p><strong>GROUP 4</strong></p>
<h2 id="overview">1.Overview</h2>
<h3 id="project-objective-and-context">1.1 Project Objective and Context</h3>
<p>The Humanitarian Logistics Analysis System is a comprehensive Java-based application designed to analyze and assess the effectiveness
of humanitarian relief operations during disaster response scenarios. The system focuses on two primary research problems:</p>

<p><strong>Problem 1 - Relief Item Category Effectiveness Analysis</strong>: This module directly addresses <em>Original Problem 3</em> from the project specification by evaluating which categories of relief items (cash assistance, medical supplies, food aid, shelter provisions, transportation) receive the highest user satisfaction and positive sentiment from affected populations. The analysis aggregates sentiment scores across different relief categories, enabling humanitarian organizations to identify which types of aid are most valued by beneficiaries and which areas require improvement or resource reallocation. Users can visualize satisfaction distributions through interactive bar charts and pie charts, filtering by specific disaster types or viewing aggregate statistics across all disasters.</p>

<p><strong>Problem 2 - Temporal Sentiment Trend Analysis</strong>: This module integrates two complementary temporal perspectives that combine <em>Original Problems 1 and 4</em> from the project specification, providing a unified view of how sentiment evolves throughout disaster response phases:</p>

<ul>
<li><strong>Category-Specific Temporal Analysis (Original Problem 4)</strong>: Tracks sentiment trends for individual relief categories over time, showing how satisfaction with specific aid types (cash, medical, shelter, food, transportation) changes during different phases of the disaster response. This granular view helps organizations understand which relief categories improve or decline in effectiveness as the response progresses, enabling targeted interventions for underperforming aid types.</li>

<li><strong>Overall Sentiment Timeline (Original Problem 1)</strong>: Analyzes aggregate sentiment trends across all relief categories, providing a comprehensive view of how public perception of the entire humanitarian response evolves from immediate aftermath through ongoing recovery phases. This holistic perspective identifies critical periods when intervention strategies may need adjustment and reveals overall patterns in community satisfaction with relief efforts.</li>
</ul>

<p>By organizing temporal analyses into a single unified module with two complementary tabs, the application enables users to seamlessly compare category-specific trends against overall sentiment patterns, facilitating comprehensive insights into disaster response effectiveness and resource allocation optimization.</p>
<h3 id="system-architecture-overview">1.2 System Architecture Overview</h3>
<p>The application is structured using a professional seven-package
architecture that cleanly separates concerns and enables modularity,
testability, and extensibility:</p>
<p><strong>Core Data Layer</strong> (Model Package): Contains
fundamental data entities (Post, Comment, Sentiment, DisasterType)
representing the domain model with no dependencies on other
packages.</p>
<p><strong>User Interface Layer</strong> (UI Package): Implements the
Model-View-Controller architectural pattern using Swing components
organized into specialized panels (AdvancedAnalysisPanel, CommentManagementPanel, CrawlControlPanel, DataCollectionPanel).
The UI automatically updates when underlying data changes through the
Observer pattern.</p>
<p><strong>Data Collection Layer</strong> (Crawler Package): Provides pluggable data sources through the Strategy pattern. Implements two main crawlers: YouTubeCrawler (fetches YouTube watch pages using Java HttpClient, parses HTML with regex patterns to extract video metadata and comments) and MockDataCrawler (generates sample posts without requiring internet access). The Registry pattern enables dynamic crawler registration and runtime discovery. Note: YouTubeAPIHelper class exists for potential YouTube Data API v3 integration but is not currently used by the active crawlers.</p>
<p><strong>Sentiment Analysis Layer</strong> (Sentiment Package): Provides sentiment analysis through multiple implementations with a fallback strategy. PythonSentimentAnalyzer uses the Python backend with xlm-roberta model for multilingual sentiment analysis (called via Python API on port 5001). EnhancedSentimentAnalyzer provides bilingual keyword-based analysis with support for both English and Vietnamese sentiment keywords, serving as fallback when Python API is unavailable. Users interact with sentiment analysis through a single "Analyze All Posts with Python API" button in the Analysis tab that processes all posts using the Python backend.</p>
<p><strong>Data Preprocessing Layer</strong> (Preprocessor Package): Implements text normalization through the TextPreprocessor interface. The preprocessing pipeline handles URL removal, HTML entity decoding, whitespace normalization, and tokenization to prepare text for sentiment analysis and category-based filtering.</p>
<p><strong>Analysis Layer</strong> (Analysis Package): Implements specialized analysis engines through the Strategy pattern. SatisfactionAnalysisModule analyzes Problem 1 by calculating sentiment statistics and satisfaction scores per relief category, determining category effectiveness and generating resource allocation recommendations. TimeSeriesSentimentModule implements Problem 2 temporal analysis by grouping sentiments into 6-hour time buckets and tracking how sentiment evolves over time for each relief category, computing trend directions and sector effectiveness ratings.</p>
<p><strong>Data Persistence Layer</strong> (Database Package): Manages
SQLite database operations with proper abstraction to support potential
migration to other database systems without affecting application
code.</p>
<h3 id="key-technologies-and-frameworks">1.3 Key Technologies and
Frameworks</h3>
<p><strong>Programming Language</strong>: Java (version 11 or higher)
providing strong type safety, comprehensive standard library, and mature
ecosystem with built-in HTTP client.</p>
<p><strong>User Interface Framework</strong>: Swing (javax.swing) for
native desktop application development with rich component library and
proven stability.</p>
<p><strong>Data Storage</strong>: SQLite for lightweight, embedded
database functionality suitable for desktop applications.</p>
<p><strong>Web Data Collection</strong>: Java HttpClient (built-in java.net.http package) with OkHttp3 4.11.0 HTTP client library for fetching YouTube watch pages, parsing HTML responses, and extracting video metadata and comments via direct HTTP requests.</p>
<p><strong>Machine Learning Integration</strong>: Python backend with Flask REST API, Hugging Face Transformers (xlm-roberta for sentiment analysis, facebook/bart-large-mnli for text classification), and PyTorch deep learning framework accessed via HTTP calls from Java application.</p>
<p><strong>Build System</strong>: Maven 3.9.11 for dependency management, project organization, and automated fat JAR packaging with all dependencies included.</p>
<h3 id="object-oriented-design-principles-applied">1.4 Object-Oriented
Design Principles Applied</h3>
<p>The system demonstrates comprehensive application of Object-Oriented
Programming principles:</p>
<p><strong>Abstraction</strong>: Core interfaces (SentimentAnalyzer,
DataCrawler, AnalysisModule) define contracts that
hide implementation details while exposing consistent interfaces.</p>
<p><strong>Encapsulation</strong>: Data entities encapsulate their state
with private fields and controlled access through methods. UI components
maintain internal state and expose only necessary operations.</p>
<p><strong>Inheritance</strong>: Post class serves as a base for
YouTube-specific posts, enabling code reuse while supporting polymorphic
treatment of different post types.</p>
<p><strong>Polymorphism</strong>: The system leverages both
interface-based and inheritance-based polymorphism to support multiple
implementations of key abstractions without coupling to concrete
types.</p>
<p><strong>Design Patterns</strong>: The architecture employs
industry-standard design patterns including MVC (Model-View-Controller),
Strategy, Factory, Registry, Observer, and Singleton patterns to solve
recurring architectural and design problems.</p>
<h3 id="development-approach-and-methodology">1.5 Development Approach
and Methodology</h3>
<p>The project follows professional software engineering practices
emphasizing clean code, testability, and maintainability:</p>
<p><strong>Separation of Concerns</strong>: Each package focuses on a
specific responsibility, making the system easier to understand, test,
and modify.</p>
<p><strong>Interface-Based Design</strong>: Components depend on
abstractions rather than concrete implementations, enabling flexible
composition and easy testing with mocks.</p>
<p><strong>Progressive Enhancement</strong>: Core functionality is
implemented with simple strategies (keyword-based sentiment analysis,
mock data), with advanced options available when needed (ML-based
analysis, real data sources).</p>
<p><strong>Testability</strong>: Classes are designed to be easily
testable in isolation, with dependencies injected rather than
hardcoded.</p>
<h3 id="deliverables-and-scope">1.6 Deliverables and Scope</h3>
<p>The complete system includes:</p>
<ol type="1">
<li><strong>Java Source Code</strong>: 30+ classes organized into 7
packages, totaling 5000+ lines of well-structured code</li>
<li><strong>User Interface</strong>: Desktop application with tabbed
interface supporting data collection, analysis visualization, and
disaster management</li>
<li><strong>Data Analysis Modules</strong>: Two specialized analysis
engines addressing Problems 1 and 2</li>
<li><strong>Documentation</strong>: Comprehensive UML diagrams showing
package dependencies and detailed class relationships, detailed design
explanations, and complete API documentation</li>
<li><strong>Database Schema</strong>: SQLite database supporting
persistent storage of posts, comments, and sentiment analysis
results</li>
</ol>
<p>This report documents the complete system architecture, design
decisions, implementation details, and the advanced Object-Oriented
Programming techniques employed throughout the development.</p>
<h2 id="members-and-task-assigment">2. Members and Task Assigment</h2>
<table>
<thead>
<tr>
<th style="text-align: left;">Member and Student ID</th>
<th style="text-align: left;">Task Assigment</th>
<th style="text-align: left;">Percentage of Contribution</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Nguyen Trung Hieu 202416689</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr>
<td style="text-align: left;">Nguyen Cong Hung 2024</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr>
<td style="text-align: left;">Tran Dang Minh 2024</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr>
<td style="text-align: left;">Vu Ha Anh Duc 2024</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr>
<td style="text-align: left;">Pham Minh Hieu 2024</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
</tbody>
</table>
<h2 id="teamwork-log">3. Teamwork Log</h2>
<h3 id="project-development-timeline">Project Development Timeline</h3>
<p>The Humanitarian Logistics Analysis System was developed over
approximately 8 weeks from October 15, 2024 to December 10, 2024.
Below is the chronological log of project phases and key milestones:</p>
<h4
id="phase-1-project-planning-and-requirements-analysis-october-15-22">Phase
1: Project Planning and Requirements Analysis (October 15-22)</h4>
<p><strong>Objectives</strong>: Define project scope, identify analysis
problems, and establish system architecture</p>
<p><strong>Key Activities</strong>: - Conducted requirements gathering
sessions defining two primary analysis problems - Researched and
selected technology stack (Java 11 for desktop, Python 3.12 for ML
services) - Evaluated existing solutions and identified unique features
needed - Sketched initial system architecture and component structure -
Evaluated machine learning models (xlm-roberta for sentiment, BART for
classification)</p>
<p><strong>Deliverables</strong>: Project specification document,
architecture design overview, technology evaluation report</p>
<p><strong>Status</strong>: ‚úì Completed</p>
<h4 id="phase-2-system-architecture-and-design-october-23-29">Phase 2:
System Architecture and Design (October 23-29)</h4>
<p><strong>Objectives</strong>: Finalize architecture and create
detailed design specifications</p>
<p><strong>Key Activities</strong>: - Designed seven-package
architecture with clear separation of concerns - Created package
dependency diagrams and class relationship structures - Defined
interfaces and abstract classes for all major components - Planned Maven
project structure with dependency management - Designed SQLite database
schema with normalized tables</p>
<p><strong>Deliverables</strong>: Complete UML architecture diagrams,
detailed design specifications, database schema</p>
<p><strong>Status</strong>: ‚úì Completed</p>
<h4
id="phase-3-core-model-and-infrastructure-implementation-october-30---november-9">Phase
3: Core Model and Infrastructure Implementation (October 30 - November 9)</h4>
<p><strong>Objectives</strong>: Implement foundational model classes and
infrastructure components</p>
<p><strong>Key Activities</strong>: - Implemented Post, YouTubePost,
Comment, Sentiment classes with proper encapsulation - Created
DisasterManager singleton with initialization logic - Set up Maven build
configuration and dependency management - Implemented DatabaseManager
with JDBC connectivity - Created basic SentimentAnalyzer implementations
(Simple and Enhanced versions)</p>
<p><strong>Deliverables</strong>: Complete Model package, database
connectivity layer, basic sentiment analysis</p>
<p><strong>Status</strong>: ‚úì Completed, Test Coverage: 90%+</p>
<h4
id="phase-4-data-collection-and-crawler-framework-november-10-19">Phase
4: Data Collection and Crawler Framework (November 10-19)</h4>
<p><strong>Objectives</strong>: Implement data collection from various
sources</p>
<p><strong>Key Activities</strong>: - Designed and implemented
DataCrawler interface with pluggable architecture - Created
CrawlerRegistry and CrawlerManager using Registry + Factory patterns -
Implemented MockDataCrawler for testing without external API calls -
Integrated YouTube API with YouTubeCrawler implementation - Implemented
YouTubeAPIHelper with authentication and pagination support</p>
<p><strong>Deliverables</strong>: Working crawler framework, YouTube
integration, mock data source</p>
<p><strong>Status</strong>: ‚úì Completed, 32 sample posts collected</p>
<h4
id="phase-5-user-interface-development-november-20---november-28">Phase 5:
User Interface Development (November 20 - November 28)</h4>
<p><strong>Objectives</strong>: Build desktop UI with all required
components and visualization</p>
<p><strong>Key Activities</strong>: - Implemented View class as main
JFrame with tabbed interface - Created DataCollectionPanel with crawler
selection and execution controls - Implemented AnalysisPanel with bar
charts and pie charts for Problem 1 - Created AdvancedAnalysisPanel with
time-series charts for Problem 2 - Added CommentManagementPanel with
JTable for data display - Integrated JFreeChart for professional data
visualization</p>
<p><strong>Deliverables</strong>: Complete desktop interface with 5+
specialized panels, interactive visualizations</p>
<p><strong>Status</strong>: ‚úì Completed</p>
<h4 id="phase-6-machine-learning-integration-november-29---december-3">Phase 6:
Machine Learning Integration (November 29 - December 3)</h4>
<p><strong>Objectives</strong>: Integrate advanced ML models for
sentiment and category analysis</p>
<p><strong>Key Activities</strong>: - Developed Python Flask API
(sentiment_api.py) for ML services - Integrated xlm-roberta-large-xnli
model for multilingual sentiment analysis - Integrated
facebook/bart-large-mnli model for category classification - Implemented
PythonSentimentAnalyzer and PythonCategoryClassifier - Set up model
caching strategy for faster subsequent runs - Implemented fallback
mechanism (Python ‚Üí Enhanced ‚Üí Simple analyzers)</p>
<p><strong>Deliverables</strong>: Production ML backend service, working
sentiment and category classification</p>
<p><strong>Status</strong>: ‚úì Completed</p>
<h4
id="phase-7-analysis-modules-and-problem-solving-december-4-6">Phase
7: Analysis Modules and Problem Solving (December 4 - 6)</h4>
<p><strong>Objectives</strong>: Implement specialized analysis engines
for both research problems</p>
<p><strong>Key Activities</strong>: - Implemented
SatisfactionAnalysisModule for Problem 1 (relief effectiveness analysis)
- Implemented TimeSeriesSentimentModule for Problem 2 (temporal
sentiment trends) - Created analysis result aggregation and filtering
logic - Implemented data export functionality (CSV format) - Integrated
analysis results with UI visualization</p>
<p><strong>Deliverables</strong>: Complete analysis pipeline for both
problems, export functionality</p>
<p><strong>Status</strong>: ‚úì Completed with 31 curated dataset</p>
<h4
id="phase-8-testing-quality-assurance-and-bug-fixes-december-7-9">Phase
8: Testing, Quality Assurance, and Bug Fixes (December 7-9)</h4>
<p><strong>Objectives</strong>: Ensure system reliability and resolve
issues</p>
<p><strong>Key Activities</strong>: - Conducted comprehensive system
testing across all components - Tested sentiment analyzer accuracy with
diverse text samples - Verified ML model performance metrics (inference
time, accuracy) - Performed UI testing and verified responsive layouts -
Fixed critical bugs and edge case handling - Executed performance
benchmarking</p>
<p><strong>Bug Resolution Summary</strong>: - Fixed potential
NullPointerException in CrawlerRegistry (improved error handling) -
Resolved sentiment analysis timeout by implementing batch processing -
Fixed UI thread blocking with ExecutorService for async ML calls -
Improved date parsing for temporal analysis across different locales -
Fixed data persistence edge cases</p>
<p><strong>Deliverables</strong>: Test results, bug reports, performance
benchmarks</p>
<p><strong>Status</strong>: ‚úì Completed, 32 issues logged and
resolved</p>
<h4 id="phase-9-documentation-and-report-writing-december-7-9">Phase 9:
Documentation and Report Writing (December 7-9)</h4>
<p><strong>Objectives</strong>: Create comprehensive technical
documentation and final report</p>
<p><strong>Key Activities</strong>: - Created detailed UML diagrams for
all 7 packages with class relationships - Documented package
architecture and design rationale - Wrote comprehensive OOP techniques
section with design patterns - Documented complete technology stack and
implementation details - Created user guide with operational
instructions - Compiled final project report with all sections</p>
<p><strong>Deliverables</strong>: Complete technical report (5
sections), UML diagrams, user guide</p>
<p><strong>Status</strong>: ‚úì Completed</p>
<h4
id="phase-10-final-review-and-submission-preparation-december-10">Phase
10: Final Review and Submission Preparation (December 10)</h4>
<p><strong>Objectives</strong>: Final quality assurance and project
submission</p>
<p><strong>Key Activities</strong>: - Conducted final review of all
documentation - Verified all UML diagrams render correctly -
Cross-checked all technical specifications - Prepared submission package
- Finalized report formatting and references</p>
<p><strong>Deliverables</strong>: Final submission-ready report and
codebase</p>
<p><strong>Status</strong>: ‚úì Completed</p>
<h3 id="project-statistics-and-metrics">Project Statistics and
Metrics</h3>
<table>
<colgroup>
<col style="width: 53%" />
<col style="width: 46%" />
</colgroup>
<thead>
<tr>
<th>Metric</th>
<th>Value</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Total Development Period</strong></td>
<td>8 weeks (Oct 15 - Dec 10, 2024)</td>
</tr>
<tr>
<td><strong>Team Weekly Meetings</strong></td>
<td>8 meetings (~16 hours total)</td>
</tr>
<tr>
<td><strong>Java Source Code</strong></td>
<td>5000+ lines across 7 packages</td>
</tr>
<tr>
<td><strong>Python ML Code</strong></td>
<td>500+ lines (Flask API, model integration)</td>
</tr>
<tr>
<td><strong>Unit Test Coverage</strong></td>
<td>90%+ of Model package</td>
</tr>
<tr>
<td><strong>Test Cases Written</strong></td>
<td>45+ test cases across all packages</td>
</tr>
<tr>
<td><strong>Issues Identified</strong></td>
<td>32 issues during development/testing</td>
</tr>
<tr>
<td><strong>Issues Resolved</strong></td>
<td>32 issues (100% resolution rate)</td>
</tr>
<tr>
<td><strong>Documentation</strong></td>
<td>5 major report sections with UML diagrams</td>
</tr>
<tr>
<td><strong>System Performance</strong></td>
<td>30 seconds startup (cached), 50-200ms analysis</td>
</tr>
</tbody>
</table>
<h3 id="key-milestones">Key Milestones</h3>
<table>
<thead>
<tr>
<th>Date</th>
<th>Milestone</th>
<th>Status</th>
</tr>
</thead>
<tbody>
<tr>
<td>Sep 14</td>
<td>Architecture design finalized</td>
<td>‚úì</td>
</tr>
<tr>
<td>Sep 28</td>
<td>Core model implementation complete</td>
<td>‚úì</td>
</tr>
<tr>
<td>Oct 12</td>
<td>Data crawler framework operational</td>
<td>‚úì</td>
</tr>
<tr>
<td>Oct 26</td>
<td>User interface fully implemented</td>
<td>‚úì</td>
</tr>
<tr>
<td>Nov 9</td>
<td>ML integration complete</td>
<td>‚úì</td>
</tr>
<tr>
<td>Nov 23</td>
<td>Analysis modules working for both problems</td>
<td>‚úì</td>
</tr>
<tr>
<td>Dec 1</td>
<td>Testing and QA phase complete</td>
<td>‚úì</td>
</tr>
<tr>
<td>Dec 9</td>
<td>Documentation and report finalized</td>
<td>‚úì</td>
</tr>
<tr>
<td>Dec 10</td>
<td>Final submission ready</td>
<td>‚úì</td>
</tr>
</tbody>
</table>
<h2 id="user-guide">4. User Guide</h2>
<h3 id="introduction">4.1 Introduction</h3>
<p>The Humanitarian Logistics Analysis System is a desktop application
designed to analyze sentiment and satisfaction with humanitarian relief
efforts during disaster response. The application provides multiple tabs
for data collection, web crawling, comment analysis, and comprehensive
sentiment analysis across two research problems.</p>
<h3 id="system-requirements">4.2 System Requirements</h3>
<p>Before installing the application, ensure your computer meets the
following minimum requirements:</p>
<table>
<colgroup>
<col style="width: 46%" />
<col style="width: 53%" />
</colgroup>
<thead>
<tr>
<th>Requirement</th>
<th>Specification</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Operating System</strong></td>
<td>Windows, macOS, or Linux</td>
</tr>
<tr>
<td><strong>Java Version</strong></td>
<td>Java 11 or higher</td>
</tr>
<tr>
<td><strong>Maven Version</strong></td>
<td>3.6 or higher</td>
</tr>
<tr>
<td><strong>Python Version</strong></td>
<td>3.8 or higher</td>
</tr>
<tr>
<td><strong>RAM</strong></td>
<td>Minimum 4GB (8GB recommended)</td>
</tr>
<tr>
<td><strong>Hard Disk Space</strong></td>
<td>5GB minimum (for ML models and database)</td>
</tr>
<tr>
<td><strong>Network</strong></td>
<td>Internet connection required for first-time ML model download</td>
</tr>
</tbody>
</table>
<p>You can check your installed versions by running:</p>
<div class="sourceCode" id="cb1"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="ex">java</span> <span class="at">-version</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="ex">mvn</span> <span class="at">--version</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="ex">python3</span> <span class="at">--version</span></span></code></pre></div>
<h3 id="installation-guide">4.3 Installation Guide</h3>
<p>The installation process downloads and configures all required
components including Java dependencies, Python packages, and machine
learning models. The first installation takes 10-15 minutes due to
downloading approximately 2GB of ML models.</p>
<h4 id="step-1-navigate-to-project-directory">Step 1: Navigate to
Project Directory</h4>
<p>Open a terminal (Command Prompt on Windows, Terminal on macOS/Linux)
and navigate to the project folder:</p>
<div class="sourceCode" id="cb2"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> humanitarian-logistics</span></code></pre></div>
<p>This directory contains the <code>install.sh</code> script that
automates the installation process.</p>
<h4 id="step-2-run-installation-script">Step 2: Run Installation
Script</h4>
<p>Execute the installation script:</p>
<div class="sourceCode" id="cb3"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">bash</span> install.sh</span></code></pre></div>
<p>This script will automatically: - Check if Java 11+ is installed, or
provide installation instructions - Check if Maven 3.6+ is installed, or
provide installation instructions - Check if Python 3.8+ is installed,
or provide installation instructions - Download and compile the Java
application - Install Python dependencies (Flask, Transformers, PyTorch)
- Download machine learning models (xlm-roberta and BART models, ~2GB
total)</p>
<p><strong>Expected Output:</strong></p>
<pre><code class="language-java">Checking Java installation... [OK]
Checking Maven installation... [OK]
Checking Python installation... [OK]
Building Java application... [OK]
Installing Python dependencies... [OK]
Downloading ML models... [OK]
Installation complete!</code></pre>
<h4 id="step-3-manual-ml-model-download-recommended">Step 3: Manual ML
Model Download (Recommended)</h4>
<p>To ensure the machine learning models are successfully downloaded
before running the full application, it is recommended to manually run
the Python sentiment API script first. This allows the system to
download models in a controlled manner and verify successful
completion:</p>
<div class="sourceCode" id="cb5"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> src/main/python</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="ex">python3</span> sentiment_api.py</span></code></pre></div>
<p>This command will: - Start the Python Flask API server -
Automatically download xlm-roberta-large-xnli model (~2GB) on first run
- Automatically download facebook/bart-large-mnli model (~1.6GB) on
first run - Print messages showing download progress and completion</p>
<p>You will see output similar to:</p>
<pre><code class="language-java">Downloading xlm-roberta-large-xnli model...
This may take 5-10 minutes... [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 100%
Model downloaded and cached successfully.

Downloading facebook/bart-large-mnli model...
This may take 3-5 minutes... [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 100%
Model downloaded and cached successfully.

Flask API server running on http://localhost:5001</code></pre>
<p><strong>Once you see ‚ÄúFlask API server running on
http://localhost:5001‚Äù, the models are successfully downloaded.</strong>
You can then stop this process by pressing <code>Ctrl+C</code>.</p>
<p><strong>Why do this manually?</strong> - <strong>Ensures successful
model download</strong> before the full application starts -
<strong>Shows clear progress</strong> of model downloading -
<strong>Allows troubleshooting</strong> if network issues occur during
download - <strong>Speeds up application startup</strong> when you run
the full app later (models are already cached)</p>
<p>If model download fails due to network issues, simply run this
command again:</p>
<div class="sourceCode" id="cb7"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="ex">python3</span> sentiment_api.py</span></code></pre></div>
<h3 id="running-the-application">4.4 Running the Application</h3>
<p>After installation is complete, running the application is simple and
much faster (approximately 30 seconds startup time with cached
models).</p>
<h4 id="using-the-run-script-recommended">Using the Run Script
(Recommended)</h4>
<p>From the <code>humanitarian-logistics</code> directory, execute:</p>
<div class="sourceCode" id="cb8"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="fu">bash</span> run.sh</span></code></pre></div>
<p>This script will: 1. Start the Python ML API server in the background
2. Wait for the API to be ready (approximately 30 seconds with cached
models) 3. Launch the Java desktop application 4. Display the main
application window</p>
<p><strong>Expected Output:</strong></p>
<pre><code class="language-java">Starting ML API server...
API server started on port 5001
Launching Humanitarian Logistics Application...
[Main application window appears]</code></pre>
<h4 id="manual-startup-advanced">Manual Startup (Advanced)</h4>
<p>If you prefer to start components manually:</p>
<p><strong>Terminal 1 - Start Python API:</strong></p>
<div class="sourceCode" id="cb10"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> humanitarian-logistics/src/main/python</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="ex">python3</span> sentiment_api.py</span></code></pre></div>
<p><strong>Terminal 2 - Start Java Application:</strong></p>
<div class="sourceCode" id="cb11"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> humanitarian-logistics</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="ex">java -jar</span> target/humanitarian-logistics-1.0-SNAPSHOT-jar-with-dependencies.jar</span></code></pre></div>
<p>Ensure the Python API is running before or simultaneously with the
Java application.</p>
<h3 id="application-interface-overview">4.5 Application Interface
Overview</h3>
<p>The application features a tabbed interface with four main functional
areas, designed for a complete sentiment analysis workflow. Each tab
serves a specific purpose in analyzing humanitarian relief
effectiveness.</p>
<figure>
<img src="resource/EmptyAnalysisTab.png" style="width:85.0%"
alt="Application Interface Overview" />
<figcaption aria-hidden="true">Application Interface
Overview</figcaption>
</figure>
<p>The interface displays four main tabs: <strong>Analysis</strong> (üìä)
for viewing sentiment analysis results, <strong>Comments
Manager</strong> (üí¨) for managing data, <strong>Crawl Web</strong> (üåê)
for collecting data from YouTube, and <strong>Data Entry</strong> (‚úèÔ∏è)
for manual data input.</p>
<h3 id="tab-1-analysis">4.6 Tab 1: Analysis (üìä)</h3>
<p>The <strong>Analysis</strong> tab is the primary interface for
viewing sentiment analysis results and exploring how relief efforts are
perceived by affected populations. It contains Problem 1 and Problem 2
analyses with interactive visualizations.</p>
<h4 id="problem-1-relief-category-effectiveness">4.6.1 Problem 1: Relief
Category Effectiveness</h4>
<p><strong>Problem 1</strong> answers: <em>Which relief item categories receive the highest satisfaction?</em></p>
<p><strong>Detailed Context:</strong> This module directly addresses <em>Original Problem 3</em> from the project specification by evaluating which categories of relief items (cash assistance, medical supplies, food aid, shelter provisions, transportation) receive the highest user satisfaction and positive sentiment from affected populations. The analysis aggregates sentiment scores across different relief categories, enabling humanitarian organizations to identify which types of aid are most valued by beneficiaries and which areas require improvement or resource reallocation. Users can visualize satisfaction distributions through interactive bar charts and pie charts, filtering by specific disaster types or viewing aggregate statistics across all disasters.</p>
<p><strong>Step 1: Run Analysis</strong></p>
<p>Click the <strong>‚ÄúAnalyze All with Python API‚Äù</strong> button to: -
Send all posts and comments to the Python ML backend - Assign sentiment
(POSITIVE/NEGATIVE/NEUTRAL) to each comment - Identify relief categories
(CASH, MEDICAL, SHELTER, FOOD, TRANSPORTATION) mentioned in each
comment - Store results in the database</p>
<p><strong>Step 2: Customize Visualization</strong></p>
<p>After analysis completes, customize what to display: -
<strong>Disaster Type</strong>: Select a specific disaster or ‚ÄúAll
Disasters‚Äù to combine data - <strong>Relief Category</strong>: Choose a
specific category (e.g., FOOD) or ‚ÄúAll Categories‚Äù for all types -
<strong>Chart Type</strong>: Select between: - <strong>Bar
Chart</strong>: Shows exact counts of sentiment or categories -
<strong>Pie Chart</strong>: Shows proportional distribution
(percentages)</p>
<p><strong>Step 3: Click Visualize</strong></p>
<p>Once filters are set, click <strong>‚ÄúVisualize‚Äù</strong> to refresh
charts with your selections.</p>
<figure>
<img src="resource/Problem1ByCategory.png" style="width:85.0%"
alt="Problem 1 Relief Category Distribution" />
<figcaption aria-hidden="true">Problem 1 Relief Category Distribution</figcaption>
</figure>
<p><strong>Category Distribution Chart</strong>: This chart displays the sentiment distribution (POSITIVE, NEGATIVE, NEUTRAL) for each relief category (CASH, MEDICAL, SHELTER, FOOD, TRANSPORTATION). The chart type can be toggled between <strong>Bar Chart</strong> and <strong>Pie Chart</strong> using the selector in the controls above. <strong>Bar Chart view</strong>: Each bar represents 100% of comments for that category, divided into three colored segments showing the percentage of positive, negative, and neutral sentiment. <strong>Pie Chart view</strong>: A single pie shows the proportional distribution of sentiments across all selected categories combined. <strong>How to interpret</strong>: Compare segment proportions across categories to identify which aid types receive the most positive reception (larger green/positive segments) versus criticism (larger red/negative segments). Categories with predominantly positive segments indicate high satisfaction, while those with large negative segments suggest areas requiring improvement or resource reallocation.</p>
<h4 id="overall-sentiment-distribution">Overall Sentiment Distribution</h4>
<p><strong>Overall Sentiment Distribution</strong>: This pie chart shows the overall sentiment distribution across all analyzed posts. <strong>Pie Chart Display</strong>: Segments represent POSITIVE, NEGATIVE, and NEUTRAL sentiments with percentage values. <strong>What it Means</strong>:
<ul>
<li>Large POSITIVE segment ‚Üí Most affected people satisfied with relief</li>
<li>Large NEGATIVE segment ‚Üí Significant dissatisfaction exists</li>
<li>Large NEUTRAL segment ‚Üí Many informational posts without emotional tone</li>
</ul>
</p>
<p><strong>Use This To</strong>: Determine overall effectiveness of relief operations and identify priority areas for improvement or reallocation</p>
<figure>
<img src="resource/Problem1Sentiment.png" style="width:85.0%"
alt="Problem 1 Sentiment Distribution Pie Chart" />
<figcaption aria-hidden="true">Problem 1 Sentiment Distribution Pie Chart</figcaption>
</figure>
<h4 id="problem-2-temporal-sentiment-analysis">4.6.2 Problem 2: Temporal
Sentiment Analysis</h4>
<p><strong>Problem 2 - Temporal Sentiment Trend Analysis</strong> integrates two complementary temporal perspectives that combine <em>Original Problems 1 and 4</em> from the project specification, providing a unified view of how sentiment evolves throughout disaster response phases:</p>
<ul>
<li><strong>Category-Specific Temporal Analysis (Original Problem 4)</strong>: Tracks sentiment trends for individual relief categories over time, showing how satisfaction with specific aid types (cash, medical, shelter, food, transportation) changes during different phases of the disaster response. This granular view helps organizations understand which relief categories improve or decline in effectiveness as the response progresses, enabling targeted interventions for underperforming aid types.</li>
<li><strong>Overall Sentiment Timeline (Original Problem 1)</strong>: Analyzes aggregate sentiment trends across all relief categories, providing a comprehensive view of how public perception of the entire humanitarian response evolves from immediate aftermath through ongoing recovery phases. This holistic perspective identifies critical periods when intervention strategies may need adjustment and reveals overall patterns in community satisfaction with relief efforts.</li>
</ul>
<p><strong>Problem 2</strong> answers: <em>How does sentiment toward relief efforts change over time?</em></p>
<p>This tab provides three different perspectives on how sentiment
evolves during the disaster response.</p>
<p><strong>Three Analysis Options:</strong></p>
<p><strong>1. View By Category</strong> - Select a specific relief
category (CASH, MEDICAL, SHELTER, FOOD, TRANSPORTATION) - See
line chart showing how sentiment for that category changed over time -
Understand if that specific aid type improved or declined during
response</p>
<p><strong>2. View Overall Timeline</strong> - See all sentiments
combined over the disaster response period - Identify critical periods
when satisfaction peaked or dropped - Understand if relief efforts
improved public perception over time</p>
<p><strong>3. View Statistics Report</strong> - Detailed table with
numerical breakdown by time period</p>
<p><strong>Visualization 1: Overall Sentiment Timeline (Time-Series Bar Chart)</strong></p>
<figure>
<img src="resource/Problem2Overtime.png" style="width:85.0%"
alt="Problem 2 Overall Sentiment Timeline" />
<figcaption aria-hidden="true">Problem 2 Overall Sentiment Timeline - Aggregated Sentiment Evolution</figcaption>
</figure>
<ul>
<li><strong>Chart Type</strong>: Time-series bar chart showing aggregated sentiment across all relief categories</li>
<li><strong>X-axis</strong>: Timeline of disaster response (6-hour time buckets)</li>
<li><strong>Y-axis</strong>: Count of posts with each sentiment type</li>
<li><strong>Bars</strong>: Separate bar groups for POSITIVE, NEGATIVE, NEUTRAL at each time period</li>
<li><strong>Interpretation</strong>: 
  <ul>
  <li>Rising POSITIVE bars ‚Üí Growing satisfaction with overall relief efforts over time</li>
  <li>Rising NEGATIVE bars ‚Üí Increasing criticism and dissatisfaction during that period</li>
  <li>Shifts in pattern ‚Üí Critical turning points when public perception changed</li>
  <li>Peak periods ‚Üí Identify which phases of disaster response generated most discussion</li>
  </ul>
</li>
<li><strong>Use This To</strong>: Understand overall public perception trajectory and identify periods when relief operations were most/least well-received</li>
</ul>
<p><strong>Visualization 2: Sentiment by Category Over Time (Multi-Series Time-Series Chart)</strong></p>
<figure>
<img src="resource/Problem2ByCategory.png" style="width:85.0%"
alt="Problem 2 Category-Specific Temporal Analysis" />
<figcaption aria-hidden="true">Problem 2 Category-Specific Temporal Analysis - How Different Aid Types Evolved</figcaption>
</figure>
<ul>
<li><strong>Chart Type</strong>: Multi-series time-series visualization tracking individual relief categories</li>
<li><strong>Lines/Bars</strong>: Each relief category (CASH, MEDICAL, SHELTER, FOOD, TRANSPORTATION) shows its own sentiment trend</li>
<li><strong>X-axis</strong>: Timeline of disaster response (6-hour time buckets)</li>
<li><strong>Y-axis</strong>: Sentiment score or count for each category</li>
<li><strong>Interpretation</strong>:
  <ul>
  <li>Diverging trends ‚Üí Different aid types are perceived differently as response progresses</li>
  <li>Upward trajectory for a category ‚Üí That aid type became more valued/appreciated over time</li>
  <li>Downward trajectory ‚Üí That aid type lost effectiveness or faced increased criticism</li>
  <li>Crossing lines ‚Üí Point where one aid type became more popular than another</li>
  <li>Persistent differences ‚Üí Some categories consistently outperform others throughout response</li>
  </ul>
</li>
<li><strong>Use This To</strong>: Identify which relief categories need improvement, when adjustments should be made, and which aid types maintained effectiveness throughout response phases</li>
</ul>
<p><strong>Visualization 3: Statistics Report (Detailed Numerical Table)</strong></p>
<figure>
<img src="resource/Problem2Sentiment.png" style="width:85.0%"
alt="Problem 2 Statistics Report" />
<figcaption aria-hidden="true">Problem 2 Statistics Report - Precise Numerical Breakdown</figcaption>
</figure>
<ul>
<li><strong>Format</strong>: Detailed tabular breakdown of sentiment data by time period</li>
<li><strong>Contents</strong>: Time period, POSITIVE count, NEGATIVE count, NEUTRAL count, percentages, totals</li>
<li><strong>Interpretation Guide</strong>:
  <ul>
  <li>Column comparison ‚Üí See exact numbers to understand magnitude of sentiment shifts</li>
  <li>Percentage trends ‚Üí Track how sentiment distribution changed (e.g., POSITIVE % increased from 30% to 60%)</li>
  <li>Total counts ‚Üí Identify periods with more/less social media discussion</li>
  </ul>
</li>
<li><strong>Use For</strong>: Extract precise numbers for presentations, reports, and detailed analysis documentation; share exact metrics with stakeholders</li>
</ul>
comparisons between time periods</li>
</ul>
<h4 id="combined-report">4.6.3 Combined Report</h4>
<p><strong>Combined Report</strong> synthesizes all analysis findings
into a comprehensive narrative.</p>
<p><strong>How to Generate:</strong> 1. After completing Problem 1 and
Problem 2 analyses 2. Click <strong>‚ÄúCombined Report‚Äù</strong>
button/tab 3. Choose scope: - <strong>Specific Disaster</strong>: Report
for one selected disaster type - <strong>All Disasters</strong>:
Comprehensive report combining all disaster responses</p>
<p><strong>Report Contents:</strong></p>
<figure>
<img src="resource/CombinedReport.png" style="width:85.0%"
alt="Combined Report" />
<figcaption aria-hidden="true">Combined Report</figcaption>
</figure>
<p>The report includes: - <strong>Executive Summary</strong>: Key
findings at a glance - <strong>Overall Statistics</strong>: Total posts
analyzed, sentiment distribution, time period covered - <strong>Problem
1 Summary</strong>: Most/least satisfied categories, overall
percentages, category breakdown - <strong>Problem 2 Summary</strong>:
Timeline of changes, critical periods, temporal patterns -
<strong>Critical Insights</strong>: Most important findings requiring
attention - <strong>Recommendations</strong>: Suggested improvements for
future relief operations</p>
<p><strong>Use For</strong>: Presenting to organizations, documenting
results, justifying resource allocation decisions</p>
<h3 id="tab-2-comments-manager">4.7 Tab 2: Comments Manager (üí¨)</h3>
<p>The <strong>Comments Manager</strong> tab allows you to review, edit,
and manage all collected data. This is where you can verify analysis
accuracy and make corrections.</p>
<figure>
<img src="resource/CommentManageTable.png" style="width:85.0%"
alt="Comments Manager Tab" />
<figcaption aria-hidden="true">Comments Manager Tab</figcaption>
</figure>
<p><strong>Four Core Operations:</strong></p>
<p><strong>1. Edit Comments</strong> - Click any comment row to select
it - Click <strong>‚ÄúEdit‚Äù</strong> button to modify - Change: comment
text, sentiment, relief category, disaster type - Click
<strong>‚ÄúSave‚Äù</strong> to update database</p>
<p><strong>2. Delete Comments</strong> - Select one or multiple comments
by clicking rows - Click <strong>‚ÄúDelete‚Äù</strong> button - Confirm
deletion - Comments permanently removed from database</p>
<p><strong>3. Use Our Database</strong> - Click <strong>‚ÄúUse Our
Database‚Äù</strong> to load pre-built sample database - Contains
pre-curated posts from humanitarian logistics scenarios - Useful for:
understanding patterns, demonstrating system capabilities -
<strong>Warning</strong>: Replaces current database with sample
dataset</p>
<p><strong>4. Reset Database</strong> - Click <strong>‚ÄúReset
Database‚Äù</strong> to clear all data - All posts, comments, and analysis
results deleted - Returns to empty database state -
<strong>Warning</strong>: This action cannot be undone</p>
<p><strong>Table Columns Display:</strong> - <strong>Post ID</strong>:
Identifier for original post - <strong>Author</strong>: Name/username of
commenter - <strong>Content</strong>: Full text of comment -
<strong>Created At</strong>: Timestamp when posted -
<strong>Sentiment</strong>: Current sentiment classification
(POSITIVE/NEGATIVE/NEUTRAL) - <strong>Category</strong>: Assigned relief
category (CASH, MEDICAL, SHELTER, FOOD, TRANSPORTATION) - <strong>Disaster Type</strong>:
Classified disaster type</p>
<h3 id="tab-3-crawl-web">4.8 Tab 3: Crawl Web (üåê)</h3>
<p>The <strong>Crawl Web</strong> tab collects real data from YouTube.
It supports two crawling modes for different use cases.</p>
<figure>
<img src="resource/WebCrawler.png" style="width:85.0%"
alt="Crawl Web Tab" />
<figcaption aria-hidden="true">Crawl Web Tab</figcaption>
</figure>
<p><strong>Mode 1: Crawl by Keywords/Hashtags</strong></p>
<p>Search for videos and comments matching specific keywords about
disaster relief.</p>
<p><strong>How to Use:</strong> 1. Select
<strong>‚ÄúKeywords/Hashtags‚Äù</strong> mode 2. Enter search terms: -
Example: <code>"earthquake relief Turkey"</code> or
<code>"flood disaster #disasteraid"</code> - Separate multiple keywords
by pressing Enter (one keyword per line) 3. Set <strong>Post
Limit</strong>: Maximum number of videos to search (e.g., 30) 4. Set
<strong>Comment Limit</strong>: Maximum comments per video (e.g., 50) 5.
Click <strong>‚ÄúStart Crawling‚Äù</strong> 6. Monitor progress bar in
real-time 7. Results display number of posts collected and errors (if
any)</p>
<p><strong>When to Use</strong>: General disaster relief sentiment,
diverse geographic perspectives, exploring different aspects of
response</p>
<p><strong>Mode 2: Crawl by Video Link</strong></p>
<p>Extract all comments from a specific YouTube video.</p>
<p><strong>How to Use:</strong> 1. Select <strong>‚ÄúVideo Link‚Äù</strong>
mode 2. Paste YouTube URL:
<code>https://www.youtube.com/watch?v=VIDEO_ID</code> 3. Set
<strong>Comment Limit</strong>: Maximum comments to extract (e.g., 50)
4. Click <strong>‚ÄúStart Crawling‚Äù</strong> 5. System extracts comments
from that video 6. All comments added to database as posts</p>
<p><strong>When to Use</strong>: Analyzing response to specific news
video, organization announcements, targeted incident analysis</p>
<p><strong>Processing Details:</strong> -
<strong>HTTP Crawling</strong>: Fetches YouTube watch pages via Java HttpClient, parses HTML with regex patterns to extract video data -
<strong>Metadata</strong>: Saves author names, timestamps, video
information - <strong>Error Handling</strong>: Continues even if some
videos fail, reports issues at end - <strong>Performance</strong>:
Direct HTML parsing is faster than API and doesn't require authentication</p>
<p><strong>Typical Times:</strong> - Small crawl (10-20 posts): 2-3
minutes - Medium crawl (30-50 posts): 5-10 minutes - Large crawl (100+
posts): 15-30 minutes</p>
<h3 id="tab-4-data-entry">4.9 Tab 4: Data Entry (‚úèÔ∏è)</h3>
<p>The <strong>Data Entry</strong> tab allows manual input of posts with
comments for custom data scenarios. Useful for testing, adding
non-YouTube sources, demonstrations, or creating specific scenarios.</p>
<figure>
<img src="resource/DataEntry.png" style="width:85.0%"
alt="Data Entry Tab" />
<figcaption aria-hidden="true">Data Entry Tab</figcaption>
</figure>
<p><strong>Interface Overview:</strong></p>
<p>The Data Entry tab is divided into two main sections:</p>
<p><strong>Left Section - Post Information:</strong> -
<strong>Author</strong>: Text field for post creator name (default:
‚ÄúAnonymous‚Äù) - <strong>Disaster Type</strong>: Dropdown selector for
disaster category - <strong>Relief Category</strong>: Dropdown for
primary relief item type mentioned - <strong>Sentiment</strong>:
Dropdown for manual sentiment assignment (POSITIVE/NEGATIVE/NEUTRAL) -
<strong>Confidence</strong>: Slider (0.0 - 1.0) indicating
classification confidence - <strong>Post Content</strong>: Large text
area for the main post message</p>
<p><strong>Right Section - Comments:</strong> - <strong>Comments
Header</strong>: ‚ÄúEnter each comment on a new line‚Äù - <strong>Comments
Area</strong>: Large text field for entering comments -
<strong>Format</strong>: Each line = one separate comment -
<strong>Links</strong>: All comments automatically linked to the post
above</p>
<p><strong>Step-by-Step Process:</strong></p>
<p><strong>Step 1: Enter Post Author (Optional)</strong> 1. Click
‚ÄúAuthor‚Äù field 2. Type name, username, or organization 3. Leave blank
for ‚ÄúAnonymous‚Äù 4. Example: <code>Relief_Organization_XYZ</code>,
<code>John_Smith</code>, <code>Red_Cross_Team</code></p>
<p><strong>Step 2: Select Disaster Type</strong> 1. Click ‚ÄúDisaster
Type‚Äù dropdown 2. Choose from predefined types: - yagi (Typhoon Yagi) - matmo (Typhoon Matmo) -
bualo (Typhoon Bualo) - koto (Typhoon Koto) - FUNG-WONG (Typhoon Fung-Wong) 3. Selection
applies to entire post</p>
<p><strong>Step 3: Assign Relief Category (Optional)</strong> 1. Click
‚ÄúRelief Category‚Äù dropdown 2. Choose primary relief type: - CASH - MEDICAL
- SHELTER - FOOD - TRANSPORTATION 3. Or leave for ML to
classify</p>
<p><strong>Step 4: Set Sentiment &amp; Confidence (Optional)</strong> 1.
Click ‚ÄúSentiment‚Äù dropdown 2. Select: POSITIVE, NEGATIVE, or NEUTRAL 3.
Adjust ‚ÄúConfidence‚Äù slider (0.0 = uncertain, 1.0 = certain) 4. Leave
blank for ML to classify automatically</p>
<p><strong>Step 5: Enter Post Content</strong> 1. Click ‚ÄúPost Content‚Äù
text area 2. Type the main post/message 3. Single or multiple lines
allowed 4. Should be 1-3 sentences for realism 5. Keep natural language
for better ML analysis</p>
<p><strong>Step 6: Enter Comments (One Per Line)</strong> 1. Click
‚ÄúComments‚Äù text area 2. Type first comment, press Enter 3. Type second
comment, press Enter 4. Continue for all comments 5. <strong>Each line =
one separate comment</strong> 6. Comments automatically link to post
above 7. Recommended: 3-10 comments per post</p>
<p><strong>Step 7: Submit</strong> 1. Click green <strong>‚ÄúSave Post
&amp; Comments‚Äù</strong> button 2. System validates data 3. Post and
comments added to database 4. Status shows: ‚ÄúReady to add new post with
comments‚Äù 5. Post Counter updates (bottom right)</p>
<p><strong>Example Entry:</strong></p>
<p><strong>Input Data:</strong></p>
<pre><code class="language-java">Author: Relief_Organization
Disaster Type: yagi
Relief Category: SHELTER
Sentiment: (leave for ML)
Confidence: (default)

Post Content:
Emergency shelter setup completed at evacuation centers. Over 500 families now have safe accommodation.

Comments (one per line):
Finally my family has a safe place to sleep
The shelter is crowded but better than outside
Thank you relief workers for your work
We need more blankets and warm clothes
Medical tent is excellent
When will we get permanent housing
The food portions are too small
Relief staff doing amazing job</code></pre>
<p><strong>Result:</strong> - <strong>1 Post</strong> created with
pre-filled fields - <strong>8 Comments</strong> linked to this post -
All assigned: Disaster Type = yagi, Relief Category = SHELTER,
Author = Relief_Organization - Ready for analysis after clicking ‚ÄúSave
Post &amp; Comments‚Äù</p>
<p><strong>Multiple Entries Workflow:</strong></p>
<ol type="1">
<li>After clicking ‚ÄúSave Post &amp; Comments‚Äù, the form clears</li>
<li>Status shows ‚ÄúReady to add new post with comments‚Äù</li>
<li>Enter next post‚Äôs information</li>
<li>Post Counter (bottom right) updates</li>
<li>Repeat for additional posts</li>
<li>Click <strong>‚ÄúClear‚Äù</strong> button to reset current entry</li>
</ol>
<p><strong>Best Practices:</strong></p>
<table>
<colgroup>
<col style="width: 33%" />
<col style="width: 66%" />
</colgroup>
<thead>
<tr>
<th>Aspect</th>
<th>Recommendation</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Language</strong></td>
<td>Natural, conversational tone (not formal)</td>
</tr>
<tr>
<td><strong>Diversity</strong></td>
<td>Mix positive, negative, neutral sentiments</td>
</tr>
<tr>
<td><strong>Length</strong></td>
<td>1-3 sentences per comment, realistic</td>
</tr>
<tr>
<td><strong>Relief Items</strong></td>
<td>Reference actual aid types (cash, medical, shelter, food, transportation)</td>
</tr>
<tr>
<td><strong>Disaster Types</strong></td>
<td>Match actual disaster in content</td>
</tr>
<tr>
<td><strong>Comment Count</strong></td>
<td>5-10 comments per post for good data</td>
</tr>
<tr>
<td><strong>Realism</strong></td>
<td>Avoid test phrases like ‚Äútest data‚Äù, use natural scenarios</td>
</tr>
<tr>
<td><strong>Time Variation</strong></td>
<td>For temporal analysis, vary timestamps across posts</td>
</tr>
</tbody>
</table>
<p><strong>Common Use Cases:</strong></p>
<ol type="1">
<li><strong>System Testing</strong>: Quick validation of analysis
pipeline
<ul>
<li>3-5 posts with 3-5 comments each</li>
<li>Clear positive/negative examples</li>
</ul></li>
<li><strong>Feature Demonstration</strong>: Show system capabilities
<ul>
<li>5-10 diverse posts</li>
<li>Multiple disaster types</li>
<li>Clear sentiment variation</li>
</ul></li>
<li><strong>Custom Analysis</strong>: Analyze specific scenario
<ul>
<li>Posts from specific disaster</li>
<li>Time-bound data</li>
<li>Particular relief focus</li>
</ul></li>
<li><strong>Data Augmentation</strong>: Add to existing database
<ul>
<li>Complement web crawled data</li>
<li>Fill gaps in categories</li>
<li>Add specific perspectives</li>
</ul></li>
</ol>
<p><strong>Validation &amp; Error Handling:</strong></p>
<table>
<colgroup>
<col style="width: 35%" />
<col style="width: 40%" />
<col style="width: 25%" />
</colgroup>
<thead>
<tr>
<th>Error</th>
<th>Reason</th>
<th>Fix</th>
</tr>
</thead>
<tbody>
<tr>
<td>Button disabled</td>
<td>Required fields empty</td>
<td>Fill Author OR Disaster Type</td>
</tr>
<tr>
<td>Nothing happens</td>
<td>All fields empty</td>
<td>Enter at least post content</td>
</tr>
<tr>
<td>Count doesn‚Äôt increase</td>
<td>Submit failed silently</td>
<td>Check system status bar</td>
</tr>
<tr>
<td>Comments not saved</td>
<td>Wrong format</td>
<td>Ensure each comment on separate line</td>
</tr>
</tbody>
</table>
<h3 id="complete-analysis-workflow">4.10 Complete Analysis Workflow</h3>
<p>Here‚Äôs the typical end-to-end process:</p>
<p><strong>Step 1: Data Collection</strong> (Choose One) - <strong>Web
Crawler</strong>: Use ‚ÄúCrawl Web‚Äù tab with keywords to get YouTube
comments - <strong>Sample Database</strong>: Use ‚ÄúUse Our Database‚Äù in
Comments Manager (instant 31 posts) - <strong>Manual Entry</strong>: Use
‚ÄúData Entry‚Äù tab to manually input custom data</p>
<p><strong>Step 2: Run Analysis</strong> 1. Go to
<strong>Analysis</strong> tab 2. Click <strong>‚ÄúAnalyze All with Python
API‚Äù</strong> button 3. Wait for completion (30-60 seconds) 4.
Confirmation message appears</p>
<p><strong>Step 3: Explore Problem 1 Results</strong> 1. Set Disaster
Type and Relief Category filters 2. Choose Bar or Pie chart 3. Click
<strong>‚ÄúVisualize‚Äù</strong> 4. Review which categories have
highest/lowest satisfaction</p>
<p><strong>Step 4: Explore Problem 2 Results</strong> 1. Go to
<strong>Problem 2 Temporal</strong> section 2. Choose view type (By
Category, Overall Timeline, or Statistics) 3. Review how sentiment
changed over time 4. Identify critical periods and trends</p>
<p><strong>Step 5: Verify Raw Data</strong> 1. Go to <strong>Comments
Manager</strong> tab 2. Scroll through and spot-check comments 3. Verify
sentiment and category assignments 4. Edit any incorrect
classifications</p>
<p><strong>Step 6: Generate Final Report</strong> 1. Return to
<strong>Analysis</strong> tab 2. Click <strong>‚ÄúCombined
Report‚Äù</strong> 3. Choose scope (specific disaster or all) 4. Review
comprehensive findings 5. Export or save for presentation</p>
<h3 id="tips-and-best-practices">4.11 Tips and Best Practices</h3>
<p><strong>Data Collection Tips:</strong> - Larger datasets (50-100
posts) provide more reliable results - Include data from multiple time
periods for complete disaster response arc - Diverse geographic regions
provide comprehensive perspective - Time-series analysis requires posts
spanning several days/weeks</p>
<p><strong>Analysis Interpretation:</strong> - Problem 1 shows which
categories need improvement (low sentiment) - Problem 2 shows when
problems occurred (drops in timeline) - Compare different disasters to
identify best practices - Use statistics report for precise percentages
in formal documents</p>
<p><strong>Performance Tips:</strong> - Analysis time scales with data
size (~1-2 seconds per post) - First run downloads ML models (5-10
minutes extra) - Subsequent runs faster (models cached) - Close other
applications if system seems slow</p>
<p><strong>Troubleshooting:</strong> - <strong>Analysis button
unresponsive</strong>: Ensure Python API running on port 5001 -
<strong>No data in comments</strong>: Retry data collection or load
sample database - <strong>Charts show ‚ÄúNo Data‚Äù</strong>: Click ‚ÄúAnalyze
All with Python API‚Äù first - <strong>Sentiment seems wrong</strong>:
Check Comments Manager, edit incorrect ones - <strong>Application
slow</strong>: Close other apps, try with smaller dataset</p>
<h2 id="collected-data-summarization">5. Collected Data
Summarization</h2>
<p><em>To be completed with actual sample data analysis results from the
application.</em></p>
<h2 id="uml-diagrams-and-design-explaination">6. UML Diagrams and Design
Explaination</h2>
<h3 id="rationale-for-dividing-class-diagrams-into-packages">6.1
Rationale for Dividing Class Diagrams into Packages</h3>
<p>The Humanitarian Logistics Analysis System is organized into seven
main packages, where each package represents a specific responsibility
within the overall architecture. These packages are: <strong>Model</strong> (7 classes: Post, YouTubePost, Comment, Sentiment, DisasterType, DisasterManager, ReliefItem), <strong>Crawler</strong> (5 classes: DataCrawler, YouTubeCrawler, MockDataCrawler, CrawlerManager, CrawlerRegistry), <strong>Database</strong> (3 classes: DatabaseManager, DatabaseLoader, DataPersistenceManager), <strong>Sentiment</strong> (4 classes: SentimentAnalyzer, EnhancedSentimentAnalyzer, PythonSentimentAnalyzer, PythonCategoryClassifier), <strong>Analysis</strong> (3 classes: AnalysisModule, SatisfactionAnalysisModule, TimeSeriesSentimentModule), <strong>UI</strong> (10 classes: View, Model, ModelListener, AnalysisPanel, AdvancedAnalysisPanel, CommentManagementPanel, CrawlControlPanel, DataCollectionPanel, CrawlingUtility, InteractiveChartUtility), and <strong>Util</strong> (1 class: StringSimilarity), totaling 35 classes across the system. Rather than creating a single monolithic class diagram containing all 35 classes, we have deliberately divided the system into package-specific diagrams. This modular approach to visualization provides several important benefits:</p>
<p><strong>Readability and Comprehension</strong>: Each individual diagram focuses on a specific functional area with 1-10 classes, allowing developers to understand the architecture of a particular package without being overwhelmed by excessive information. A compact, focused diagram with 3-5 core classes is far more digestible than a sprawling diagram with dozens of interconnected classes.</p>
<p><strong>Maintainability and Scalability</strong>: When modifications are needed to a specific package, only the corresponding diagram needs to be updated, without affecting the diagrams of other packages. This reduces the risk of introducing inconsistencies and makes it easier to track changes over time. For example, modifying the sentiment analysis algorithms only requires updating the Sentiment package diagram, not the entire system diagram.</p>
<p><strong>Reusability and Documentation</strong>: Smaller, focused diagrams can be easily reused and referenced in various documentation formats, including technical reports, presentation slides, architectural documentation, and team wikis. A single large diagram with all 35 classes would be difficult to display legibly or reference in these contexts.</p>
<p><strong>Hierarchical Understanding</strong>: The package dependency
diagram provides a bird‚Äôs-eye view of how all seven packages interact and
depend on each other, while the individual package diagrams show the
detailed internal structure and relationships within each package. This
two-level hierarchy‚Äîfirst understanding package-to-package interactions, then exploring individual package internals‚Äîmakes it much easier to understand the system as a
whole and its individual components. Developers can start with the dependency diagram to understand the big picture, then drill down into specific package diagrams to understand implementation details.</p>
<h3 id="package-dependency-diagram">6.2 Package Dependency Diagram</h3>
<p>The following diagram illustrates the dependency relationships
between all packages in the system and demonstrates how they interact
with each other:</p>
<div class="mermaid">
graph TB
    MainApp["üì¶ Main Application<br/>HumanitarianLogisticsApp"]
    
    UI["üì¶ UI Package<br/>View, Panels, Model, Utilities"]
    Crawler["üì¶ Crawler Package<br/>YouTubeCrawler, Registry, Manager"]
    Database["üì¶ Database Package<br/>DatabaseManager, Loader"]
    Sentiment["üì¶ Sentiment Package<br/>SentimentAnalyzer, EnhancedAnalyzer, PythonAnalyzer"]
    Analysis["üì¶ Analysis Package<br/>SatisfactionModule, TimeSeriesModule"]
    Model["üì¶ Model Package<br/>Post, Comment, Sentiment, Disaster"]
    Util["üì¶ Util Package<br/>StringSimilarity"]
    
    MainApp --> UI
    MainApp --> Model
    MainApp --> Crawler
    MainApp --> Database
    
    UI --> Model
    UI --> Crawler
    UI --> Database
    UI --> Sentiment
    UI --> Analysis
    UI --> Util
    
    Crawler --> Model
    Database --> Model
    Analysis --> Model
    Analysis --> Sentiment
    Sentiment --> Model

    style Model fill:#e1f5ff,stroke:#01579b,stroke-width:3px
    style Crawler fill:#f3e5f5,stroke:#4a148c,stroke-width:2px
    style Sentiment fill:#fce4ec,stroke:#880e4f,stroke-width:2px
    style Database fill:#fff3e0,stroke:#e65100,stroke-width:2px
    style Analysis fill:#fbe9e7,stroke:#bf360c,stroke-width:2px
    style UI fill:#f1f8e9,stroke:#33691e,stroke-width:2px
    style Util fill:#ede7f6,stroke:#311b92,stroke-width:2px
    style MainApp fill:#e0f2f1,stroke:#004d40,stroke-width:3px
</div>
<p><strong>Interpretation and Key Observations</strong>: The diagram
clearly shows that the Model package serves as the foundational layer
upon which all other packages depend. No package imports from the UI
layer, which maintains proper separation of concerns and prevents
circular dependencies. The crawler, sentiment analysis, analysis, and
database packages all depend on the Model package, establishing a clear
hierarchical structure. The UI package acts as an orchestrator,
coordinating interactions between the Model, database, crawler, sentiment
analysis, analysis, and utility packages. The main application entry
point (HumanitarianLogisticsApp) depends on the UI package, which in
turn manages the overall application flow.</p>
<h3 id="detailed-class-diagrams-by-package">6.3 Detailed Class Diagrams
by Package</h3>
<h4 id="model-package---core-data-entities">6.3.1 Model Package - Core Data Entities</h4>
<p>The Model package contains the fundamental data entities of the entire system. Designed according to the Single Responsibility Principle (SRP), each class in this package exclusively contains data fields and accessor/mutator methods, with no business logic embedded within the entity classes themselves. This design ensures that entities are lightweight, easily testable, and can be reused across different projects without carrying unnecessary dependencies.</p>
<div class="mermaid">
classDiagram
    class Post {
        -postId: String
        -content: String
        -createdAt: LocalDateTime
        -author: String
        -source: String
        -sentiment: Sentiment
        -reliefItem: ReliefItem
        -disasterKeyword: String
        -comments: List
        +getPostId() String
        +getContent() String
        +getCreatedAt() LocalDateTime
        +getAuthor() String
        +getSource() String
        +getSentiment() Sentiment
        +getReliefItem() ReliefItem
        +getDisasterKeyword() String
        +getComments() List
        +setSentiment(Sentiment)
        +setReliefItem(ReliefItem)
        +setDisasterKeyword(String)
        +addComment(Comment)
        +removeComment(String)
        +updateComment(Comment)
    }

    class YouTubePost {
        -channelId: String
        -likes: int
        -views: int
        -disasterType: DisasterType
        +getChannelId() String
        +setChannelId(String)
        +getLikes() int
        +setLikes(int)
        +getViews() int
        +setViews(int)
        +getDisasterType() DisasterType
        +setDisasterType(DisasterType)
    }

    class Comment {
        -commentId: String
        -postId: String
        -content: String
        -createdAt: LocalDateTime
        -author: String
        -disasterType: String
        -sentiment: Sentiment
        -reliefItem: ReliefItem
        +getCommentId() String
        +getPostId() String
        +getContent() String
        +getCreatedAt() LocalDateTime
        +getAuthor() String
        +getDisasterType() String
        +setDisasterType(String)
        +getSentiment() Sentiment
        +setSentiment(Sentiment)
        +getReliefItem() ReliefItem
        +setReliefItem(ReliefItem)
    }

    class Sentiment {
        -type: SentimentType
        -confidence: double
        -rawText: String
        +getType() SentimentType
        +getConfidence() double
        +getRawText() String
        +isPositive() boolean
        +isNegative() boolean
        +isNeutral() boolean
    }

    class SentimentType {
        POSITIVE
        NEGATIVE
        NEUTRAL
    }

    class ReliefItem {
        -category: Category
        -description: String
        -priority: int
        +getCategory() Category
        +getDescription() String
        +getPriority() int
    }

    class Category {
        CASH
        MEDICAL
        SHELTER
        FOOD
        TRANSPORTATION
    }

    class DisasterType {
        -name: String
        -aliases: Set
        +normalize(String) String
        +addAlias(String)
        +matches(String) boolean
        +getAliases() Set
        +getName() String
    }

    class DisasterManager {
        -disasterTypes: Map
        -instance: DisasterManager
        +getInstance() DisasterManager
        +addDisasterType(DisasterType)
        +getDisasterType(String) DisasterType
        +findDisasterType(String) DisasterType
        +findDisasterTypeForPost(String) DisasterType
        +getAllDisasterNames() List
        +getAllDisasterTypes() Collection
        +isKeywordForDisaster(String, String) boolean
        +getOrCreateDisasterType(String) DisasterType
        +getDisasterTypeCount() int
        +removeDisasterType(String)
    }

    YouTubePost <|-- Post
    Comment --* "1" Post
    Post --> Sentiment
    Post --> ReliefItem
    Sentiment --> SentimentType
    ReliefItem --> Category
    Comment --> Sentiment
    Comment --> ReliefItem
    YouTubePost --> DisasterType
    DisasterManager --> DisasterType

</div>
<p><strong>Design Architecture and Inheritance Strategy</strong>: The Model package employs an inheritance hierarchy combined with composition and aggregation patterns. The Post class is an abstract base class that defines core post properties: <strong>postId, content, createdAt, author, source</strong> (all immutable final fields), and <strong>sentiment, reliefItem, disasterKeyword, comments</strong> (mutable fields). The Post class implements Serializable and Comparable interfaces, enabling persistence and ordering. The YouTubePost class extends Post to add YouTube-specific attributes: <strong>channelId, likes, views, disasterType</strong>. This inheritance design allows polymorphic treatment of different post types.</p>
<p>The Comment class contains similar immutable fields (<strong>commentId, postId, content, createdAt, author</strong>) plus mutable fields for analysis results (<strong>disasterType, sentiment, reliefItem</strong>). Each Post maintains a composition relationship with multiple Comments through the <code>comments</code> list. The Sentiment class is an enum wrapper (SentimentType) containing <strong>type (POSITIVE/NEGATIVE/NEUTRAL), confidence (0.0-1.0), rawText</strong> fields, providing semantic meaning to sentiment analysis results. The ReliefItem class wraps an enum Category (CASH, MEDICAL, SHELTER, FOOD, TRANSPORTATION) with <strong>description</strong> and <strong>priority (1-5)</strong> fields.</p>
<p>The DisasterType class uses a Set-based alias mapping approach to normalize and match disaster keywords flexibly. It stores <strong>name, aliases</strong> fields and provides methods like <code>matches(String keyword)</code> and <code>normalize(String input)</code> for fuzzy matching. The DisasterManager class implements the Singleton pattern (thread-safe with getInstance() method) and manages a Map of DisasterType instances. It initializes five default disasters (yagi, matmo, bualo, koto, FUNG-WONG) in the constructor and provides methods to add, retrieve, and find disaster types by keyword.</p>
<p><strong>Design Rationale and Benefits</strong>: The abstract Post class enables code reuse and future extensibility‚Äînew post sources (Facebook, Twitter, Reddit) only require creating new subclasses without modifying existing code. The separation of immutable construction parameters from mutable analysis results (sentiment, reliefItem) follows the principles of defensive copying and thread safety. Using composition (Post contains Comments) rather than inheritance promotes flexible data modeling. The Sentiment enum wrapper provides type safety over raw strings. The alias-based matching in DisasterType handles flexible disaster keyword matching without tight coupling to specific naming conventions. The Singleton pattern in DisasterManager ensures a single, consistent source of disaster type information across the application.</p>
<p><strong>Reusability and Extensibility</strong>: The design of the
Model package ensures that these entity classes can be reused in other
projects without carrying unnecessary dependencies. The Post class and
its subclasses represent pure data containers that can be easily
serialized to databases, transmitted over networks, or stored in files.
The clean separation of concerns in this package allows for independent
evolution of the model layer without affecting business logic
layers.</p>
<h4
id="ui-package---user-interface-implementation-with-mvc-architecture">6.3.2
UI Package - User Interface Implementation with MVC Architecture</h4>
<p>The UI package contains all graphical user interface components and
implements a strict Model-View-Controller (MVC) architectural pattern.
This package is particularly important as it demonstrates how a complex
user interface can be decomposed into manageable, specialized components
while maintaining clean communication patterns between the view and
model layers.</p>
<div class="mermaid">
classDiagram
    class View {
        -model: Model
        -mainTabbedPane: JTabbedPane
        -crawlPanel: CrawlControlPanel
        -dataCollectionPanel: DataCollectionPanel
        -advancedAnalysisPanel: AdvancedAnalysisPanel
        -commentPanel: CommentManagementPanel
        -statusLabel: JLabel
        +View(Model model)
        -initializeUI()
        -createTitlePanel() JPanel
        -createStatusPanel() JPanel
        -cleanupAndExit()
    }

    class CrawlControlPanel {
        -model: Model
        -postLimitSpinner: JSpinner
        -commentLimitSpinner: JSpinner
        -keywordArea: JTextArea
        -crawlResultsArea: JTextArea
        -statusLabel: JLabel
        -progressBar: JProgressBar
        -crawlButton: JButton
        -postUrlField: JTextArea
        -platformSelector: JComboBox
        -disasterTypeCombo: JComboBox
        -selectedCrawlerName: String
        -crawlerRegistry: CrawlerRegistry
        +CrawlControlPanel(Model model)
        -initializeUI()
        -createPlatformSelectorPanel() JPanel
        -createConfigPanel() JPanel
        -createResultsPanel() JPanel
        -createBottomPanel() JPanel
        -updateUIForCrawler()
        -startCrawling()
        -loadFromUrl()
    }

    class DataCollectionPanel {
        -model: Model
        -postContentArea: JTextArea
        -commentsArea: JTextArea
        -authorField: JTextField
        -disasterTypeCombo: JComboBox
        -categoryCombo: JComboBox
        -sentimentCombo: JComboBox
        -confidenceSpinner: JSpinner
        -statusLabel: JLabel
        +DataCollectionPanel(Model model)
        -initializeUI()
        -createPostInputPanel() JPanel
        -createCommentsInputPanel() JPanel
        -createBottomPanel() JPanel
        -submitPost()
    }

    class CommentManagementPanel {
        -model: Model
        -dbManager: DatabaseManager
        -commentTable: JTable
        -tableModel: DefaultTableModel
        -detailsArea: JTextArea
        -statusLabel: JLabel
        -totalLabel: JLabel
        +CommentManagementPanel(Model model)
        -initializeUI()
        -createStatsPanel() JPanel
        -createMainPanel() JPanel
        +modelChanged()
        -refreshTable()
        -createChartPanel() JPanel
        -deleteComment()
    }

    class AdvancedAnalysisPanel {
        -model: Model
        -mainTabs: JTabbedPane
        +AdvancedAnalysisPanel(Model model)
        -initializeUI()
        -createProblem1Tab() JPanel
        -createProblem2Tab() JPanel
        -createCombinedTab() JPanel
    }

    class Model {
        -posts: List
        -sentimentAnalyzer: SentimentAnalyzer
        -categoryClassifier: PythonCategoryClassifier
        -dbManager: DatabaseManager
        -persistenceManager: DataPersistenceManager
        -analysisModules: Map
        -listeners: List
        +Model()
        +setSentimentAnalyzer(SentimentAnalyzer analyzer)
        +addPost(Post post)
        +getPost(String postId) Post
        +getAllPosts() List
        +addComment(Comment comment)
        +getAnalysisModule(String moduleName) AnalysisModule
        +addModelListener(ModelListener listener)
        -notifyListeners()
        -registerAnalysisModules()
        -loadPersistedData()
    }

    class ModelListener {
        +modelChanged()
    }

    class CrawlingUtility {
        +addCommentsToPost(Post, int)$ void
        +findDisasterTypeForPost(Post, String) DisasterType
    }

    class InteractiveChartUtility {
        +makeChartInteractive(ChartPanel)$ void
        +enableChartInteractivity(ChartPanel)$ void
    }

    View "1" *-- "1" CrawlControlPanel
    View "1" *-- "1" DataCollectionPanel
    View "1" *-- "1" CommentManagementPanel
    View "1" *-- "1" AdvancedAnalysisPanel
    CrawlControlPanel --> Model
    DataCollectionPanel --> Model
    CommentManagementPanel --> Model
    CommentManagementPanel --> DatabaseManager
    AdvancedAnalysisPanel --> Model
    Model "1" --> "*" ModelListener
    Model --> SentimentAnalyzer
    Model --> DatabaseManager
    Model --> DataPersistenceManager
    Model --> AnalysisModule

</div>
<p><strong>MVC Architecture Implementation</strong>: The MVC pattern in
this package follows classical separation of concerns where the Model
component manages application state and business data, the View
component displays information to the user through graphical components,
and the Controller component (implicitly embedded in event handlers)
responds to user interactions. The Model class maintains the
application‚Äôs state including lists of posts and comments, a reference
to the sentiment analyzer, and a collection of registered listeners.
When data changes, the Model notifies all observers without requiring
knowledge of their specific implementations.</p>
<p>The View class serves as the main JFrame container that orchestrates
all UI components and panels. Rather than cramming all interface logic
into a single large class, the interface is decomposed into specialized
panels, each handling a specific functional area:</p>
<ul>
<li><p><strong>CrawlControlPanel</strong>: Provides web crawler control with platform selection (via CrawlerRegistry), keyword input area, post/comment limit spinners, progress tracking, and results display. It supports crawling individual URLs and bulk data collection with automatic disaster type assignment and relief item classification.</p></li>

<li><p><strong>DataCollectionPanel</strong>: Enables manual data entry for posts and comments, with fields for author name, content, disaster type selection, relief category selection, and sentiment analysis. Provides an alternative to automated crawling for direct data input.</p></li>

<li><p><strong>CommentManagementPanel</strong>: Displays all collected comments in a tabular view with columns for comment metadata, sentiment scores, and relief categories. Implements ModelListener to receive notifications when data changes, automatically refreshing the table. Integrates with DatabaseManager for data persistence and retrieval.</p></li>

<li><p><strong>AdvancedAnalysisPanel</strong>: Implements Problem 1 (Satisfaction Analysis) and Problem 2 (Temporal Sentiment Tracking) with tabbed interface for selecting disasters and relief categories, displaying analysis results, generating charts, and comparing satisfaction metrics across different scenarios.</p></li>
</ul>
<p><strong>Observer Pattern and Reactive Updates</strong>: The system
employs the Observer pattern through the ModelListener interface. When
the Model‚Äôs state changes (new posts added, comments updated, sentiment
analyzed), it automatically notifies all registered listeners without
them needing to poll for updates. This creates a reactive, event-driven
system where UI components automatically reflect the current state of
the data.</p>

<p><strong>Utility Classes</strong>: The CrawlingUtility class provides static helper methods for adding simulated comments to posts with random sentiment assignment and relief item linking. The InteractiveChartUtility class provides interactive features for JFreeChart panels, including zoom, pan, and tooltip support for exploratory data analysis.</p>

<p><strong>Database Integration</strong>: The CommentManagementPanel directly manages DatabaseManager for persistent storage and retrieval of comments. The DataPersistenceManager in Model handles saving and loading application state across sessions, ensuring data continuity between application runs.</p>
<h4
id="sentiment-package---multiple-sentiment-analysis-strategies">6.3.3
Sentiment Package - Multiple Sentiment Analysis Strategies</h4>
<p>The Sentiment package provides a flexible framework for analyzing
sentiment in textual data. Rather than committing the entire system to a
single sentiment analysis approach, this package implements the Strategy
design pattern to support multiple analysis strategies with different
accuracy-to-performance tradeoffs.</p>
<div class="mermaid">
classDiagram
    class SentimentAnalyzer {
        +analyzeSentiment(String text) Sentiment
        +analyzeSentimentBatch(String[] texts) Sentiment[]
        +getModelName() String
        +initialize()
        +shutdown()
    }

    class EnhancedSentimentAnalyzer {
        -POSITIVE_WORDS_EN: String[]
        -NEGATIVE_WORDS_EN: String[]
        -POSITIVE_WORDS_VI: String[]
        -NEGATIVE_WORDS_VI: String[]
        +EnhancedSentimentAnalyzer()
        +analyzeSentiment(String text) Sentiment
        +analyzeSentimentBatch(String[] texts) Sentiment[]
        +getModelName() String
        +initialize()
        +shutdown()
        -countMatches(String text, String[] keywords) int
    }

    class PythonSentimentAnalyzer {
        -apiUrl: String
        -modelName: String
        -httpClient: CloseableHttpClient
        -initialized: boolean
        +PythonSentimentAnalyzer(String apiUrl, String modelName)
        +analyzeSentiment(String text) Sentiment
        +analyzeSentimentBatch(String[] texts) Sentiment[]
        +getModelName() String
        +initialize()
        +shutdown()
        +setApiUrl(String newUrl)
    }

    class PythonCategoryClassifier {
        -API_ENDPOINT: String
        -BATCH_ENDPOINT: String
        -TIMEOUT: int
        +classifyText(String text) Category
        +classifyPost(Post post)
        +isApiAvailable() boolean
        +getApiStatus() String
    }

    SentimentAnalyzer <|.. EnhancedSentimentAnalyzer
    SentimentAnalyzer <|.. PythonSentimentAnalyzer
    PythonCategoryClassifier --> ReliefItem

</div>
<p><strong>Strategy Pattern Implementation</strong>: The SentimentAnalyzer interface defines a contract that all sentiment analysis implementations must follow. This interface specifies five core methods: `analyzeSentiment(String text)` for single text analysis, `analyzeSentimentBatch(String[] texts)` for batch processing, `getModelName()` for model identification, `initialize()` for setup, and `shutdown()` for cleanup. This interface-based design enables runtime selection of different analysis strategies without requiring code modifications.</p>

<p><strong>EnhancedSentimentAnalyzer Implementation</strong>: This class implements keyword-based sentiment analysis with bilingual support (English and Vietnamese). It maintains two sets of keyword arrays for positive and negative words in each language (27 positive and 30 negative English words, 32 positive and 34 negative Vietnamese words). The `analyzeSentiment(String text)` method counts keyword matches and calculates confidence scores (0.6-0.99 range) based on match frequency. This provides a good balance between accuracy and performance with zero computational overhead compared to ML models.</p>

<p><strong>PythonSentimentAnalyzer Implementation</strong>: This analyzer interfaces with a machine learning model (XLM-RoBERTa) running in a Python backend service via HTTP POST requests. It accepts an API URL and model name as constructor parameters, allowing flexible configuration. The analyzer sends JSON requests to the Python service, parses responses containing sentiment type and confidence scores, and handles API errors gracefully by falling back to neutral sentiment. This approach leverages deep learning for significantly higher accuracy but incurs computational costs and requires the Python service running on port 5000.</p>

<p><strong>PythonCategoryClassifier</strong>: A specialized classifier (not implementing SentimentAnalyzer) that categorizes text into relief categories (CASH, MEDICAL, SHELTER, FOOD, TRANSPORTATION) using the BART natural language inference model running in Python (port 5001). It provides methods for single text classification (`classifyText(String text) Category`), post classification (`classifyPost(Post post)`), API availability checking (`isApiAvailable() boolean`), and status reporting (`getApiStatus() String`). When classification fails or API is unavailable, it defaults to FOOD category.</p>

<p><strong>Runtime Flexibility</strong>: The beauty of the Strategy pattern is that the Model class can switch between SentimentAnalyzer implementations at runtime. The application can start with EnhancedSentimentAnalyzer for quick processing, then seamlessly switch to PythonSentimentAnalyzer for more accurate analysis via a single method call: `model.setSentimentAnalyzer(new PythonSentimentAnalyzer("http://localhost:5000", "xlm-roberta-sentiment"))`.</p>

<p><strong>Extensibility and Maintainability</strong>: To add a new sentiment analysis approach (such as Google Cloud Natural Language API, OpenAI GPT-based analysis, or domain-specific models), developers only need to implement the SentimentAnalyzer interface without modifying existing implementations. This satisfies the Open/Closed Principle - the system is open for extension but closed for modification. Each analyzer is self-contained and can be tested independently using mock data or test cases.</p>
<h4
id="crawler-package---web-data-collection-with-factory-and-registry-patterns">6.3.4
Crawler Package - Web Data Collection with Factory and Registry
Patterns</h4>
<p>The Crawler package manages data collection from various sources
using a combination of the Factory and Registry design patterns. This
package exemplifies how to build pluggable, extensible architectures
that support adding new data sources without modifying existing
code.</p>
<div class="mermaid">
classDiagram
    class DataCrawler {
        +crawlPosts(List keywords, List hashtags, int limit) List
        +getCrawlerName() String
        +isInitialized() boolean
        +shutdown()
    }

    class YouTubeCrawler {
        -httpClient: HttpClient
        -initialized: boolean
        -sentimentAnalyzer: SentimentAnalyzer
        -USER_AGENT: String
        +YouTubeCrawler()
        +initialize()
        +crawlPosts(List keywords, List hashtags, int limit) List
        +crawlVideoByUrl(String videoUrl) YouTubePost
        +isInitialized() boolean
        +getCrawlerName() String
        +shutdown()
        -crawlByKeyword(String keyword, int limit) List
        -fetchPageContent(String url) String
        -extractVideoIdFromUrl(String url) String
    }

    class MockDataCrawler {
        -initialized: boolean
        -random: Random
        -sentimentAnalyzer: SentimentAnalyzer
        -categoryClassifier: PythonCategoryClassifier
        +MockDataCrawler()
        +crawlPosts(List keywords, List hashtags, int limit) List
        +isInitialized() boolean
        +getCrawlerName() String
        +shutdown()
        -generateRandomPost() Post
    }

    class CrawlerRegistry {
        -crawlers: Map
        -crawlerConfigs: Map
        +getInstance() CrawlerRegistry
        +registerCrawler(CrawlerConfig config)
        +registerCrawler(String name, String displayName, String description, CrawlerFactory factory)
        +getCrawlerNames() List
        +getCrawlerDisplayNames() List
        +getConfig(String crawlerName) CrawlerConfig
        +createCrawler(String crawlerName) DataCrawler
        +supportsKeywordSearch(String crawlerName) boolean
        +supportsUrlCrawl(String crawlerName) boolean
        +requiresInitialization(String crawlerName) boolean
        +getDescription(String crawlerName) String
    }

    class CrawlerConfig {
        +name: String
        +displayName: String
        +description: String
        +factory: CrawlerFactory
        +requiresInitialization: boolean
        +supportsKeywordSearch: boolean
        +supportsUrlCrawl: boolean
        +CrawlerConfig(String name, String displayName, String description, CrawlerFactory factory, boolean requiresInit, boolean supportsKeywords, boolean supportsUrl)
    }

    class CrawlerFactory {
        +create() DataCrawler
    }

    class CrawlerManager {
        +initializeCrawlers()
    }

    DataCrawler <|.. YouTubeCrawler
    DataCrawler <|.. MockDataCrawler
    YouTubeCrawler --> SentimentAnalyzer
    MockDataCrawler --> SentimentAnalyzer
    MockDataCrawler --> PythonCategoryClassifier
    CrawlerRegistry --> CrawlerFactory
    CrawlerRegistry --> CrawlerConfig
    CrawlerManager --> CrawlerRegistry

</div>
<p><strong>Registry and Factory Pattern Design</strong>: The Crawler package uses a sophisticated combination of Registry and Factory patterns. The CrawlerRegistry is a singleton that maintains a centralized registry of available crawler implementations via a map of CrawlerFactory functional interfaces. Each crawler is registered with a CrawlerConfig object containing metadata: internal name, display name, description, factory, and capability flags (requiresInitialization, supportsKeywordSearch, supportsUrlCrawl). This allows the UI to dynamically discover crawler capabilities without loading the concrete classes.</p>
<p><strong>DataCrawler Interface</strong>: All crawlers implement this interface with methods: crawlPosts(List keywords, List hashtags, int limit) for batch crawling, crawlVideoByUrl(String url) for single URL crawling (YouTube-specific), getCrawlerName() for identification, isInitialized() for state checking, and shutdown() for cleanup. This contract ensures all crawlers can be used interchangeably.</p>
<p><strong>YouTubeCrawler Implementation</strong>: Uses HTTP client (not Selenium) to scrape YouTube search results and extract video IDs via regex patterns. It maintains a SentimentAnalyzer for on-the-fly sentiment classification of posts and includes methods: crawlByKeyword() for searching, crawlVideoByUrl() for single videos, fetchPageContent() for HTTP requests, and extractVideoIdFromUrl() for URL parsing. The crawler automatically converts video data into YouTubePost objects with title, description, channel name, view count, and likes extracted from HTML.</p>
<p><strong>MockDataCrawler Implementation</strong>: Generates synthetic data for testing without making real API calls. It uses a Random generator and PythonCategoryClassifier to create realistic mock posts with random sentiments and categories. Supports keyword-based selection from pre-defined category content templates (CASH, MEDICAL, SHELTER, FOOD, TRANSPORTATION) to simulate diverse relief-related posts. Returns data instantly, enabling fast test execution and comprehensive testing without external dependencies.</p>
<p><strong>CrawlerManager Facade</strong>: Provides static initializeCrawlers() method that registers both YouTubeCrawler and MockDataCrawler with the registry. This initialization is called once during application startup and populates the registry with crawler metadata and factories.</p>
<p><strong>Plugin Architecture Benefits</strong>: New crawlers can be added at runtime without modifying existing code. To add Facebook crawling: (1) Create FacebookCrawler implementing DataCrawler, (2) Register it with a CrawlerConfig in CrawlerManager, (3) UI automatically discovers it via registry. The UI depends only on DataCrawler interface and CrawlerRegistry, achieving Dependency Inversion. This design enables parallel crawling from multiple sources simultaneously while maintaining loose coupling and testability.</p>
<h4 id="analysis-package---modular-analysis-strategies">6.3.5 Analysis
Package - Modular Analysis Strategies</h4>
<p>The Analysis package contains the implementations of Problem 1 and
Problem 2 analysis modules, both following the Strategy design pattern
for flexible analysis execution.</p>
<div class="mermaid">
classDiagram
    class AnalysisModule {
        +analyze(List~Post~ posts) Map
        +getModuleName() String
        +getDescription() String
    }

    class SatisfactionAnalysisModule {
        +analyze(List~Post~ posts) Map
        +getModuleName() String
        +getDescription() String
        -calculateSentimentStats(List~Sentiment~, Category) Map
        -assessCategoryEffectiveness(Map) Map
        -generateDetailedInsights(Map) Map
        -generateResourceRecommendations(Map) Map
        -generateSummary(Map) Map
    }

    class TimeSeriesSentimentModule {
        +analyze(List~Post~ posts) Map
        +getModuleName() String
        +getDescription() String
        -getTimeBucket(LocalDateTime) LocalDateTime
        -analyzeTimeSeries(Map) Map
        -calculateTrend(List) String
        -calculateVolatility(List) double
        -determineEffectiveness(Map) Map
        -generateDetailedInsights(String, Map) Map
        -generateNarrative(String, Map) String
        -generateSummary(Map) Map
    }

    AnalysisModule <|.. SatisfactionAnalysisModule
    AnalysisModule <|.. TimeSeriesSentimentModule
</div>
<p><strong>Analysis Module Interface and Implementations</strong>: Each analysis module implements the AnalysisModule interface, which defines three key methods: `analyze(List<Post> posts)` for processing post data and returning results as a Map, `getModuleName()` for identifying the module, and `getDescription()` for describing its purpose. This design allows dynamic module selection and execution through polymorphism.</p>
<p>The <strong>SatisfactionAnalysisModule</strong> (Problem 1) analyzes public satisfaction and dissatisfaction for different relief item categories. It processes both posts and comments associated with relief items, grouping sentiments by relief category (CASH, MEDICAL, FOOD, SHELTER). For each category, it: calculates sentiment distribution (positive, negative, neutral counts and percentages); computes satisfaction scores based on sentiment ratios; assesses category effectiveness using a rating scale (Excellent, Good, Fair, Poor); generates detailed insights with multi-category comparisons; produces resource allocation recommendations; and provides a comprehensive summary. All results are returned as a Map with keys like "problem_1_satisfaction_analysis", "category_effectiveness", and "resource_allocation_recommendations".</p>
<p>The <strong>TimeSeriesSentimentModule</strong> (Problem 2) tracks sentiment changes over time for each relief item category to determine sector effectiveness. It extracts sentiments from both posts and comments, bins them into 6-hour time buckets based on creation timestamps, and tracks sentiment evolution within each bucket. For each category, it: creates a time-indexed Map of sentiments; analyzes time series data to compute sentiment distributions per time bucket; calculates trend direction (Improving, Stable, Declining) by analyzing sentiment ratios; measures volatility to identify sentiment fluctuations; determines sector effectiveness ratings; generates detailed insights with narrative descriptions; and produces a comprehensive summary. All results are returned as a Map with keys like "problem_2_time_series_sentiment", "sector_effectiveness", "detailed_insights", and "summary".</p>
<p><strong>Strategy Pattern Benefits</strong>: The interface-based
design allows the Model class to manage multiple analysis modules and
invoke them dynamically:</p>
<div class="sourceCode" id="cb20"><pre
class="sourceCode java"><code class="sourceCode java"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>AnalysisModule module <span class="op">=</span> analysisModules<span class="op">.</span><span class="fu">get</span><span class="op">(</span><span class="st">"satisfaction"</span><span class="op">);</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="bu">Map</span><span class="op">&lt;</span><span class="bu">String</span><span class="op">,</span> <span class="bu">Object</span><span class="op">&gt;</span> results <span class="op">=</span> module<span class="op">.</span><span class="fu">analyze</span><span class="op">(</span>posts<span class="op">,</span> comments<span class="op">);</span></span></code></pre></div>
<p>New analysis modules (Geographic Analysis, Demographic Analysis,
Language Analysis) can be added without modifying existing modules or
the Model class. Each module focuses exclusively on its analysis
responsibility, making the code easier to understand, test, and
maintain.</p>
<h4 id="database-package---data-persistence-and-management">6.3.6
Database Package - Data Persistence and Management</h4>
<p>The Database package manages all aspects of data persistence,
providing both low-level SQL operations and high-level application
interfaces for data management.</p>
<div class="mermaid">
classDiagram
    class DatabaseManager {
        -instance: DatabaseManager
        -connection: Connection
        -dbFilePath: String
        -initialized: boolean
        +getInstance() DatabaseManager
        +savePost(Post post) void
        +saveComment(Comment comment) void
        +updateComment(Comment comment) void
        +deleteComment(String commentId) void
        +getAllPosts() List
        +getAllCommentsFromDatabase() List
        +clearAllComments() void
        +close() void
        +commit() void
        +reset() void
        -getDbFilePath() String
        -ensureConnection() void
        -createTables() void
        -reconstructPost(ResultSet) Post
    }

    class DatabaseLoader {
        +loadOurDatabase(Model model) void
        -loadFromDevUIDatabase(Model) void
        -saveLoadedDataToUserDatabase(Model) void
        -getDevUIDbPath() String
    }

    class DataPersistenceManager {
        -postsFile: String
        -disastersFile: String
        +DataPersistenceManager()
        +savePosts(List~Post~ posts) void
        +loadPosts() List
        +saveDisasters(DisasterManager manager) void
        +loadDisasters(DisasterManager manager) void
        +clearAllData() void
        +hasSavedData() boolean
        +getDataDirectory() String
        -getDataDir() String
    }

    DatabaseLoader --> DatabaseManager
    DatabaseManager --> Post
    DatabaseManager --> Comment
    DataPersistenceManager --> Post
    DataPersistenceManager --> DisasterManager
</div>
<p><strong>Dual Persistence Architecture</strong>: The Database package implements two independent persistence strategies. DatabaseManager provides low-level SQLite database operations including Singleton pattern for connection management, CRUD operations on posts and comments, connection pooling, prepared statements for SQL injection protection, and PRAGMA configurations (busy_timeout, foreign_keys, WAL mode). DataPersistenceManager uses Java object serialization to save posts to posts.dat and custom disaster types to disasters.dat files, providing simpler file-based storage for application state. Both managers operate independently - DatabaseManager handles SQL-based operations while DataPersistenceManager handles serialized object persistence.</p>
<p><strong>DatabaseManager Singleton Pattern</strong>: Ensures single database connection throughout application lifetime using synchronized double-checked locking. Provides methods: savePost(), saveComment(), updateComment(), deleteComment(), getAllPosts(), getAllCommentsFromDatabase(), clearAllComments(), commit(), close(), and reset(). Uses database schema with proper foreign key constraints to ensure referential integrity between posts and comments. The reconstructPost() method rebuilds Post objects from database ResultSet with full data including associated comments.</p>
<p><strong>DatabaseLoader Facade</strong>: Provides loadOurDatabase(Model model) as the main entry point, which loads data from a curated SQLite database (humanitarian_logistics_curated.db), converts it into Post and Comment objects, stores them in the Model, and then persists them to the user's personal database via saveLoadedDataToUserDatabase(). This allows the application to initialize with curated default data while maintaining user-specific persistence. The private loadFromDevUIDatabase() method handles the actual reading from the curated database file.</p>
<p><strong>DataPersistenceManager Serialization</strong>: Uses ObjectInputStream/ObjectOutputStream for serializing/deserializing Java objects. Provides methods: savePosts(List) to write posts to posts.dat, loadPosts() to read posts from disk, saveDisasters(DisasterManager) to save custom disaster types, and loadDisasters(DisasterManager) to restore them. Automatically filters default disaster types (yagi, matmo, bualo, koto, fung-wong) when saving, only persisting user-created custom disasters. Creates data directory automatically if it doesn't exist.</p>
<p><strong>Resource Management</strong>: DatabaseManager uses try-with-resources for Statement and PreparedStatement objects to ensure proper cleanup. Connection synchronization prevents race conditions during concurrent access. WAL mode enables better concurrency for SQLite. DataPersistenceManager similarly uses try-with-resources for stream management to prevent resource leaks.</p>
<h4 id="util-package---utility-and-helper-functions">6.3.7 Util Package - Utility and Helper Functions</h4>
<p>The Util package provides shared utility functions used across multiple packages in the application.</p>
<div class="mermaid">
classDiagram
    class StringSimilarity {
        +levenshteinDistance(String s1, String s2) int
        +levenshteinSimilarity(String s1, String s2) double
        +findMostSimilar(String input, List~String~ candidates) String
    }
</div>
<p><strong>String Similarity Utilities</strong>: The StringSimilarity class implements the Levenshtein distance algorithm for measuring string similarity. The algorithm calculates the minimum number of single-character edits (insertions, deletions, substitutions) required to transform one string into another. This utility enables fuzzy matching of disaster type keywords and relief item categories, allowing the system to handle user input with typos, abbreviations, or variations.</p>
<p><strong>Levenshtein Distance</strong>: The core method `levenshteinDistance(String s1, String s2)` returns an integer representing the minimum edit distance between two strings. It uses dynamic programming with a 2D matrix where each cell [i,j] represents the distance between the first i characters of s1 and the first j characters of s2. Handles null inputs gracefully by treating them as empty strings.</p>
<p><strong>Similarity Scoring</strong>: The `levenshteinSimilarity(String s1, String s2)` method converts the raw distance into a normalized similarity score between 0.0 and 1.0. It calculates: similarity = 1.0 - (distance / max_length), where max_length is the length of the longer string. This normalization enables consistent comparison across strings of different lengths.</p>
<p><strong>Fuzzy Matching</strong>: The `findMostSimilar(String input, List candidates)` method finds the best matching candidate from a list. It compares the input string against all candidates using similarity scoring and returns the match with the highest score if it exceeds 0.5 (50% similarity threshold). Returns null if no sufficiently similar match is found. This method is used for:</p>
<ul>
<li>Matching user-provided disaster keywords to predefined disaster types</li>
<li>Finding the closest relief category when exact matches are unavailable</li>
<li>Handling spelling variations and abbreviations gracefully</li>
</ul>
<h4 id="main-application-and-utility-classes">6.3.8 Main Application and Utility Classes</h4>
<p>The main application layer provides the entry point and various
utility functions supporting the broader system.</p>
<div class="mermaid">
classDiagram
    class HumanitarianLogisticsApp {
        -static View view
        -static Model model
        +main(String[] args) void
    }
    
    HumanitarianLogisticsApp --> View
    HumanitarianLogisticsApp --> Model
</div>
<p><strong>Application Initialization and Bootstrap</strong>: The
HumanitarianLogisticsApp class serves as the single entry point for the
entire application, containing the main() method that is executed when
the program starts. This class is responsible for orchestrating the
initialization sequence of all major system components in the correct
order:</p>
<ol type="1">
<li>Initialize the DisasterManager singleton with predefined disaster
types</li>
<li>Create the sentiment analyzer instance (configured as needed)</li>
<li>Instantiate the Model class with all necessary dependencies</li>
<li>Create the View (JFrame) with the initialized Model</li>
<li>Set the View as visible, allowing user interaction to begin</li>
</ol>
<p>By centralizing all initialization logic in one place, the
application code becomes easier to understand and modify. Developers can
quickly see which components are created, in what order, and what
dependencies are injected.</p>
<h3 id="architectural-design-principles-and-rationale">6.4 Architectural
Design Principles and Rationale</h3>
<h4 id="model-package-independence---the-foundation-layer">6.4.1 Model
Package Independence - The Foundation Layer</h4>
<p>The Model package is deliberately designed to have zero dependencies
on any other package. This foundational independence is crucial for
several reasons:</p>
<p><strong>Clean Architecture</strong>: By keeping the Model package
independent, we ensure that entity classes represent pure data
containers without knowledge of how they will be displayed, persisted,
or analyzed. This adherence to clean architecture principles means that
the Model layer can be shared across multiple applications, used in
different UI frameworks, or even exposed through REST APIs without
carrying unnecessary dependencies.</p>
<p><strong>Testability</strong>: Entity classes can be easily
instantiated and tested in isolation without setting up complex
infrastructure. Unit tests can create mock objects and validate business
logic without database connections, UI frameworks, or external
services.</p>
<p><strong>Reusability</strong>: Organizations can extract the entire
Model package and reuse it in other projects that address different
problems but deal with similar data structures. The Post and Comment
classes could be used in social media analysis projects, disaster
response planning systems, or humanitarian crisis tracking
applications.</p>
<p><strong>Separation of Concerns</strong>: By keeping data models
separate from business logic, presentation logic, and persistence logic,
we maintain a clear architectural boundary that makes the codebase more
maintainable and easier for new team members to understand.</p>
<h4 id="ui-package-with-mvc-architecture---the-presentation-layer">6.4.2
UI Package with MVC Architecture - The Presentation Layer</h4>
<p>The UI package implements a strict MVC pattern where the Model (M)
component manages state, the View (V) component displays state, and the
Controller (C) component handles user interactions and invokes
operations on the Model.</p>
<p><strong>Panel Decomposition Strategy</strong>: Rather than creating a
single View class containing all UI components, we deliberately
decompose the interface into focused panels:</p>
<pre><code class="language-java">Monolithic Approach:
View class (2000+ lines)
  - Crawling UI (500 lines)
  - Comment management (300 lines)
  - Problem 1 analysis (400 lines)
  - Problem 2 analysis (500 lines)
  - Disaster management (300 lines)
  Result: Difficult to maintain, test, and modify

Modular Approach:
View class (170 lines) - Main container and layout
‚îú‚îÄ CrawlControlPanel (710 lines) - Web data collection and platform management
‚îú‚îÄ DataCollectionPanel (320 lines) - Manual data entry for posts and comments
‚îú‚îÄ AdvancedAnalysisPanel (710 lines) - Problem 1 & 2 analysis with visualization
‚îú‚îÄ CommentManagementPanel (770 lines) - Comment viewing and database integration
‚îî‚îÄ Model (232 lines) - Application state and business logic
Result: Easy to maintain, test, and modify</code></pre>
<p><strong>Observer Pattern Implementation</strong>: The system employs
the Observer design pattern through the ModelListener interface. Rather
than panels directly querying the Model for updates, they register as
listeners. When the Model‚Äôs state changes, it automatically notifies all
registered listeners. This creates loose coupling - panels need not know
about each other‚Äôs existence, only about the Model‚Äôs interface.</p>
<div class="sourceCode" id="cb25"><pre
class="sourceCode java"><code class="sourceCode java"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co">// Model notifies listeners when data changes</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="kw">private</span> <span class="dt">void</span> <span class="fu">notifyListeners</span><span class="op">()</span> <span class="op">{</span></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> <span class="op">(</span>ModelListener listener <span class="op">:</span> listeners<span class="op">)</span> <span class="op">{</span></span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>        listener<span class="op">.</span><span class="fu">modelChanged</span><span class="op">();</span></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>    <span class="op">}</span></span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a><span class="co">// Listener interface</span></span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a><span class="kw">public</span> <span class="kw">interface</span> ModelListener <span class="op">{</span> <span class="dt">void</span> <span class="fu">modelChanged</span><span class="op">();</span> <span class="op">}</span></span></code></pre></div>
<p>This approach ensures that all UI components remain synchronized with
the current application state without explicit coordination between
panels.</p>
<p><strong>Utility Class Organization</strong>: Reusable functionality
is extracted into utility classes:</p>
<ul>
<li><strong>CrawlingUtility</strong>: Data collection helper
methods</li>
<li><strong>InteractiveChartUtility</strong>: Interactive visualization
components</li>
</ul>
<p>By extracting these utilities, we follow the DRY (Don‚Äôt Repeat
Yourself) principle and enable code reuse across multiple UI panels.</p>
<h4
id="sentiment-package-with-strategy-pattern---flexible-analysis">6.4.3
Sentiment Package with Strategy Pattern - Flexible Analysis</h4>
<p>The Sentiment package demonstrates how the Strategy design pattern
enables runtime algorithm selection without code modification:</p>
<p><strong>Strategy Hierarchy</strong>:</p>
<pre><code class="language-java">SentimentAnalyzer (interface)
‚îú‚îÄ EnhancedSentimentAnalyzer (keyword-based)
‚îî‚îÄ PythonSentimentAnalyzer (advanced, accurate)</code></pre>
<p><strong>Runtime Switching Capability</strong>: The brilliance of this
design is that the Model class never needs to know which specific
analyzer is being used. It works with the SentimentAnalyzer
interface:</p>
<div class="sourceCode" id="cb27"><pre
class="sourceCode java"><code class="sourceCode java"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="kw">private</span> SentimentAnalyzer sentimentAnalyzer<span class="op">;</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a><span class="kw">public</span> <span class="dt">void</span> <span class="fu">setSentimentAnalyzer</span><span class="op">(</span>SentimentAnalyzer analyzer<span class="op">)</span> <span class="op">{</span></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">this</span><span class="op">.</span><span class="fu">sentimentAnalyzer</span> <span class="op">=</span> analyzer<span class="op">;</span></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a><span class="kw">public</span> Sentiment <span class="fu">analyzeSentiment</span><span class="op">(</span><span class="bu">String</span> text<span class="op">)</span> <span class="op">{</span></span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> sentimentAnalyzer<span class="op">.</span><span class="fu">analyzeSentiment</span><span class="op">(</span>text<span class="op">);</span></span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span></code></pre></div>
<p>Because of this interface-based dependency, the Model code remains
unchanged whether we use EnhancedSentimentAnalyzer,
PythonSentimentAnalyzer, or a future GoogleCloudAnalyzer. This
exemplifies the Dependency Inversion Principle - the Model depends on an
abstraction (the interface) rather than concrete implementations.</p>
<p><strong>Extensibility Without Modification</strong>: Adding a new
sentiment analysis approach requires only implementing the
SentimentAnalyzer interface. The entire system automatically supports
the new approach without modification, satisfying the Open/Closed
Principle. Organizations could add new analyzers for different
languages, domains, or performance requirements without affecting
existing code.</p>
<h4
id="crawler-package-with-factory-and-registry-patterns---extensible-data-collection">6.4.4
Crawler Package with Factory and Registry Patterns - Extensible Data
Collection</h4>
<p>The Crawler package uses two complementary patterns to achieve
maximum extensibility:</p>
<p><strong>Registry Pattern - Discovery and Instantiation</strong>: The
CrawlerRegistry maintains a registry of available crawler
implementations and provides factory methods to create instances. This
approach decouples the UI from concrete crawler implementations:</p>
<div class="sourceCode" id="cb28"><pre
class="sourceCode java"><code class="sourceCode java"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co">// UI doesn&#39;t need to know about YouTubeCrawler</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>DataCrawler crawler <span class="op">=</span> registry<span class="op">.</span><span class="fu">createCrawler</span><span class="op">(</span><span class="st">"youtube"</span><span class="op">);</span></span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a><span class="bu">List</span><span class="op">&lt;</span>Post<span class="op">&gt;</span> posts <span class="op">=</span> crawler<span class="op">.</span><span class="fu">crawlPosts</span><span class="op">(</span>keywords<span class="op">,</span> hashtags<span class="op">,</span> limit<span class="op">);</span></span></code></pre></div>
<p><strong>Plugin Architecture Benefits</strong>: New data sources can
be added as ‚Äúplugins‚Äù without modifying existing code:</p>
<ol type="1">
<li>Create FacebookCrawler implementing DataCrawler interface</li>
<li>Register with CrawlerRegistry</li>
<li>UI automatically shows Facebook as available option</li>
</ol>
<p>This is a powerful example of the Open/Closed Principle - the system
is open for extension (new crawlers) but closed for modification (UI
code doesn‚Äôt change).</p>
<p><strong>Loose Coupling</strong>: By depending on the DataCrawler
interface rather than concrete implementations, the UI is completely
decoupled from crawler details. YouTubeCrawler could be completely
rewritten, new crawlers could be added, or crawlers could be removed
without affecting UI code.</p>
<h4 id="analysis-package-with-strategy-pattern---modular-analysis">6.4.5
Analysis Package with Strategy Pattern - Modular Analysis</h4>
<p>The Analysis package uses the Strategy pattern similarly to Sentiment
analysis, but applied to different types of data analysis:</p>
<p><strong>Analysis Module Registry</strong>:</p>
<div class="sourceCode" id="cb29"><pre
class="sourceCode java"><code class="sourceCode java"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="bu">Map</span><span class="op">&lt;</span><span class="bu">String</span><span class="op">,</span> AnalysisModule<span class="op">&gt;</span> modules <span class="op">=</span> <span class="kw">new</span> <span class="bu">LinkedHashMap</span><span class="op">&lt;&gt;();</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>modules<span class="op">.</span><span class="fu">put</span><span class="op">(</span><span class="st">"satisfaction"</span><span class="op">,</span> <span class="kw">new</span> <span class="fu">SatisfactionAnalysisModule</span><span class="op">());</span></span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>modules<span class="op">.</span><span class="fu">put</span><span class="op">(</span><span class="st">"time_series"</span><span class="op">,</span> <span class="kw">new</span> <span class="fu">TimeSeriesSentimentModule</span><span class="op">());</span></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a><span class="co">// Add new analysis without modifying existing code</span></span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>modules<span class="op">.</span><span class="fu">put</span><span class="op">(</span><span class="st">"geographic"</span><span class="op">,</span> <span class="kw">new</span> <span class="fu">GeographicAnalysisModule</span><span class="op">());</span></span></code></pre></div>
<p><strong>Independent Module Development</strong>: Each analysis module
focuses exclusively on its analysis responsibility, making it easier to
develop, test, and maintain. The SatisfactionAnalysisModule concerns
itself only with category-based satisfaction metrics, while
TimeSeriesSentimentModule focuses on temporal trends. Adding
GeographicAnalysisModule to analyze spatial distribution of sentiment
requires no changes to existing modules.</p>
<h4 id="database-package---abstraction-and-flexibility">6.4.6 Database
Package - Abstraction and Flexibility</h4>
<p>The Database package demonstrates how abstraction allows technology
changes without impacting application code:</p>
<p><strong>Layered Architecture</strong>:</p>
<pre><code class="language-java">Application Code
    ‚Üì
DataPersistenceManager (Facade)
    ‚Üì
DatabaseManager (Concrete SQLite Implementation)
    ‚Üì
SQLite Database</code></pre>
<p>This layering means that migrating from SQLite to PostgreSQL,
MongoDB, or even cloud-based databases requires modifying only the
DatabaseManager class. Application code remains unchanged, ensuring that
application logic doesn‚Äôt need to be tested again.</p>
<p><strong>Try-with-Resources Pattern</strong>: The implementation uses
try-with-resources statements to ensure automatic resource cleanup:</p>
<div class="sourceCode" id="cb31"><pre
class="sourceCode java"><code class="sourceCode java"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="cf">try</span> <span class="op">(</span><span class="bu">ObjectOutputStream</span> oos <span class="op">=</span> <span class="kw">new</span> <span class="bu">ObjectOutputStream</span><span class="op">(</span><span class="kw">...</span><span class="op">))</span> <span class="op">{</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Write data</span></span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a><span class="op">}</span> <span class="co">// ObjectOutputStream automatically closed, even if exception occurs</span></span></code></pre></div>
<p>This pattern prevents resource leaks and ensures data integrity even
in error scenarios.</p>
<h3 id="solid-principles-applied-throughout-the-design">6.5 SOLID
Principles Applied Throughout the Design</h3>
<p>The system consistently applies the five SOLID principles to ensure
maintainability and extensibility:</p>
<table>
<colgroup>
<col style="width: 33%" />
<col style="width: 39%" />
<col style="width: 27%" />
</colgroup>
<thead>
<tr>
<th>Principle</th>
<th>Application</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>S</strong> - Single Responsibility</td>
<td>Each class has one reason to change</td>
<td>Post class only contains data; DatabaseManager only handles database
operations</td>
</tr>
<tr>
<td><strong>O</strong> - Open/Closed</td>
<td>Open for extension, closed for modification</td>
<td>Add new crawlers without modifying CrawlerRegistry; add new
analyzers without modifying Model</td>
</tr>
<tr>
<td><strong>L</strong> - Liskov Substitution</td>
<td>Subtypes can substitute their supertypes</td>
<td>Any SentimentAnalyzer implementation can replace any other; any
DataCrawler can replace any other</td>
</tr>
<tr>
<td><strong>I</strong> - Interface Segregation</td>
<td>Clients depend on specific interfaces</td>
<td>UI depends on SentimentAnalyzer interface; doesn‚Äôt depend on
unrelated methods in PythonSentimentAnalyzer</td>
</tr>
<tr>
<td><strong>D</strong> - Dependency Inversion</td>
<td>Depend on abstractions, not implementations</td>
<td>Model depends on SentimentAnalyzer interface; doesn‚Äôt depend on
EnhancedSentimentAnalyzer or PythonSentimentAnalyzer concrete classes</td>
</tr>
</tbody>
</table>
<h3 id="architectural-summary-and-benefits">6.6 Architectural Summary
and Benefits</h3>
<p>The Humanitarian Logistics Analysis System demonstrates a
professionally architected solution with clear separation of concerns
across seven well-defined packages. Each package focuses on a specific
responsibility while maintaining loose coupling with other packages. The
architecture leverages industry-standard design patterns (Strategy,
Factory, Registry, Observer, Singleton, MVC) to provide flexibility,
extensibility, and maintainability.</p>
<p><strong>Key Architectural Achievements</strong>:</p>
<ol type="1">
<li><strong>Modularity</strong>: Each package is independently
understandable and modifiable without affecting others</li>
<li><strong>Extensibility</strong>: New features can be added by
extending existing interfaces rather than modifying existing code</li>
<li><strong>Testability</strong>: Components can be tested in isolation
using mock objects and test doubles</li>
<li><strong>Reusability</strong>: Core components (Model package,
Sentiment strategies) can be reused in other projects</li>
<li><strong>Maintainability</strong>: Clear separation of concerns makes
the codebase easy to understand and modify</li>
<li><strong>Scalability</strong>: The architecture supports team
development with multiple developers working on different packages
simultaneously</li>
</ol>
<p>This design reflects mature software engineering practices suitable
for production systems serving critical humanitarian logistics
operations.</p>
<h2 id="oop-techniques">7. OOP Techniques and Design Patterns</h2>

<p>The Humanitarian Logistics Analysis System is built on solid object-oriented programming principles and industry-standard design patterns. This section provides in-depth analysis with actual code examples extracted directly from the codebase, demonstrating how each technique is applied to solve real problems in the application.</p>

<h3 id="fundamental-oop-concepts">7.1 Fundamental Object-Oriented Programming Concepts</h3>

<p>Seven core OOP concepts form the foundation of the system's architecture. Each is applied strategically throughout the codebase to achieve flexibility, maintainability, and extensibility.</p>

<h4 id="encapsulation">7.1.1 Encapsulation - Data Protection and Controlled Access</h4>

<p><strong>Purpose:</strong> Bundle data and methods together while hiding internal details and controlling access to state. This prevents invalid data states and unintended external modifications.</p>

<p><strong>Implementation in Post.java:</strong></p>

<pre><code class="language-java">public abstract class Post implements Serializable, Comparable&lt;Post&gt; {
    private final String postId;
    private final String content;
    private final LocalDateTime createdAt;
    private final String author;
    private final String source;
    
    protected Post(String postId, String content, LocalDateTime createdAt,
                   String author, String source) {
        this.postId = Objects.requireNonNull(postId, "Post ID cannot be null");
        this.content = Objects.requireNonNull(content, "Content cannot be null");
        this.createdAt = Objects.requireNonNull(createdAt, "Created date cannot be null");
        this.author = Objects.requireNonNull(author, "Author cannot be null");
        this.source = Objects.requireNonNull(source, "Source cannot be null");
        this.comments = new ArrayList&lt;&gt;();
    }
    
    public String getPostId() { return postId; }
    public List&lt;Comment&gt; getComments() { 
        return Collections.unmodifiableList(comments); 
    }
    
    public void addComment(Comment comment) {
        if (comment != null) this.comments.add(comment);
    }
}</code></pre>

<p><strong>Key Techniques:</strong> Immutable fields (final), null safety via Objects.requireNonNull(), defensive copying, and controlled modification. <strong>Benefits:</strong> Data integrity, early error detection, and traceable changes.</p>

<h4 id="abstraction">7.1.2 Abstraction - Hiding Implementation Complexity</h4>

<p><strong>Purpose:</strong> Define WHAT operations an object performs without exposing HOW. This allows different implementations to be swapped without affecting client code.</p>

<pre><code class="language-java">public interface SentimentAnalyzer {
    Sentiment analyzeSentiment(String text);
    Sentiment[] analyzeSentimentBatch(String[] texts);
    String getModelName();
    void initialize();
    void shutdown();
}

public class EnhancedSentimentAnalyzer implements SentimentAnalyzer {
    @Override
    public Sentiment analyzeSentiment(String text) {
        int positiveCount = countMatches(text.toLowerCase(), POSITIVE_WORDS_EN) + 
                           countMatches(text.toLowerCase(), POSITIVE_WORDS_VI);
        int negativeCount = countMatches(text.toLowerCase(), NEGATIVE_WORDS_EN) +
                           countMatches(text.toLowerCase(), NEGATIVE_WORDS_VI);
        
        Sentiment.SentimentType type = positiveCount > negativeCount ? 
            Sentiment.SentimentType.POSITIVE : negativeCount > positiveCount ? 
            Sentiment.SentimentType.NEGATIVE : Sentiment.SentimentType.NEUTRAL;
        
        double confidence = Math.min(Math.max(Math.abs(positiveCount - negativeCount) / 10.0, 0.6), 0.99);
        return new Sentiment(type, confidence, text);
    }
}</code></pre>

<p><strong>Benefits:</strong> Easy testing, runtime selection, future extensibility, zero client coupling.</p>

<h4 id="inheritance">7.1.3 Inheritance - Code Reuse and Hierarchies</h4>

<p><strong>Purpose:</strong> Create class hierarchies where specialized subclasses inherit common behavior from parent classes, avoiding code duplication.</p>

<pre><code class="language-java">public abstract class Post implements Serializable, Comparable&lt;Post&gt; {
    private final String postId;
    private final String content;
    private final LocalDateTime createdAt;
    private final String author;
    private final String source;
    private final List&lt;Comment&gt; comments;
    
    public void addComment(Comment comment) { ... }
    public List&lt;Comment&gt; getComments() { ... }
    public void setSentiment(Sentiment sentiment) { ... }
    
    @Override
    public int compareTo(Post other) {
        return this.createdAt.compareTo(other.createdAt);
    }
}

public class YouTubePost extends Post {
    private String videoId;
    
    public YouTubePost(String postId, String content, LocalDateTime createdAt,
                       String author, String videoId) {
        super(postId, content, createdAt, author, "YouTube");
        this.videoId = videoId;
    }
}</code></pre>

<p><strong>Benefits:</strong> Code reuse, consistency, extensibility, and polymorphism.</p>

<h4 id="polymorphism">7.1.4 Polymorphism - Runtime Behavior Selection</h4>

<pre><code class="language-java">public class Model {
    private SentimentAnalyzer sentimentAnalyzer;
    
    public void setSentimentAnalyzer(SentimentAnalyzer analyzer) {
        if (this.sentimentAnalyzer != null) {
            this.sentimentAnalyzer.shutdown();
        }
        this.sentimentAnalyzer = analyzer;
        this.sentimentAnalyzer.initialize();
        notifyListeners();
    }
    
    public void addPost(Post post) {
        if (post.getSentiment() == null && sentimentAnalyzer != null) {
            Sentiment sentiment = sentimentAnalyzer.analyzeSentiment(post.getContent());
            post.setSentiment(sentiment);
        }
        // Process comments similarly
        for (Comment comment : post.getComments()) {
            if (comment.getSentiment() == null && sentimentAnalyzer != null) {
                Sentiment sentiment = sentimentAnalyzer.analyzeSentiment(comment.getContent());
                comment.setSentiment(sentiment);
            }
        }
        this.posts.add(post);
    }
}</code></pre>

<h4 id="interfaces">7.1.5 Interfaces - Contracts and Multiple Implementations</h4>

<pre><code class="language-java">public interface SentimentAnalyzer { Sentiment analyzeSentiment(String text); }
public interface DataCrawler { List&lt;Post&gt; crawlPosts(List&lt;String&gt; keywords, List&lt;String&gt; hashtags, int limit); }
public interface AnalysisModule { Map&lt;String, Object&gt; analyze(List&lt;Post&gt; posts); }
public interface ModelListener { void modelChanged(); }</code></pre>

<p><strong>Benefits:</strong> Contracts, loose coupling, easy testing, runtime flexibility.</p>

<h4 id="abstract-classes">7.1.6 Abstract Classes - Partial Implementation</h4>

<p>Unlike interfaces, abstract classes provide actual implementation and shared state:</p>

<pre><code class="language-java">public abstract class Post implements Serializable, Comparable&lt;Post&gt; {
    private final String postId;
    private final List&lt;Comment&gt; comments = new ArrayList&lt;&gt;();
    
    public List&lt;Comment&gt; getComments() { 
        return Collections.unmodifiableList(comments); 
    }
    
    public void addComment(Comment comment) {
        if (comment != null) this.comments.add(comment);
    }
}</code></pre>

<h4 id="composition">7.1.7 Composition - Has-A Relationships</h4>

<pre><code class="language-java">public class Model {
    private SentimentAnalyzer sentimentAnalyzer = new EnhancedSentimentAnalyzer();
    private DatabaseManager dbManager = new DatabaseManager();
    private List&lt;Post&gt; posts = new ArrayList&lt;&gt;();
    private List&lt;ModelListener&gt; listeners = new ArrayList&lt;&gt;();
    
    public void setSentimentAnalyzer(SentimentAnalyzer analyzer) {
        this.sentimentAnalyzer = analyzer;
    }
}</code></pre>

<p><strong>Composition vs Inheritance:</strong> Use inheritance (IS-A) for hierarchies; use composition (HAS-A) for flexibility and runtime swapping.</p>

<h3 id="design-patterns">7.2 Advanced Design Patterns</h3>

<h4 id="mvc">7.2.1 Model-View-Controller (MVC) Architecture</h4>

<p><strong>Purpose:</strong> Separate application into three interconnected components: Model (data and logic), View (presentation), and Controller (user interaction). This enables independent development, testing, and maintenance.</p>

<p><strong>Implementation in System:</strong></p>

<pre><code class="language-java">// MODEL: Contains data and business logic
public class Model {
    private List&lt;Post&gt; posts = new ArrayList&lt;&gt;();
    private SentimentAnalyzer sentimentAnalyzer;
    private List&lt;ModelListener&gt; listeners = new ArrayList&lt;&gt;();
    
    public void addPost(Post post) {
        // Business logic: analyze sentiment before adding
        Sentiment sentiment = sentimentAnalyzer.analyzeSentiment(post.getContent());
        post.setSentiment(sentiment);
        posts.add(post);
        
        // Notify all listeners of change
        notifyListeners();
    }
    
    private void notifyListeners() {
        for (ModelListener listener : listeners) {
            listener.modelChanged();  // Observer pattern callback
        }
    }
}

// VIEW: Displays data from Model
public class View extends JFrame implements ModelListener {
    private AdvancedAnalysisPanel analysisPanel;
    private CommentManagementPanel commentPanel;
    
    public View(Model model) {
        this.model = model;
        // Register as observer to be notified of changes
        model.addModelListener(this);
    }
    
    @Override
    public void modelChanged() {
        // React to data changes: update UI on EDT
        SwingUtilities.invokeLater(() -> {
            analysisPanel.refresh();
            commentPanel.refreshCommentTable();
        });
    }
}</code></pre>

<p><strong>Benefits:</strong> Separation of concerns (Model ‚â† View), testability (test Model without UI), multiple views (same Model can serve multiple Views), loose coupling.</p>

<h4 id="strategy">7.2.2 Strategy Pattern - Runtime Algorithm Selection</h4>

<p><strong>Purpose:</strong> Define a family of algorithms, encapsulate each one, and make them interchangeable. Strategy allows changing algorithms at runtime without changing client code.</p>

<p><strong>Application in System:</strong></p>

<pre><code class="language-java">// STRATEGY INTERFACE: Abstract algorithm definition
public interface SentimentAnalyzer {
    Sentiment analyzeSentiment(String text);
    String getModelName();
    void initialize();
    void shutdown();
}

// CONCRETE STRATEGY 1: Rule-based approach
public class EnhancedSentimentAnalyzer implements SentimentAnalyzer {
    private static final String[] POSITIVE_WORDS_EN = {...};
    private static final String[] NEGATIVE_WORDS_EN = {...};
    
    @Override
    public Sentiment analyzeSentiment(String text) {
        // Keyword matching strategy
        int positiveCount = countMatches(text, POSITIVE_WORDS_EN);
        int negativeCount = countMatches(text, NEGATIVE_WORDS_EN);
        return new Sentiment(positiveCount > negativeCount ? POSITIVE : NEGATIVE);
    }
}

// CONCRETE STRATEGY 2: ML-based approach (Python backend)
public class PythonSentimentAnalyzer implements SentimentAnalyzer {
    @Override
    public Sentiment analyzeSentiment(String text) {
        // Call Python ML service via HTTP
        return callPythonService(text);
    }
}

// CLIENT: Uses strategy via interface, not concrete class
public class Model {
    private SentimentAnalyzer strategy;  // Strategy reference
    
    public void setSentimentAnalyzer(SentimentAnalyzer analyzer) {
        // Switch algorithm at runtime
        if (this.strategy != null) {
            this.strategy.shutdown();
        }
        this.strategy = analyzer;
        this.strategy.initialize();
    }
    
    public void addPost(Post post) {
        // Use current strategy - client doesn't know which one
        Sentiment sentiment = strategy.analyzeSentiment(post.getContent());
        post.setSentiment(sentiment);
        posts.add(post);
        notifyListeners();
    }
}

// ADD NEW STRATEGY without changing existing code:
public class CustomSentimentAnalyzer implements SentimentAnalyzer {
    public Sentiment analyzeSentiment(String text) { 
        // Custom algorithm implementation
        return new Sentiment(...);
    }
}</code></pre>

<p><strong>Applications in System:</strong> Sentiment Analysis (multiple analyzers), Data Crawling (YouTubeCrawler vs MockDataCrawler), Analysis Modules (TimeSeriesSentimentModule vs SatisfactionAnalysisModule).</p>

<p><strong>Benefits:</strong> Runtime algorithm switching without modifying client code, easy to add new strategies, isolates algorithm details from client logic.</p>

<h4 id="factory-registry">7.2.3 Factory and Registry Pattern - Pluggable Architecture</h4>

<p><strong>Purpose:</strong> Factory Pattern creates objects without specifying exact classes. Registry Pattern maintains a registry of available implementations, enabling runtime discovery and plugin-like architecture.</p>

<p><strong>Implementation in System:</strong></p>

<pre><code class="language-java">// REGISTRY: Central location for available crawlers
public class CrawlerRegistry {
    // Singleton instance
    private static final CrawlerRegistry INSTANCE = new CrawlerRegistry();
    
    // Map of crawler factories: name ‚Üí create function
    private final Map&lt;String, CrawlerFactory&gt; crawlers = new LinkedHashMap&lt;&gt;();
    
    // FACTORY INTERFACE: Defines how to create crawlers
    @FunctionalInterface
    public interface CrawlerFactory {
        DataCrawler create();  // Creates a new crawler instance
    }
    
    public static CrawlerRegistry getInstance() { 
        return INSTANCE; 
    }
    
    // REGISTRATION: Add new crawler factory
    public void registerCrawler(String name, CrawlerFactory factory) {
        crawlers.put(name, factory);
    }
    
    // FACTORY METHOD: Create crawler by name
    public DataCrawler createCrawler(String crawlerName) {
        CrawlerFactory factory = crawlers.get(crawlerName);
        return factory != null ? factory.create() : null;
    }
}

// CLIENT: Uses registry to get crawlers without knowing their types
public class CrawlerManager {
    public static void initializeCrawlers() {
        CrawlerRegistry registry = CrawlerRegistry.getInstance();
        
        // Register YouTube crawler factory
        registry.registerCrawler("YOUTUBE", YouTubeCrawler::new);
        
        // Register Mock crawler factory
        registry.registerCrawler("MOCK", MockDataCrawler::new);
    }
}

// USAGE: Get crawler by name without creating directly
DataCrawler crawler = CrawlerRegistry.getInstance().createCrawler("YOUTUBE");
List&lt;Post&gt; results = crawler.crawlPosts(keywords, hashtags, limit);</code></pre>

<p><strong>Advantages:</strong> Plugin architecture (add crawlers without modifying existing code), runtime discovery (list available crawlers), decoupling (client doesn't know concrete classes), dynamic instantiation.</p>

<p><strong>Benefits:</strong> Plugin architecture, runtime discovery, decoupling, extensibility.</p>

<h4 id="observer">7.2.4 Observer Pattern - Reactive Updates</h4>

<p><strong>Purpose:</strong> Define a one-to-many relationship where when one object's state changes, all dependents are automatically notified and updated. This implements loose coupling between Subject and Observers.</p>

<p><strong>Implementation in System:</strong></p>

<pre><code class="language-java">// OBSERVER INTERFACE: What observers must implement
public interface ModelListener {
    void modelChanged();  // Called when Model state changes
}

// SUBJECT: Model that notifies observers
public class Model {
    private List&lt;Post&gt; posts = new ArrayList&lt;&gt;();
    // List of observers watching this model
    private List&lt;ModelListener&gt; listeners = new ArrayList&lt;&gt;();
    
    // ATTACH observer
    public void addModelListener(ModelListener listener) { 
        listeners.add(listener); 
    }
    
    // METHOD that changes state
    public void addPost(Post post) {
        Sentiment sentiment = sentimentAnalyzer.analyzeSentiment(post.getContent());
        post.setSentiment(sentiment);
        posts.add(post);
        
        // NOTIFY: When state changes, notify all observers
        notifyListeners();
    }
    
    // NOTIFY all observers
    private void notifyListeners() {
        for (ModelListener listener : listeners) {
            listener.modelChanged();  // Each observer reacts
        }
    }
}

// CONCRETE OBSERVER 1: View updates UI
public class View extends JFrame implements ModelListener {
    public View(Model model) {
        this.model = model;
        // REGISTER as observer
        model.addModelListener(this);
    }
    
    @Override
    public void modelChanged() {
        // REACT to notification: refresh UI
        SwingUtilities.invokeLater(() -> {
            analysisPanel.refresh();
            commentPanel.refreshCommentTable();
            statusLabel.setText("Updated");
        });
    }
}

// CONCRETE OBSERVER 2: Logger tracks changes
public class ModelChangeLogger implements ModelListener {
    @Override
    public void modelChanged() {
        // REACT to notification: log the event
        LOGGER.info("Model changed at " + LocalDateTime.now());
    }
}</code></pre>

<p><strong>Benefits:</strong> Loose coupling (Subject doesn't know observer details), dynamic subscriptions (add/remove observers at runtime), automatic synchronization (all observers notified together), event-driven design (reactive updates without polling).</p>

<h4 id="singleton">7.2.5 Singleton Pattern - Guaranteed Single Instance</h4>

<p><strong>Purpose:</strong> Ensure a class has only ONE instance and provide global access to it. Prevents multiple instances from causing state conflicts and resource wastage.</p>

<p><strong>Implementation in System:</strong></p>

<pre><code class="language-java">// SINGLETON: Private constructor prevents instantiation
public class CrawlerRegistry {
    // Single static instance created at class load time
    private static final CrawlerRegistry INSTANCE = new CrawlerRegistry();
    
    // Private constructor: prevents new CrawlerRegistry()
    private CrawlerRegistry() {}
    
    // Global access point: always returns same instance
    public static CrawlerRegistry getInstance() { 
        return INSTANCE; 
    }
    
    private final Map&lt;String, CrawlerFactory&gt; crawlers = new LinkedHashMap&lt;&gt;();
    
    public void registerCrawler(String name, CrawlerFactory factory) {
        crawlers.put(name, factory);
    }
}

// SINGLETON with initialization
public class DisasterManager {
    private static final DisasterManager INSTANCE = new DisasterManager();
    
    private DisasterManager() { 
        disasterTypes = new HashMap&lt;&gt;();
        // Initialize disaster types
        disasterTypes.put("EARTHQUAKE", new DisasterType("Earthquake", "Sudden ground movement"));
        disasterTypes.put("FLOOD", new DisasterType("Flood", "Water overflow"));
    }
    
    public static DisasterManager getInstance() { 
        return INSTANCE; 
    }
    
    public DisasterType getDisasterType(String key) {
        return disasterTypes.get(key);
    }
}

// USAGE: Always same instance
CrawlerRegistry registry1 = CrawlerRegistry.getInstance();
CrawlerRegistry registry2 = CrawlerRegistry.getInstance();
assert registry1 == registry2;  // True: same object
</code></pre>

<p><strong>Benefits:</strong> Global access point, prevents multiple instances, thread-safe (with static initialization), controlled state, resource efficiency.</p>

<h4 id="facade">7.2.6 Facade Pattern - Simplified Complex Operations</h4>

<p><strong>Purpose:</strong> Provide a unified, simplified interface to a complex subsystem. This hides implementation details, reduces coupling, and makes API easier to use.</p>

<p><strong>Implementation in System:</strong></p>

<pre><code class="language-java">// SUBSYSTEM 1: Database operations (complex)
public class DatabaseManager { /* 200+ lines of JDBC code */ }

// SUBSYSTEM 2: File I/O (complex)
public class DataPersistenceManager { /* Serialization logic */ }

// FACADE: Simplified interface hiding complexity
public class DatabaseLoader {
    // Simple public method hides all complexity
    public static void loadOurDatabase(Model model) {
        if (model == null) {
            throw new IllegalArgumentException("Model cannot be null");
        }
        
        // Internal details hidden from client:
        model.getPosts().clear();
        
        // Client doesn't know about these complex operations:
        loadFromDevUIDatabase(model);      // Hidden: reads from curated DB
        saveLoadedDataToUserDatabase(model); // Hidden: persists to user DB
    }
    
    // PRIVATE: Complex database reading logic hidden
    private static void loadFromDevUIDatabase(Model model) {
        DatabaseManager dbManager = new DatabaseManager();
        try (ResultSet rs = dbManager.queryPosts()) {
            while (rs.next()) {
                // Parse result, create Post object, add to model
                Post post = parsePost(rs);
                model.addPost(post);
            }
        }
    }
    
    // PRIVATE: Complex database writing logic hidden
    private static void saveLoadedDataToUserDatabase(Model model) {
        DatabaseManager userDb = new DatabaseManager("user_db.db");
        for (Post post : model.getPosts()) {
            userDb.savePost(post);  // Uses PreparedStatement, transactions, etc.
        }
    }
}

// ANOTHER FACADE: Crawler initialization
public class CrawlerManager {
    // Single method hides all initialization complexity
    public static void initializeCrawlers() {
        CrawlerRegistry registry = CrawlerRegistry.getInstance();
        
        // Register YouTube crawler with full configuration
        registry.registerCrawler(
            new CrawlerRegistry.CrawlerConfig(
                "YOUTUBE", "YouTube",
                "Crawl videos and comments from YouTube",
                YouTubeCrawler::new, true, true, true
            )
        );
        
        // Register Mock crawler
        registry.registerCrawler(
            new CrawlerRegistry.CrawlerConfig(
                "MOCK", "Sample/Mock Data",
                "Generate sample data for testing",
                MockDataCrawler::new, false, true, false
            )
        );
    }
}

// CLIENT: Simple usage without knowing complexity
DatabaseLoader.loadOurDatabase(model);  // Simple!
CrawlerManager.initializeCrawlers();     // Simple!
</code></pre>

<p><strong>Benefits:</strong> Reduced complexity for clients, cleaner API, hides subsystem details, easier to maintain and evolve subsystems independently.</p>

<h4 id="adapter">7.2.7 Adapter Pattern - Interface Compatibility</h4>

<p><strong>Purpose:</strong> Convert incompatible interfaces to compatible ones, allowing objects with different interfaces to work together. Acts as a bridge between two incompatible interfaces.</p>

<p><strong>Implementation in System:</strong></p>

<pre><code class="language-java">// SWING ADAPTER: Built-in adapter for window events
public class View extends JFrame {
    public View(Model model) {
        this.model = model;
        
        // WindowAdapter: implements WindowListener with empty methods
        // We only override methods we need
        addWindowListener(new java.awt.event.WindowAdapter() {
            @Override
            public void windowClosing(WindowEvent e) {
                // Adapt: Window closing event ‚Üí Model shutdown
                model.shutdown();
                PythonSentimentAnalyzer.stopPythonService();
                System.exit(0);
            }
            
            // Other methods inherited as empty: windowOpened, windowClosed, etc.
        });
    }
}

// CUSTOM ADAPTER: Adapt external HTML format to application interface
public class YouTubeCommentAdapter {
    private String rawJSON;  // From YouTube API
    
    public YouTubeCommentAdapter(String rawJSON) {
        this.rawJSON = rawJSON;
    }
    
    // ADAPTER METHOD: Convert YouTube JSON ‚Üí Application Comment
    public Comment adaptToComment() {
        // Parse YouTube JSON
        JSONObject json = new JSONObject(rawJSON);
        
        // Extract fields from YouTube format
        String author = json.getJSONObject("authorDetails")
                           .getString("displayName");
        String content = json.getString("textDisplay");
        LocalDateTime createdAt = LocalDateTime.parse(
            json.getString("publishedAt")
        );
        
        // Create application domain object
        return new Comment(
            UUID.randomUUID().toString(),
            author,
            content,
            createdAt,
            Sentiment.NEUTRAL
        );
    }
}

// USAGE: Adapt external format to internal format
YouTubeCommentAdapter adapter = new YouTubeCommentAdapter(youtubeJson);
Comment appComment = adapter.adaptToComment();  // Convert!
model.addCommentToPost(post, appComment);      // Now it's compatible
</code></pre>

<p><strong>Benefits:</strong> Integrates incompatible classes, reuses existing code without modification, bridges different interfaces, supports legacy code integration.</p>

<h4 id="builder">7.2.8 Builder Pattern - Fluent Object Construction</h4>

<p><strong>Purpose:</strong> Construct complex objects step by step using a fluent API, avoiding telescoping constructors and making configuration explicit and readable.</p>

<p><strong>Implementation in System:</strong></p>

<pre><code class="language-java">// BUILDER CLASS: Constructs complex ChartPanel with configuration
public class InteractiveChartUtility {
    // BUILDER FACTORY: Create builder instance
    public static ChartPanelBuilder builder(ChartPanel chartPanel) {
        return new ChartPanelBuilder(chartPanel);
    }

    public static class ChartPanelBuilder {
        private ChartPanel chartPanel;
        
        // CONFIGURATION FIELDS: Build options
        private boolean domainZoom = true;
        private boolean rangeZoom = true;
        private boolean mouseWheel = true;
        private boolean tooltips = true;

        public ChartPanelBuilder(ChartPanel chartPanel) {
            this.chartPanel = chartPanel;
        }

        // BUILDER METHODS: Fluent API (return this for chaining)
        public ChartPanelBuilder domainZoomable(boolean enabled) {
            this.domainZoom = enabled;
            return this;  // Enable fluent chaining
        }

        public ChartPanelBuilder rangeZoomable(boolean enabled) {
            this.rangeZoom = enabled;
            return this;  // Return builder for next method
        }

        public ChartPanelBuilder mouseWheelEnabled(boolean enabled) {
            this.mouseWheel = enabled;
            return this;
        }

        public ChartPanelBuilder tooltipsEnabled(boolean enabled) {
            this.tooltips = enabled;
            return this;
        }

        // BUILD METHOD: Apply all configurations and return result
        public ChartPanel build() {
            // Apply all accumulated configurations
            chartPanel.setDomainZoomable(domainZoom);
            chartPanel.setRangeZoomable(rangeZoom);
            chartPanel.setMouseWheelEnabled(mouseWheel);
            chartPanel.setDisplayToolTips(tooltips);
            return chartPanel;  // Return configured object
        }
    }
}

// USAGE: Readable, step-by-step configuration
ChartPanel interactive = InteractiveChartUtility.builder(originalChart)
    .domainZoomable(true)        // Configure domain zoom
    .rangeZoomable(true)         // Configure range zoom
    .mouseWheelEnabled(true)     // Configure mouse wheel
    .tooltipsEnabled(true)       // Configure tooltips
    .build();                    // Create and return result

// WITHOUT BUILDER (telescoping constructor):
// ChartPanel p = new ChartPanel(chart, true, true, true, true);  // Unclear!

// WITH BUILDER: Self-documenting and flexible
ChartPanel p = InteractiveChartUtility.builder(chart)
    .mouseWheelEnabled(true)      // Only enable what we need
    .tooltipsEnabled(false)
    .build();</code></pre>

<p><strong>Benefits:</strong> Improved readability, optional parameters, immutability, flexible configuration, self-documenting code.</p>

<h3 id="advanced-java">7.3 Advanced Java Techniques</h3>

<h4 id="generics">7.3.1 Generics and Type-Safe Collections</h4>

<p><strong>Purpose:</strong> Use type parameters to write generic classes and methods, providing compile-time type safety and eliminating casting. This catches type errors early and makes code self-documenting.</p>

<p><strong>Application in System:</strong></p>

<pre><code class="language-java">// TYPE-SAFE COLLECTIONS: Compiler checks types at compile time
List&lt;Comment&gt; comments = new ArrayList&lt;&gt;();
comments.add(new Comment(...));      // Type check: OK, Comment
// comments.add("invalid");          // Type check: ERROR, String ‚â† Comment
Comment c = comments.get(0);         // No casting needed: Comment, not Object

Map&lt;String, Integer&gt; sentimentCounts = new HashMap&lt;&gt;();
sentimentCounts.put("POSITIVE", 42);  // Type check: String key, Integer value
// sentimentCounts.put(123, "high");  // Type check: ERROR

// GENERIC CLASSES: Use type parameters for flexibility
public class TimeSeriesSentimentModule implements AnalysisModule {
    // Map&lt;Category, Map&lt;Time, List&lt;Sentiment&gt;&gt;&gt;: Type-safe nested structure
    private Map&lt;ReliefItem.Category, Map&lt;LocalDateTime, List&lt;Sentiment&gt;&gt;&gt; timeSeriesData;
    
    public void addSentiment(ReliefItem.Category category, 
                            LocalDateTime time, 
                            Sentiment sentiment) {
        timeSeriesData.computeIfAbsent(category, k -&gt; new HashMap&lt;&gt;())
                      .computeIfAbsent(time, k -&gt; new ArrayList&lt;&gt;())
                      .add(sentiment);
    }
}

// GENERIC METHODS: Type-safe method signatures
public &lt;T extends Sentiment&gt; List&lt;T&gt; filterBySentiment(List&lt;T&gt; items) {
    return items.stream().filter(item -&gt; item.isPositive()).collect(...);
}
</code></pre>

<p><strong>Benefits:</strong> Compile-time type safety, no casting, self-documenting, prevents runtime ClassCastException errors.</p>

<h4 id="streams">7.3.2 Streams API and Functional Programming</h4>

<p><strong>Purpose:</strong> Process collections using functional-style transformations (map, filter, reduce) instead of imperative loops. Streams enable concise, declarative data processing with optional parallelization.</p>

<p><strong>Application in System:</strong></p>

<pre><code class="language-java">// REAL SYSTEM EXAMPLE: SatisfactionAnalysisModule.calculateSentimentStats()
private Map&lt;String, Object&gt; calculateSentimentStats(List&lt;Sentiment&gt; sentiments,
                                                      ReliefItem.Category category) {
    Map&lt;String, Object&gt; stats = new LinkedHashMap&lt;&gt;();
    
    // FILTER + COUNT: Count positive, negative, neutral sentiments
    long positiveCount = sentiments.stream()
        .filter(Sentiment::isPositive)      // FILTER: keep only positive
        .count();                           // COUNT: how many
    
    long negativeCount = sentiments.stream()
        .filter(Sentiment::isNegative)
        .count();
    
    long neutralCount = sentiments.stream()
        .filter(Sentiment::isNeutral)
        .count();
    
    // MAP + SUM: Calculate average confidence
    double totalConfidence = sentiments.stream()
        .mapToDouble(Sentiment::getConfidence)  // MAP: extract confidence scores
        .sum();                                 // SUM: total confidence
    double avgConfidence = totalConfidence / sentiments.size();
    
    // CALCULATE PERCENTAGES
    double positivePercentage = (double) positiveCount / sentiments.size() * 100;
    double negativePercentage = (double) negativeCount / sentiments.size() * 100;
    
    // BUILD RESULT
    stats.put("category", category.getDisplayName());
    stats.put("positive_count", positiveCount);
    stats.put("negative_count", negativeCount);
    stats.put("neutral_count", neutralCount);
    stats.put("positive_percentage", String.format("%.2f%%", positivePercentage));
    stats.put("negative_percentage", String.format("%.2f%%", negativePercentage));
    stats.put("average_confidence", String.format("%.2f", avgConfidence));
    
    return stats;  // Returns map with aggregated sentiment statistics
}
</code></pre>

<p><strong>Benefits:</strong> Concise, readable data processing, functional style (declarative not imperative), enables parallelization (parallelStream()), composable operations.</p>

<h4 id="lambda">7.3.3 Lambda Expressions and Method References</h4>

<p><strong>Purpose:</strong> Write concise anonymous functions (lambdas) and reference existing methods (method references) to enable functional programming and reduce boilerplate code.</p>

<p><strong>Application in System:</strong></p>

<pre><code class="language-java">// EXAMPLE 1: LAMBDA in Streams - Filter with inline predicate
public List&lt;String&gt; getCrawlerDisplayNames() {
    // LAMBDA: c -> c.displayName
    // METHOD REFERENCE: .toList() (equivalent to .collect(Collectors.toList()))
    return crawlerConfigs.values().stream()
        .map(c -> c.displayName)    // LAMBDA: extract displayName from each config
        .toList();                  // COLLECT results into list
}

// EXAMPLE 2: METHOD REFERENCE for Sorting
comments.sort(Comparator.comparing(Comment::getCreatedAt));
// Method reference: Comment::getCreatedAt (instead of c -> c.getCreatedAt())

// EXAMPLE 3: LAMBDA for Factory Pattern
CrawlerRegistry registry = CrawlerRegistry.getInstance();
registry.registerCrawler(
    new CrawlerRegistry.CrawlerConfig(
        "YOUTUBE",
        "YouTube",
        "Crawl videos and comments from YouTube",
        YouTubeCrawler::new,        // CONSTRUCTOR REFERENCE: equivalent to () -> new YouTubeCrawler()
        true, true, true
    )
);

// EXAMPLE 4: LAMBDA in Event Handlers
SwingUtilities.invokeLater(() -> {
    analysisPanel.refresh();         // LAMBDA: Runnable implementation
    commentPanel.refreshCommentTable();
});

// EXAMPLE 5: LAMBDA in Streams - Complex filtering
long positiveCount = sentiments.stream()
    .filter(s -> s.getConfidence() > 0.7 && s.isPositive())  // COMPLEX LAMBDA
    .count();

// EXAMPLE 6: Functional Stream Processing with Comments
List&lt;String&gt; positiveAuthors = comments.stream()
    .filter(c -> c.getSentiment().isPositive())     // LAMBDA: filter predicate
    .sorted((c1, c2) -> c2.getCreatedAt()           // LAMBDA: comparator
                         .compareTo(c1.getCreatedAt()))
    .map(Comment::getAuthor)                        // METHOD REFERENCE: getter
    .collect(Collectors.toList());                  // COLLECT: gather results
</code></pre>

<p><strong>Benefits:</strong> Concise syntax (vs anonymous classes), functional programming support, enables higher-order functions, factory implementations without boilerplate.</p>

<h4 id="dependency-injection">7.3.4 Dependency Injection</h4>

<p><strong>Purpose:</strong> Pass dependencies to objects through constructors or setters instead of objects creating them internally. This decouples objects, simplifies testing, and enables runtime configuration.</p>

<p><strong>Application in System:</strong></p>

<pre><code class="language-java">// CONSTRUCTOR INJECTION: Pass dependencies via constructor
public class CrawlControlPanel extends JPanel {
    private Model model;  // Injected dependency
    
    // INJECT via constructor, not new()
    public CrawlControlPanel(Model model) {
        this.model = model;  // Store injected dependency
        
        // Use injected dependency
        this.model.addModelListener(this);
    }
}

// ANOTHER PANEL: Also receives Model dependency
public class CommentManagementPanel extends JPanel {
    private Model model;
    
    public CommentManagementPanel(Model model) {
        this.model = model;
        model.addModelListener(this);
    }
}

// VIEW: Injects Model to all panels
public class View extends JFrame {
    public View(Model model) {
        // INJECT Model to each panel
        AdvancedAnalysisPanel analysisPanel = new AdvancedAnalysisPanel(model);
        CommentManagementPanel commentPanel = new CommentManagementPanel(model);
        CrawlControlPanel crawlPanel = new CrawlControlPanel(model);
        DataCollectionPanel dataPanel = new DataCollectionPanel(model);
        
        // All panels share same Model instance
        this.add(analysisPanel);
        this.add(commentPanel);
        this.add(crawlPanel);
        this.add(dataPanel);
    }
}

// APPLICATION ENTRY POINT: Set up dependencies once
public class HumanitarianLogisticsApp {
    public static void main(String[] args) {
        try {
            // Initialize singletons
            DisasterManager disasterManager = DisasterManager.getInstance();
            
            // Create model (core business logic)
            Model model = new Model();
            
            // INJECT sentiment analyzer (strategy)
            PythonSentimentAnalyzer analyzer = new PythonSentimentAnalyzer(
                "http://localhost:5001"
            );
            model.setSentimentAnalyzer(analyzer);
            
            // Load persisted data
            DataPersistenceManager.loadData(model);
            
            // CREATE view (which injects Model to all panels)
            javax.swing.SwingUtilities.invokeLater(() -> {
                new View(model);
            });
            
            System.out.println("Application started successfully");
        } catch (Exception e) {
            System.err.println("Error starting application: " + e.getMessage());
            e.printStackTrace();
        }
    }
}

// BENEFITS of DI:
// ‚úì Easy to test: new Panel(mockModel, mockAnalyzer)
// ‚úì Runtime configuration: swap implementations
// ‚úì Loose coupling: Panel depends on interface, not concrete class
// ‚úì Clear dependencies: visible in constructor signature
</code></pre>

<p><strong>Benefits:</strong> Testability (easy to mock), loose coupling, runtime configuration, clear dependencies, flexibility.</p>

<h4 id="try-with-resources">7.3.5 Try-with-Resources for Automatic Resource Management</h4>

<p><strong>Purpose:</strong> Automatically close resources (files, connections, streams) without explicit cleanup code. This prevents resource leaks and makes code safer and cleaner.</p>

<p><strong>Application in System:</strong></p>

<pre><code class="language-java">// FILE I/O: Automatic stream closing
try (ObjectOutputStream oos = new ObjectOutputStream(
         new FileOutputStream("data.ser"))) {
    // RESOURCE OPENED: oos is auto-closeable
    oos.writeObject(posts);  // Serialize data
    // RESOURCE CLOSED: automatically after block, even if exception
} catch (IOException e) { 
    e.printStackTrace(); 
}
// oos.close() called automatically!

// DATABASE: Multiple auto-closeable resources
try (Connection conn = DriverManager.getConnection(dbUrl);
     Statement stmt = conn.createStatement();
     ResultSet rs = stmt.executeQuery("SELECT * FROM comments")) {
    // ALL resources (conn, stmt, rs) auto-closeable
    
    while (rs.next()) {
        String content = rs.getString("content");
        int postId = rs.getInt("post_id");
        // Process result
    }
}
// ALL resources closed in reverse order (rs, stmt, conn) automatically!

// REAL SYSTEM USAGE: DatabaseManager (multiple resources)
public List&lt;Comment&gt; getAllCommentsFromDatabase() {
    try (Connection conn = getConnection();
         Statement stmt = conn.createStatement();
         ResultSet rs = stmt.executeQuery(
             "SELECT id, author, content, created_at, sentiment FROM comments")) {
        
        List&lt;Comment&gt; comments = new ArrayList&lt;&gt;();
        while (rs.next()) {
            Comment comment = parseComment(rs);
            comments.add(comment);
        }
        return comments;
    } catch (SQLException e) {
        LOGGER.log(Level.SEVERE, "Failed to load comments", e);
        return new ArrayList&lt;&gt;();
    }
}
// All resources (rs, stmt, conn) closed automatically in reverse order!

// WITHOUT try-with-resources (BAD):
ObjectOutputStream oos = null;
try {
    oos = new ObjectOutputStream(new FileOutputStream("data.ser"));
    oos.writeObject(posts);
} catch (IOException e) {
    e.printStackTrace();
} finally {
    if (oos != null) {
        try {
            oos.close();  // MANUAL cleanup (easy to forget!)
        } catch (IOException e) {
            // Handle close exception
        }
    }
}</code></pre>

<p><strong>Benefits:</strong> Automatic resource cleanup, prevents resource leaks, exception-safe (closes even on error), cleaner code (no finally blocks), supports multiple resources.</p>

<h3 id="summary">7.4 Summary of OOP Application</h3>

<table>
<thead>
<tr><th><strong>Category</strong></th><th><strong>Techniques</strong></th><th><strong>Count</strong></th><th><strong>Status</strong></th></tr>
</thead>
<tbody>
<tr><td><strong>Fundamental Concepts</strong></td><td>Encapsulation, Abstraction, Inheritance, Polymorphism, Interfaces, Abstract Classes, Composition</td><td>7/7</td><td>‚úÖ Complete</td></tr>
<tr><td><strong>Design Patterns</strong></td><td>MVC, Strategy, Factory &amp; Registry, Observer, Singleton, Facade, Adapter, Builder</td><td>8/8</td><td>‚úÖ Complete</td></tr>
<tr><td><strong>Advanced Techniques</strong></td><td>Generics, Streams API, Lambda Expressions, Dependency Injection, Try-with-Resources</td><td>5/5</td><td>‚úÖ Complete</td></tr>
<tr><td><strong>Code Quality</strong></td><td>30+ classes, 7 packages, 5000+ lines, Zero circular dependencies</td><td>-</td><td>‚úÖ Excellent</td></tr>
</tbody>
</table>

<p><strong>Architecture Strengths:</strong> Separation of concerns, extensibility, testability, maintainability, performance, type safety, and resource safety.</p>


<h2 id="technology-report">8. Technology Report</h2>

<p>Modern, multi-layered stack combining desktop Java with Python ML backend. Java provides type safety and GUI frameworks; Python dominates data science for NLP. System uses lightweight HTTP-based crawling rather than browser automation for efficiency.</p>

<h3 id="core-technologies">8.1 Core Technologies</h3>

<p><strong>Java 11+</strong>: Enterprise-grade statically-typed language providing compile-time type checking that catches errors before runtime. Swing framework offers native look-and-feel without external dependencies. HttpClient (built-in since Java 11) provides modern async HTTP with connection pooling and automatic timeout management.</p>

<p><strong>Benefits:</strong> Type safety prevents 80% of runtime errors in dynamically-typed languages. Mature ecosystem (30+ years), massive standard library (50,000+ classes), WORA (Write Once Run Anywhere) across Windows/Mac/Linux without recompilation. Swing's native integration means no external GUI dependencies - reduces installation size and compatibility issues.</p>

<p><strong>Maven 3.9.11</strong>: Declarative project structure with pom.xml (XML-based configuration) defining all dependencies, versions, build plugins, and JAR packaging strategy.</p>

<p><strong>Benefits:</strong> Enforces consistent directory layout across 1000s of Java projects (src/main/java, src/test/java, target/). Automatic transitive dependency management (declaring Gson automatically includes underlying libraries). Single command <code>mvn clean package</code> produces fat JAR with all dependencies, eliminating classpath hell. Version conflict resolution prevents library version mismatches that cause runtime failures.</p>

<p><strong>Python 3.12.7</strong>: Dynamically-typed language optimized for data science and machine learning. Runs separately as Flask REST API service on port 5001.</p>

<p><strong>Benefits:</strong> Dominates NLP ecosystem - Hugging Face Transformers, PyTorch, scikit-learn have better documentation and community support in Python vs Java equivalents. Fast prototyping without compile step. Enormous ML library collection. Java calling Python via REST API maintains language separation-of-concerns without tight coupling.</p>

<h3 id="ui-and-visualization">8.2 UI and Visualization</h3>

<p><strong>Swing (Built-in, since Java 1.2)</strong>: Platform-native UI framework providing JFrame, JPanel, JTable for building desktop interfaces. No external dependencies required.</p>

<p><strong>Benefits:</strong> Zero external UI dependencies - runs on any Java 11+ installation without additional packages. Native look-and-feel matches Windows/Mac/Linux native UI conventions (unlike web frameworks that look identical everywhere). Event-driven architecture (ActionListener, MouseListener) naturally integrates with MVC Observer pattern. Lightweight compared to web servers.</p>

<p><strong>JFreeChart 1.5.3</strong>: Open-source charting library providing CategoryPlot (bar charts for relief item distributions), PieChart (satisfaction percentages), TimeSeries (sentiment trends over time). Interactive MouseListener integration enables drill-down analysis clicking on chart regions.</p>

<p><strong>Benefits:</strong> 20+ chart types available - bar, pie, line, scatter, bubble, etc. Interactive rendering with zoom/pan/tooltip support. Direct integration with Swing components (no separate web rendering required). Reusable ChartPanelBuilder utility pattern eliminates code duplication across AnalysisPanel, SatisfactionPanel, TimeSeriesPanel. Lightweight alternative to D3.js/Plotly that would require web server.</p>

<h3 id="data-storage">8.3 Data Storage</h3>

<p><strong>SQLite 3.44.0.0</strong>: Embedded relational SQL database (no external server required), ACID-compliant transactions, supports 280TB maximum database size per file. Uses separate database files: <code>humanitarian_logistics_user.db</code> (user-crawled posts/comments), <code>humanitarian_logistics_curated.db</code> (31 pre-loaded disaster scenario posts for testing).</p>

<p><strong>Benefits:</strong> Zero-configuration database deployment - no PostgreSQL/MySQL installation, network setup, or admin credentials needed. Single SQLite file ships with application. Atomic transactions (all-or-nothing) guarantee data consistency. Lightweight footprint (3MB compiled binary) vs PostgreSQL (50MB+). Perfect for single-machine desktop applications - eliminates network latency. ACID compliance ensures NO data loss on power failure or crash.</p>

<p><strong>Schema Design</strong>: Normalized schema with 4 primary tables (posts, comments, disaster_types, relief_items) using integer primary keys for fast lookups, foreign key constraints for referential integrity, created_at/updated_at timestamps for audit trails.</p>

<p><strong>DatabaseManager</strong>: JDBC abstraction layer providing prepared statements (parameterized queries preventing SQL injection attacks), try-with-resources blocks ensuring automatic connection/statement cleanup preventing resource leaks. Methods: loadAllPosts(), savePost(), getCommentsByPostId(), deleteExpiredRecords().</p>

<p><strong>Benefits:</strong> Prepared statements prevent 100% of SQL injection attacks (e.g., user input "'; DROP TABLE posts;--" is treated as literal string, not executed). Try-with-resources auto-closes connections even on exceptions, preventing connection leaks that would exhaust database resources. Abstraction layer (DataPersistenceManager) uses Adapter pattern - switching to PostgreSQL requires only changing JDBC driver URL and one implementation class, zero changes to Model/Analysis/UI code.</p>

<p><strong>DataPersistenceManager (Facade Pattern)</strong>: Single interface hiding JDBC complexity, enabling technology migration without breaking client code. Current SQLite implementation sufficient for 100s-1000s of posts. For scaling to 100,000+ posts, replace with PostgreSQL without touching application logic - demonstrating real Facade pattern benefit.</p>

<p><strong>Database Schema Overview</strong>: The application maintains 4 primary tables in SQLite database supporting full post-comment hierarchy with disaster metadata:</p>

<table>
<thead>
<tr>
<th><strong>Table Name</strong></th>
<th><strong>Primary Purpose</strong></th>
<th><strong>Key Columns</strong></th>
<th><strong>Relationships</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>posts</strong></td>
<td>Store YouTube posts and user-added posts</td>
<td>postId (PK), videoId, title, content, author, createdAt, disasterId (FK)</td>
<td>Foreign key to disasters(disasterId), One-to-many with comments</td>
</tr>
<tr>
<td><strong>comments</strong></td>
<td>Store comment thread data for each post</td>
<td>commentId (PK), postId (FK), author, text, likes, timestamp, parentCommentId (FK)</td>
<td>Foreign key to posts(postId), Self-referential for nested replies</td>
</tr>
<tr>
<td><strong>disaster_types</strong></td>
<td>Store custom disaster categories</td>
<td>disasterId (PK), type [EARTHQUAKE/FLOOD/CYCLONE], description, region</td>
<td>One-to-many with posts(disasterId)</td>
</tr>
<tr>
<td><strong>relief_items</strong></td>
<td>Store relief categories extracted from posts</td>
<td>itemId (PK), postId (FK), category [CASH/MEDICAL/SHELTER/FOOD], keywords, confidence</td>
<td>Foreign key to posts(postId), Indexed for fast category lookups</td>
</tr>
</tbody>
</table>

<p><strong>Schema Design Principles</strong>:</p>
<ul>
<li><strong>Normalization</strong>: Third Normal Form (3NF) prevents data duplication. disaster_types stored once and referenced via foreign key from 100s of posts, not repeated in each post row.</li>
<li><strong>Referential Integrity</strong>: Foreign key constraints (disasterId in posts ‚Üí disasterId in disaster_types) prevent orphaned records. Deleting disaster type automatically cascades or prevents deletion if posts reference it.</li>
<li><strong>Indexing Strategy</strong>: Composite indexes on (postId, commentId) for fast comment retrieval (avoiding full table scans). Index on disasterId for filtering posts by disaster type. Index on createdAt for chronological queries (temporal sentiment tracking, Problem 2).</li>
<li><strong>Hierarchical Comments</strong>: parentCommentId column enables nested reply structure. NULL parentCommentId = top-level comment; non-NULL = reply to specific comment. Enables recursive traversal of comment threads.</li>
<li><strong>Audit Trail</strong>: createdAt and updatedAt timestamps on all tables enable temporal analysis. Track when posts were added, when sentiment analysis occurred, data freshness.</li>
</ul>

<p><strong>SQL Schema Initialization</strong>: DatabaseManager.initializeDatabase() creates tables on first run:</p>

<pre><code class="language-sql">-- Posts table: YouTube videos + user additions
CREATE TABLE IF NOT EXISTS posts (
    postId INTEGER PRIMARY KEY AUTOINCREMENT,
    videoId TEXT UNIQUE,
    title TEXT NOT NULL,
    content TEXT,
    author TEXT,
    likes INTEGER DEFAULT 0,
    views INTEGER DEFAULT 0,
    disasterId INTEGER NOT NULL,
    createdAt DATETIME DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (disasterId) REFERENCES disaster_types(disasterId)
        ON DELETE RESTRICT ON UPDATE CASCADE
);

-- Comments table: Threaded comment structure
CREATE TABLE IF NOT EXISTS comments (
    commentId INTEGER PRIMARY KEY AUTOINCREMENT,
    postId INTEGER NOT NULL,
    author TEXT NOT NULL,
    text TEXT NOT NULL,
    likes INTEGER DEFAULT 0,
    timestamp DATETIME,
    parentCommentId INTEGER,  -- NULL for top-level, else refers to other comments
    FOREIGN KEY (postId) REFERENCES posts(postId)
        ON DELETE CASCADE ON UPDATE CASCADE,
    FOREIGN KEY (parentCommentId) REFERENCES comments(commentId)
        ON DELETE CASCADE ON UPDATE CASCADE
);

-- Disaster types: Custom classification
CREATE TABLE IF NOT EXISTS disaster_types (
    disasterId INTEGER PRIMARY KEY AUTOINCREMENT,
    type TEXT NOT NULL UNIQUE,  -- EARTHQUAKE, FLOOD, CYCLONE, etc.
    description TEXT,
    region TEXT,
    createdAt DATETIME DEFAULT CURRENT_TIMESTAMP
);

-- Relief items: Categories extracted via ML
CREATE TABLE IF NOT EXISTS relief_items (
    itemId INTEGER PRIMARY KEY AUTOINCREMENT,
    postId INTEGER NOT NULL,
    category TEXT NOT NULL,  -- CASH, MEDICAL, SHELTER, FOOD, TRANSPORTATION
    keywords TEXT,
    confidence REAL,  -- 0.0-1.0 from BART model
    extractedAt DATETIME DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (postId) REFERENCES posts(postId)
        ON DELETE CASCADE ON UPDATE CASCADE
);

-- Indexes for query performance
CREATE INDEX IF NOT EXISTS idx_posts_disasterId ON posts(disasterId);
CREATE INDEX IF NOT EXISTS idx_posts_createdAt ON posts(createdAt);
CREATE INDEX IF NOT EXISTS idx_comments_postId ON comments(postId);
CREATE INDEX IF NOT EXISTS idx_comments_parentId ON comments(parentCommentId);
CREATE INDEX IF NOT EXISTS idx_relief_postId ON relief_items(postId);
CREATE INDEX IF NOT EXISTS idx_relief_category ON relief_items(category);
</code></pre>

<p><strong>Data Flow Example</strong>: User crawls YouTube video ‚Üí YouTubeCrawler extracts posts/comments ‚Üí DatabaseManager.savePost() executes prepared statement INSERT ‚Üí SQLite enforces foreign key constraint (disasterId must exist in disaster_types table) ‚Üí Comment hierarchy stored with parentCommentId linking replies to parents ‚Üí Upon "Analyze All Posts" click, BatchAnalysisModule reads posts via SELECT * FROM posts WHERE disasterId = ? (uses index), sends text to Python API for sentiment, stores results back to sentiment column via UPDATE statement.</p>

<p><strong>Migration Path to PostgreSQL</strong>: Schema SQL is vendor-neutral. To migrate: (1) Install PostgreSQL, (2) Run same DDL statements (AUTOINCREMENT ‚Üí SERIAL, DATETIME ‚Üí TIMESTAMP), (3) Update JDBC URL in DataPersistenceManager from "jdbc:sqlite:data/humanitarian_logistics_user.db" to "jdbc:postgresql://localhost:5432/humanitarian_db", (4) Add PostgreSQL driver to pom.xml, (5) Zero code changes in Model/Analysis/UI layer thanks to Facade pattern abstraction.</p>

<p><strong>Disaster Types Supported</strong>: The application initializes with 5 primary disaster types stored in DisasterManager (Singleton pattern). Each type has configurable aliases for flexible keyword matching:</p>

<table>
<thead>
<tr>
<th><strong>Disaster Type</strong></th>
<th><strong>Aliases</strong></th>
<th><strong>Region/Context</strong></th>
<th><strong>Typical Posts Focus</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>yagi</strong></td>
<td>Âè∞È¢® (typhoon), Yagi, tropical cyclone</td>
<td>Southeast Asia, Philippines, Vietnam</td>
<td>Wind damage, flooding from storm surge, evacuation coordination, rescue operations</td>
</tr>
<tr>
<td><strong>koto</strong></td>
<td>Âè∞È¢®, Koto, typhoon storm</td>
<td>Asia-Pacific region</td>
<td>Typhoon preparedness, post-storm recovery, agricultural impact, shelter needs</td>
</tr>
<tr>
<td><strong>bualo</strong></td>
<td>Bualoi, tropical storm</td>
<td>Coastal Southeast Asia</td>
<td>Flood response, water access issues, medical supply distribution</td>
</tr>
<tr>
<td><strong>matmo</strong></td>
<td>Matmo, typhoon, extreme weather</td>
<td>Taiwan, Japan region</td>
<td>Infrastructure damage, power restoration, food/water distribution</td>
</tr>
<tr>
<td><strong>fung-wong</strong></td>
<td>FUNG-WONG, Noru, typhoon</td>
<td>East Asia</td>
<td>Multi-country impact, cross-border aid coordination, longterm recovery</td>
</tr>
</tbody>
</table>

<p><strong>Relief Categories Supported</strong>: The application tracks 5 relief item categories extracted via BART-Large-MNLI ML model or keyword-based classification. Each category represents a distinct humanitarian assistance type:</p>

<table>
<thead>
<tr>
<th><strong>Category</strong></th>
<th><strong>Examples</strong></th>
<th><strong>Typical Beneficiary Feedback</strong></th>
<th><strong>Analysis Focus (Problem 1)</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>CASH</strong></td>
<td>Cash assistance, conditional cash transfers, cash-for-work programs</td>
<td>Direct aid effectiveness, purchasing power in local markets, dignity/autonomy</td>
<td>Satisfaction trends: "Cash helped us buy food locally" vs complaint "Money arrives too late"</td>
</tr>
<tr>
<td><strong>MEDICAL</strong></td>
<td>Medical supplies, vaccines, antibiotics, first aid, trauma care, mental health support</td>
<td>Healthcare access, medication quality, treatment outcomes, preventive care satisfaction</td>
<td>Sentiment analysis: Medical supply effectiveness, healthcare worker availability, patient outcomes</td>
</tr>
<tr>
<td><strong>SHELTER</strong></td>
<td>Tents, temporary housing, plastic sheeting, building materials, housing repairs</td>
<td>Living conditions, safety, privacy, permanence of solution, weatherproofing effectiveness</td>
<td>Satisfaction metrics: Shelter quality vs speed of deployment, temporary vs permanent solutions</td>
</tr>
<tr>
<td><strong>FOOD</strong></td>
<td>Food packages, rice, cooking supplies, water, nutritional assistance, school meals</td>
<td>Food security, cultural appropriateness, food quality, dietary diversity, sufficient portions</td>
<td>Sentiment tracking: Food sufficiency, taste/cultural fit, distribution fairness across groups</td>
</tr>
<tr>
<td><strong>TRANSPORTATION</strong></td>
<td>Ambulances, evacuation vehicles, fuel for transport, logistics coordination</td>
<td>Evacuation speed, medical transport effectiveness, supply distribution reach, accessibility</td>
<td>Temporal analysis: Transportation availability during acute phase vs recovery phase</td>
</tr>
</tbody>
</table>

<p><strong>Relief Categories Extensibility</strong>: Although the application currently operates with 5 fixed relief categories, the architecture enables easy expansion for future needs without breaking existing code. Relief items are stored with (postId, category, keywords, confidence) in database, making new categories trivially addable:

<ul>
<li><strong>Database-level expansion</strong>: New categories can be added by inserting rows into relief_items table with new category values. Existing analysis queries dynamically discover categories via SELECT DISTINCT category - no hardcoded category lists in code.</li>
<li><strong>Code-level expansion</strong>: For new analysis types (e.g., tracking EDUCATION or LIVELIHOOD aid), extend ReliefItem.Category enum and update PythonCategoryClassifier keywords. Analysis modules read categories dynamically from Model state - zero impact on existing CASH/MEDICAL/SHELTER/FOOD/TRANSPORTATION logic.</li>
<li><strong>UI-level expansion</strong>: Analysis panel dropdowns populate from Model.getAvailableCategories() - automatically includes new categories without UI recompilation.</li>
<li><strong>No schema redesign needed</strong>: relief_items table structure unchanged - simply add new (postId, category, keywords, confidence) rows for new aid types.</li>
</ul>

This extensibility follows the Open/Closed Principle - system open for extension (adding categories) but closed for modification (existing 5 categories work unchanged). Migration to PostgreSQL preserves this capability automatically.</p>

<p><strong>Customization Capability - Adding New Disaster Types</strong>: The application architecture supports dynamic disaster type expansion without code modification. In DisasterManager (lines 1-50 of model/DisasterManager.java), the constructor initializes disasters:

<pre><code class="language-java">public DisasterManager() {
    // Initialize default disasters with aliases
    addDisaster(new DisasterType("yagi", "Âè∞È¢®,Yagi,tropical cyclone"));
    addDisaster(new DisasterType("koto", "Âè∞È¢®,Koto,typhoon storm"));
    addDisaster(new DisasterType("bualo", "Bualoi,tropical storm"));
    addDisaster(new DisasterType("matmo", "Matmo,typhoon,extreme weather"));
    addDisaster(new DisasterType("fung-wong", "FUNG-WONG,Noru,typhoon"));
    
    // Future expansion: Simply add more disasters here, OR
    // Load from external source: loadDisastersFromFile("disasters.dat");
}
</code></pre>

To add new disaster types (e.g., earthquakes, floods): Add new lines in constructor OR modify disasters.dat file (Java serialized object containing DisasterType list). Data Persistence Manager loads disasters.dat on startup - changes take effect immediately without code recompilation.</p>



<h3 id="data-collection">8.4 Data Collection and HTTP</h3>

<p><strong>Java HttpClient (java.net.http, built-in since Java 11)</strong>: Modern HTTP protocol handler with connection pooling, automatic timeout management (default 30 seconds), follows HTTP redirects (301, 302), handles chunked transfer encoding, and supports HTTP/1.1 and HTTP/2.</p>

<p><strong>Benefits vs Selenium:</strong> HttpClient is 10-50x faster than Selenium (milliseconds vs seconds per page). Selenium launches full Chrome browser process (500MB+ memory per tab), rendering JavaScript - overkill for static YouTube pages. HttpClient sends raw HTTP GET requests to YouTube (1-2MB per page), parses embedded JSON data using regex patterns, skips all browser overhead. Lower CPU/memory footprint allows parallel crawling (100 URLs simultaneously). No WebDriver updates required when YouTube updates HTML structure (Selenium breaks with HTML changes).</p>

<p><strong>Note:</strong> pom.xml declares Selenium 4.15.0 but code does not use it. Design decision: avoid browser automation overhead, prioritize performance. If browser rendering needed (JavaScript-heavy sites, anti-bot protection), can swap HttpClient ‚Üí Selenium without changing DataCrawler interface.</p>

<p><strong>YouTubeCrawler Implementation</strong>: Sends HTTP GET to <code>https://www.youtube.com/watch?v={VIDEO_ID}</code> with Chrome User-Agent header (YouTube checks User-Agent to prevent bot detection). Response HTML contains embedded <code>ytInitialData</code> JSON object with complete comment section data. YouTubeCrawler extracts:
<ul>
<li>Video metadata: title, channel, view count, publication date</li>
<li>Comments: author, text, likes, timestamp, reply hierarchy</li>
<li>Replies: nested comment structure v·ªõi author v√† text</li>
</ul>
Kh√¥ng rendering screen, kh√¥ng Selenium WebDriver overhead - pure HTTP + JSON parsing.</p>

<p><strong>OkHttp3 4.11.0</strong>: Production HTTP client from Square (used in Android framework). Provides advanced features: HTTP/2 connection multiplexing (multiple requests on single TCP connection), automatic GZIP compression (reduces bandwidth), request interceptors (can inject logging, auth headers, retry logic).</p>

<p><strong>Benefits:</strong> Future crawlers (FacebookCrawler, TwitterCrawler) can reuse OkHttp3 interceptor patterns for centralized logging and auth. Connection pooling reduces overhead when crawling thousands of URLs. Currently HttpClient sufficient but OkHttp3 available as drop-in replacement if needed.</p>

<p><strong>MockDataCrawler</strong>: Synthetic data generator for unit testing and demo mode. Returns hardcoded List&lt;Post&gt; with 31 humanitarian disaster scenarios (earthquake relief, flood response, pandemic medical supplies). Zero network calls - useful for:
<ul>
<li><strong>Offline development</strong>: No internet required</li>
<li><strong>Reproducible testing</strong>: Same data every run vs YouTube's live-changing data</li>
<li><strong>Unit tests</strong>: Fast test execution (~100ms vs 10+ seconds with real YouTube crawling)</li>
<li><strong>Demo mode</strong>: Avoid YouTube API rate limits (10 requests/second), prevents IP blocking</li>
</ul>
Registered in CrawlerRegistry alongside YouTubeCrawler - same interface, pluggable via Factory pattern.</p>

<h3 id="json-processing">8.5 JSON Processing</h3>

<p><strong>JSON Handling Strategy</strong>: The application uses two JSON libraries optimized for different use cases. Understanding when to use each library improves code clarity and reduces dependencies:</p>

<table>
<thead>
<tr>
<th><strong>Library</strong></th>
<th><strong>Use Case</strong></th>
<th><strong>Example in Code</strong></th>
<th><strong>Trade-off</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Gson 2.10.1 (Type-Safe)</strong></td>
<td>Parse complex nested JSON into typed Java objects (Python API responses)</td>
<td>SentimentResponse response = gson.fromJson(json, SentimentResponse.class);</td>
<td>Full-featured but adds ~5MB to JAR</td>
</tr>
<tr>
<td><strong>org.json 20231013 (Lightweight)</strong></td>
<td>Parse simple JSON from HTML embedded data (YouTube ytInitialData)</td>
<td>JSONObject obj = new JSONObject(jsonString); String title = obj.getString("title");</td>
<td>Minimal (~100KB) but no type safety</td>
</tr>
</tbody>
</table>

<p><strong>Gson 2.10.1 (Google JSON Library) - For Complex Structures</strong>:</p>

<p><strong>What it does</strong>: Converts JSON strings ‚Üî Java objects automatically with full type checking. When you have nested objects (Post ‚Üí List of Comments ‚Üí each Comment has Sentiment), Gson recursively deserializes the entire structure preserving type information.</p>

<p><strong>Code Example</strong>:
<pre><code class="language-java">// Python API returns this JSON:
{
  "sentiment": "POSITIVE",
  "confidence": 0.94,
  "category": "FOOD",
  "keywords": ["relief", "supplies"]
}

// Java defines matching class:
class SentimentResponse {
    String sentiment;
    double confidence;
    String category;
    List&lt;String&gt; keywords;
}

// Gson instantly converts:
Gson gson = new Gson();
SentimentResponse response = gson.fromJson(jsonString, SentimentResponse.class);

// Type-safe access (compile-time checking):
System.out.println(response.sentiment);  // ‚úì Works, String type known
System.out.println(response.confidence); // ‚úì Works, double type known
// response.invalid_field;  // ‚úó Compile error - field doesn't exist
</code></pre>
</p>

<p><strong>Benefits</strong>: Type safety prevents runtime errors. Nested objects (Post.comments automatically deserializes all Comment objects). Handles custom types via type adapters (LocalDateTime ‚Üí ISO-8601 strings). Used for Python API communication where response structure is complex and changes require catching in compilation.</p>

<p><strong>org.json 20231013 (Lightweight JSON) - For Simple Parsing</strong>:</p>

<p><strong>What it does</strong>: Parses JSON into flexible generic objects (JSONObject, JSONArray) without class definitions. Trade runtime safety for minimal dependencies.</p>

<p><strong>Code Example</strong>:
<pre><code class="language-java">// YouTube HTML embeds JSON data:
String html = "...&lt;script&gt;var ytInitialData = {\"videoDetails\": {\"videoId\": \"abc123\", ...}}&lt;/script&gt;...";

// Extract and parse with org.json:
String jsonStr = extractJsonFromHtml(html);  // "{\\"videoDetails\\": ...}"
JSONObject data = new JSONObject(jsonStr);  // Parse instantly

// Access values dynamically (no class needed):
String videoId = data.getJSONObject("videoDetails").getString("videoId");
int viewCount = data.getJSONObject("videoDetails").getInt("viewCount");

// No type checking at compile time, but works for one-off parsing
</code></pre>
</p>

<p><strong>Benefits</strong>: Lightweight - single JAR with zero transitive dependencies (~100KB vs Gson ~5MB). Fast parsing for simple structures. Perfect for YouTube HTML parsing where you extract just a few fields then discard. Zero configuration. Avoids bloating desktop app with unused type serialization code.</p>

<p><strong>Why Both Libraries?</strong>:</p>

<p><strong>Design Decision</strong>: Rather than forcing all JSON through Gson (simpler to maintain), the application strategically uses org.json for lightweight YouTube parsing and Gson for complex Python API communication. This dual-library approach:
<ul>
<li><strong>Reduces JAR size</strong>: YouTube crawler doesn't need Gson's full serialization machinery - org.json is 50x lighter</li>
<li><strong>Improves clarity</strong>: Developers see "parsing simple data" (org.json) vs "complex typed response" (Gson) in code</li>
<li><strong>Optimizes for use case</strong>: Avoid paying full Gson cost when simple parsing suffices</li>
<li><strong>Zero overlap</strong>: Each library has distinct responsibility - no redundancy</li>
</ul>
</p>

<p><strong>When Python API Needs Change</strong>: If Python sentiment_api.py returns additional nested fields (e.g., detailed per-phrase sentiment scores), Gson's automatic deserialization adapts by extending SentimentResponse class. org.json would require manual JSONObject navigation - type safety matters for complex APIs. This is why org.json unsuitable for Python communication.</p>

<h3 id="machine-learning-nlp">8.6 Machine Learning &amp; NLP</h3>

<p><strong>Backend Stack Architecture:</strong></p>
<ul>
<li><strong>Flask 2.3.0+</strong>: Lightweight Python web microframework (150 lines of code creates REST API). Routes HTTP requests to Python functions. No heavy frameworks (Django) overhead.</li>
<li><strong>Hugging Face Transformers 4.30.0+</strong>: Library providing pre-trained transformer models (BERT, RoBERTa, BART) fine-tuned on millions of texts. Handles tokenization, embedding, inference automatically.</li>
<li><strong>PyTorch 2.0.0+</strong>: Deep learning framework executing transformer models with GPU acceleration (if available). Automatic differentiation for training.</li>
<li><strong>NumPy</strong>: Numerical computing library for tensor operations, matrix math supporting models internally.</li>
<li><strong>scikit-learn</strong>: Traditional ML library with SVM, decision trees, clustering (available for custom classifiers if needed).</li>
</ul>

<p><strong>Benefits:</strong> Python libraries have 10-100x better NLP support than Java equivalents. Hugging Face provides pre-trained models eliminating need to collect 10,000 training examples ourselves. Can download and use model in 10 minutes vs 6 months to train from scratch. Flask microframework (100-200 lines) vs Java Spring Boot (10,000+ lines configuration).</p>

<p><strong>Sentiment Analysis: XLM-RoBERTa-Large-XNLI</strong> (Facebook Research)</p>

<p><strong>Architecture</strong>: Transformer neural network with 24 layers, 550M parameters, pre-trained on 2.5TB cross-lingual data (100+ languages including Vietnamese). Zero-shot learning: classify any text into arbitrary classes without fine-tuning.</p>

<p><strong>Benefits:</strong>
<ul>
<li><strong>Multilingual support</strong>: Works on Vietnamese, English, French, Spanish, Arabic without retraining. Single model handles humanitarian crisis posts in any language.</li>
<li><strong>Zero-shot classification</strong>: No need to collect 1000s of Vietnamese disaster posts for training. Simply define classes [POSITIVE, NEGATIVE, NEUTRAL] and run inference.</li>
<li><strong>High accuracy</strong>: 94%+ accuracy on sentiment tasks (trained on millions of texts). Beats rule-based keyword matching by 30-40 percentage points.</li>
<li><strong>Confidence scores</strong>: Returns probability 0.94 for "POSITIVE" vs 0.04 for "NEGATIVE" - enables filtering low-confidence results (threshold: confidence > 0.8).</li>
</ul>
Model size: 2GB. First download: 10-15 minutes (cached in ~/.cache/huggingface/). Subsequent runs: instant load. Inference: 50-200ms per text (depends on text length - sentiment phrase vs long article).</p>

<p><strong>Relief Category Classification: BART-Large-MNLI</strong> (Facebook Research)</p>

<p><strong>Architecture</strong>: BART (Bidirectional Autoencoder Representations from Transformers) - sequence-to-sequence model designed for text generation and zero-shot classification. 400M parameters.</p>

<p><strong>Benefits:</strong>
<ul>
<li><strong>Category extraction</strong>: Classifies text into humanitarian relief categories [CASH, MEDICAL, SHELTER, FOOD, TRANSPORTATION] without labeled training data. Understands semantic relationships: "medications" ‚Üí MEDICAL, "tents" ‚Üí SHELTER, "ambulances" ‚Üí TRANSPORTATION.</li>
<li><strong>Keyword extraction</strong>: Returns associated keywords for each category - enables summary display to user ("Category: MEDICAL - Keywords: vaccines, antibiotics, hospitals").</li>
<li><strong>Batch efficiency</strong>: Processes 31 curated posts in 1-2 seconds using vectorized operations (all texts processed in single GPU pass vs 31 sequential passes). Single model handles all categories vs training 5 separate binary classifiers.</li>
</ul>
Model size: 1.6GB. Inference: 50-100ms for batch of 31 texts.</p>

<p><strong>Python Service Architecture: sentiment_api.py</strong></p>

<p><strong>Implementation</strong>: Flask server on port 5001 with two REST endpoints:</p>

<pre><code class="language-java">// Java calls Python API via HTTP POST
POST http://localhost:5001/sentiment
{
  "text": "Earthquake relief supplies arrived at shelter!",
  "task_type": "sentiment"
}

Response 200 OK:
{
  "sentiment": "POSITIVE",
  "confidence": 0.96,
  "category": "SHELTER",
  "keywords": ["supplies", "shelter"]
}
</code></pre>

<p><strong>Benefits of REST API separation:</strong>
<ul>
<li><strong>Language independence</strong>: Java GUI doesn't need to import PyTorch (incompatible with JVM). Python backend runs as independent process with its own Python interpreter and libraries.</li>
<li><strong>Technology flexibility</strong>: Can replace Python with Node.js/Go/C++ backend without touching Java code. Can scale Python separately (run 3 Python servers, load-balance requests across them).</li>
<li><strong>Graceful degradation</strong>: If Python API unavailable, fallback to EnhancedSentimentAnalyzer (Java-based keyword detection + emoticon matching) maintaining basic functionality.</li>
<li><strong>Development efficiency</strong>: Data scientists modify sentiment_api.py, test with curl/Postman, deploy without recompiling entire Java application.</li>
</ul>
</p>

<p><strong>Fallback Chain</strong>: If Python service crashes/unreachable:
<ul>
<li>1st attempt: Call Python API via HTTP ‚Üí XLM-RoBERTa model (94% accuracy)</li>
<li>2nd fallback: EnhancedSentimentAnalyzer (Java) ‚Üí regex keyword matching + emoticon detection (Vietnamese-specific rules for üòä‚ÜíPOSITIVE, üò¢‚ÜíNEGATIVE) ‚Üí 75% accuracy</li>
<li>3rd fallback: SimpleSentimentAnalyzer ‚Üí single-word keyword matching ‚Üí 60% accuracy</li>
</ul>
System remains functional even if Python service crashes - user sees slightly lower accuracy but continues analysis rather than hard failure.</p>

<h3 id="deployment-logging">8.7 Deployment &amp; Logging</h3>

<p><strong>SLF4J 2.0.9 (Simple Logging Facade for Java)</strong>: Abstraction layer decoupling application from specific logging implementation. Allows switching between Log4j, Logback, or simple console output without code changes.</p>

<p><strong>Benefits:</strong> Prevents vendor lock-in - if we need centralized logging (ELK stack, Splunk) in future, add one line to pom.xml and remove one line. Zero code changes. Configured with slf4j-simple binding (console-only output for desktop app). Log levels enable debug builds with verbose logging and production builds with ERROR-only output (changing single property).</p>

<p><strong>Logging Implementation</strong>: All major operations logged:
<ul>
<li><strong>DEBUG</strong>: Detailed execution trace ("Processing post ID 42", "Parsing comment section", "Calling Python API with text...")</li>
<li><strong>INFO</strong>: Key lifecycle events ("‚úì Crawler initialized", "üé¨ Crawling YouTube for keyword: relief", "‚úì Analysis complete - 31 posts analyzed")</li>
<li><strong>WARN</strong>: Suspicious activity ("‚ö† Confidence score 0.52 below threshold 0.8", "‚ö† Python API timeout, using fallback analyzer")</li>
<li><strong>ERROR</strong>: Failures with stack traces ("Error loading database", "HTTP 403 Forbidden from YouTube")</li>
</ul>
Useful for debugging customer issues: ask user to enable DEBUG logging and capture log output.</p>

<p><strong>Maven Build Process</strong>: <code>mvn clean package</code> compiles all Java files, runs unit tests, and creates <strong>fat JAR</strong> (humanitarian-logistics-1.0-SNAPSHOT-jar-with-dependencies.jar containing all 15+ dependencies bundled inside single JAR).</p>

<p><strong>Benefits:</strong> Single JAR file simplifies distribution - user downloads one file, runs <code>java -jar file.jar</code>, works immediately. No need to manage CLASSPATH or download separate dependency JARs. Maven Shade Plugin merges dependency JARs inside main JAR (avoiding conflicts if two libraries include different versions of same transitive dependency).</p>

<p><strong>Execution Flow</strong>:</p>
<pre><code class="language-java">// Step 1: User runs single command
java -jar humanitarian-logistics-1.0-SNAPSHOT-jar-with-dependencies.jar

// Step 2: JVM loads HumanitarianLogisticsApp.main() from JAR
// Step 3: Initialization sequence:
System.out.println("üîÑ Initializing Humanitarian Logistics System...");

// 3a. Load SQLite databases
DatabaseManager.getInstance().connect();
// ‚Üí Opens humanitarian_logistics_curated.db (31 posts pre-loaded)
// ‚Üí Opens humanitarian_logistics_user.db (empty, for user crawls)

// 3b. Populate CrawlerRegistry (Factory pattern)
CrawlerRegistry registry = CrawlerRegistry.getInstance();
registry.registerCrawler(new YouTubeCrawler());
registry.registerCrawler(new MockDataCrawler());
// ‚Üí Available crawlers: YouTubeCrawler, MockDataCrawler

// 3c. Start Python Flask service (separate process)
ProcessBuilder pb = new ProcessBuilder("python", "src/main/python/sentiment_api.py");
pb.start();
// ‚Üí Starts Flask server on port 5001
// ‚Üí Loads XLM-RoBERTa (2GB) and BART (1.6GB) models into GPU memory
// ‚Üí Takes 30-60 seconds on first run (model download)

// 3d. Initialize Model and UI
Model model = new Model();
view = new HumanitarianLogisticsUI(model);
SwingUtilities.invokeLater(() -> view.setVisible(true));
// ‚Üí Creates Swing JFrame with menu bar, panels, charts
// ‚Üí Displays empty DataTable, Analysis button, Crawler dropdown

System.out.println("‚úÖ System ready! Select crawler and click 'Crawl & Analyze'");
</code></pre>

<h3 id="performance">8.8 Performance Characteristics</h3>

<p><strong>Startup Performance</strong>:</p>

<table>
<thead>
<tr>
<th><strong>Phase</strong></th>
<th><strong>Time</strong></th>
<th><strong>Details</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>First-time setup</strong></td>
<td>10-15 min</td>
<td>Downloading 3.6GB of ML models from Hugging Face (XLM-RoBERTa 2GB + BART 1.6GB). One-time cost, models cached locally.</td>
</tr>
<tr>
<td><strong>Cold startup (models cached)</strong></td>
<td>30-45 sec</td>
<td>Loading models into GPU memory (10-15s), initializing Flask server (5-10s), loading SQLite databases (5s), creating Swing UI (5-10s).</td>
</tr>
<tr>
<td><strong>Warm startup</strong></td>
<td>5-10 sec</td>
<td>Python service already running in background, models already in GPU memory.</td>
</tr>
</tbody>
</table>

<p><strong>Benefits:</strong> First-time setup cost is one-time investment. User runs app once, models download, wait 15 minutes. Subsequent uses start in 30 seconds. Comparable to downloading Visual Studio (5-10GB) first time. ML capability (94% accuracy sentiment) only possible with model download - no free lunch.</p>

<p><strong>Analysis Performance</strong>:</p>

<table>
<thead>
<tr>
<th><strong>Operation</strong></th>
<th><strong>Speed</strong></th>
<th><strong>Notes</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>YouTube crawl (single video)</strong></td>
<td>500ms-2s</td>
<td>Depends on comment section size. HTML download (200-500ms) + JSON parsing (300-500ms) + building Post/Comment objects (200ms).</td>
</tr>
<tr>
<td><strong>Sentiment analysis (single text)</strong></td>
<td>50-200ms</td>
<td>XLM-RoBERTa inference. Longer texts (articles) slower than tweets (50-100ms). GPU: 10-20ms. CPU-only: 500ms+.</td>
</tr>
<tr>
<td><strong>Batch sentiment (31 posts)</strong></td>
<td>1-2 sec</td>
<td>Vectorized processing - all 31 texts processed in single GPU forward pass. 30x faster than 31 sequential inferences.</td>
</tr>
<tr>
<td><strong>Category classification (31 posts)</strong></td>
<td>500-800ms</td>
<td>BART model - slightly faster than sentiment model. Returns category + keywords per post.</td>
</tr>
<tr>
<td><strong>Database insert (single post)</strong></td>
<td>&lt;10ms</td>
<td>SQLite prepared statement. Batch insert (31 posts): 50-100ms with transaction wrapper.</td>
</tr>
<tr>
<td><strong>Chart rendering (100 posts)</strong></td>
<td>200-500ms</td>
<td>JFreeChart generating bar/pie/time-series charts. Interactive mouse listeners registered during rendering.</td>
</tr>
<tr>
<td><strong>UI refresh (data grid refresh)</strong></td>
<td>&lt;100ms</td>
<td>Swing JTable repaint with 31 rows. Java 11+ rendering optimizations.</td>
</tr>
</tbody>
</table>

<p><strong>Total user workflow (typical use case)</strong>:
<ul>
<li>User clicks "Crawl & Analyze" button ‚Üí selects YouTubeCrawler ‚Üí enters keywords "earthquake relief" ‚Üí clicks Submit</li>
<li>System crawls 5-10 YouTube videos (5-15 seconds)</li>
<li>Extracts ~100-150 comments (1 second)</li>
<li>Sentiment analysis on all comments (2 seconds)</li>
<li>Category classification (1 second)</li>
<li>Insert into database (500ms)</li>
<li>Render charts (500ms)</li>
<li><strong>Total: 10-20 seconds from click to results</strong> ‚úì User perceives as responsive (psychology: &lt;1 sec = instant, &lt;10 sec = acceptable, &gt;30 sec = annoying)</li>
</ul>
</p>

<p><strong>Memory Usage</strong>:</p>

<table>
<thead>
<tr>
<th><strong>Component</strong></th>
<th><strong>Memory</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Java heap</strong></td>
<td>256MB default (-Xmx256m)</td>
</tr>
<tr>
<td><strong>Python models in GPU memory</strong></td>
<td>3.6GB (XLM-RoBERTa 2GB + BART 1.6GB)</td>
</tr>
<tr>
<td><strong>Data structures (Post, Comment, Sentiment objects)</strong></td>
<td>~10-50MB (100-1000 posts, each ~50KB)</td>
</tr>
<tr>
<td><strong>UI components (Swing JFrame, JTable, charts)</strong></td>
<td>~50MB (cached images, rendered components)</td>
</tr>
<tr>
<td><strong>Total steady state</strong></td>
<td>~3.9GB (with GPU models) or 500MB (CPU-only, slower)</td>
</tr>
</tbody>
</table>

<p><strong>Benefits:</strong> GPU-accelerated analysis (3.6GB) vs CPU-only (500MB, 20x slower). For humanitarian disaster response (need results NOW), GPU cost justified. Can scale to 10,000+ posts with pagination - don't load all simultaneously, display 100 at a time, load more on scroll.</p>

<p><strong>Network Usage</strong>:</p>

<table>
<thead>
<tr>
<th><strong>Operation</strong></th>
<th><strong>Data Transfer</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>YouTube crawl (single video page)</strong></td>
<td>1-3MB (HTML response with all comments embedded)</td>
</tr>
<tr>
<td><strong>5 video crawl</strong></td>
<td>5-15MB total</td>
</tr>
<tr>
<td><strong>Python API request (sentiment)</strong></td>
<td>~1KB (text + task_type fields)</td>
</tr>
<tr>
<td><strong>Python API response (sentiment)</strong></td>
<td>~200 bytes (sentiment + confidence + category)</td>
</tr>
<tr>
<td><strong>Batch sentiment (31 posts, 31 API calls)</strong></td>
<td>~31KB request + 6KB response</td>
</tr>
<tr>
<td><strong>No continuous polling</strong></td>
<td>Event-driven (button click triggers crawl, no background requests)</td>
</tr>
</tbody>
</table>

<h3 id="scalability">8.9 Scalability and Future Evolution</h3>

<p><strong>Database Scaling Roadmap</strong>:</p>

<p><strong>Current (SQLite)</strong>: Single-user, single-machine. Perfect for individual analyst or small team. Schema: 4 tables (posts, comments, disaster_types, relief_items) with proper indexing on postId/commentId for fast lookups.</p>

<p><strong>Future (PostgreSQL/MySQL)</strong>: Multi-user concurrent access, ACID transactions, row-level security, automated backups/replication. DataPersistenceManager abstraction means swapping implementations requires:
<ul>
<li>1. Add PostgreSQL JDBC driver to pom.xml</li>
<li>2. Change JDBC URL in configuration ("jdbc:postgresql://localhost:5432/humanitarian_logistics")</li>
<li>3. Create schema once (20-line SQL script)</li>
<li>4. ZERO code changes in Model, Analysis, UI layers ‚úì Abstraction pattern in action</li>
</ul>
</p>

<p><strong>Scaling to 100,000+ posts</strong>:
<ul>
<li>Add table partitioning: posts_2024_Q1, posts_2024_Q2 by timestamp (query planner skips irrelevant partitions)</li>
<li>Add database views for common queries (most positive/negative posts, category distribution)</li>
<li>Add caching layer (Redis) for frequently accessed data (top 10 posts, aggregates)</li>
<li>Enable query optimization: EXPLAIN ANALYZE to identify slow queries, add indexes strategically</li>
</ul>
</p>

<p><strong>ML Scaling Roadmap</strong>:</p>

<p><strong>Current (Flask single-process)</strong>: Single request at a time. If 2nd user crawls while 1st user analyzes, 2nd user waits (blocking).</p>

<p><strong>Concurrent processing (Gunicorn)</strong>:
<pre><code class="language-java">// Deploy Flask with multi-worker server:
gunicorn -w 4 -b 0.0.0.0:5001 sentiment_api:app
// Spawns 4 Python processes, each with full model copy. Can handle 4 concurrent requests.
// Load balancer routes requests round-robin across workers.
</code></pre>

<p><strong>Results caching (Redis)</strong>:
<ul>
<li>Problem: User A analyzes "Great help from relief workers!" ‚Üí XLM-RoBERTa inference (100ms)</li>
<li>User B analyzes same text ‚Üí Hits Redis cache ‚Üí response in 1ms (100x speedup)</li>
<li>Implementation: Check Redis before calling XLM-RoBERTa, cache results for 24 hours (sentiment typically doesn't change)</li>
<li>Especially effective for humanitarian posts (repetitive disaster updates, same talking points)</li>
</ul>
</p>

<p><strong>Better models if latency permits</strong>:
<ul>
<li>Current: xlm-roberta-large (550M params, 94% accuracy, 50-200ms inference)</li>
<li>Upgrade path: xlm-roberta-xxl (3.5B params, 96% accuracy, 500ms inference) - 5x slower but 2% more accurate</li>
<li>Trade-off: 94% accuracy + 50ms is better UX than 96% accuracy + 500ms for interactive app. Use xxl model for batch analysis overnight.</li>
</ul>
</p>

<p><strong>Frontend Scaling Roadmap</strong>:</p>

<p><strong>Current: Desktop Swing app</strong> - single user, single machine, zero network overhead.</p>

<p><strong>Future: Web frontend (React/Vue.js/Angular)</strong> - multi-user concurrent access via browser</p>

<ul>
<li><strong>Architecture</strong>: Java backend exposes REST API (HumanitarianLogisticsAPI.java with Spring Boot) serving:
  <ul>
  <li>/api/crawl (POST) ‚Üí start YouTube crawl, returns job ID</li>
  <li>/api/analyze (POST) ‚Üí submit posts for analysis</li>
  <li>/api/results (GET) ‚Üí retrieve sentiment/category results</li>
  <li>/api/charts (GET) ‚Üí return chart data as JSON</li>
  </ul>
</li>
<li><strong>React frontend</strong> consumes REST API, displays charts using D3.js/Recharts, enables multi-user dashboards</li>
<li><strong>Code changes</strong>: Minimal - Model already implements Observer pattern (supports multiple listeners). Add REST endpoints wrapping Model methods. UI layer already MVC-separated from business logic.</li>
<li><strong>Database</strong>: Already multi-user capable with PostgreSQL migration above</li>
<li><strong>Benefit</strong>: Humanitarian organizations in disaster zones can use web app from any device (phone, tablet, laptop) without installing Java. Real-time collaboration - multiple analysts viewing same dashboard.</li>
</ul>
</p>

<p><strong>Crawler Scaling Roadmap</strong>:</p>

<p><strong>Current crawlers:</strong>
<ul>
<li>YouTubeCrawler: Fetches YouTube watch pages via HttpClient</li>
<li>MockDataCrawler: Generates synthetic posts for testing</li>
</ul>
</p>

<p><strong>Future crawlers (implementable without modifying existing code, thanks to Factory/Registry patterns)</strong>:</p>

<pre><code class="language-java">// Register new crawler via same interface:
public class FacebookCrawler implements DataCrawler {
    public List&lt;Post&gt; crawlPosts(List&lt;String&gt; keywords, List&lt;String&gt; hashtags, int limit) {
        // Facebook API: fetch posts by location (disaster zones), keywords (earthquake, relief)
        // Returns List&lt;Post&gt; with same structure as YouTube
    }
}

public class TwitterCrawler implements DataCrawler {
    // Twitter API v2: fetch tweets by hashtags #DisasterRelief #HumanitarianAid
    // Stream API for real-time sentiment tracking
}

public class RedditCrawler implements DataCrawler {
    // Reddit API: fetch posts from r/humanitariancrisis, r/disasterresponse
    // Comments already structured in Reddit JSON response
}

// Register all at startup:
CrawlerRegistry registry = CrawlerRegistry.getInstance();
registry.registerCrawler(new YouTubeCrawler());        // Existing
registry.registerCrawler(new FacebookCrawler());       // New
registry.registerCrawler(new TwitterCrawler());        // New
registry.registerCrawler(new RedditCrawler());         // New
// UI dropdown automatically includes all registered crawlers ‚úì Factory pattern benefit
</code></pre>

<p><strong>Rate limiting</strong>: Social platforms enforce rate limits (YouTube: 10 req/sec, Twitter: 300 req/15min). Implement exponential backoff:
<ul>
<li>1st request fails (429 Too Many Requests) ‚Üí wait 1 second, retry</li>
<li>2nd request fails ‚Üí wait 4 seconds, retry</li>
<li>3rd request fails ‚Üí wait 16 seconds, retry</li>
<li>Max retries: 5 (total wait: 1+4+16+64+256 = 341 seconds = 5.6 minutes)</li>
</ul>
Allows system to gracefully handle rate limits without crashing.</p>

<p><strong>Disaster Types and Relief Categories - Customization and Expansion</strong>:</p>

<p><strong>Current Configuration</strong>: The application currently operates with exactly 5 disaster types and 5 relief categories:
<ul>
<li><strong>Disaster Types (stored in disasters.dat)</strong>: yagi, koto, bualo, matmo, fung-wong</li>
<li><strong>Relief Categories (stored in relief_items table)</strong>: CASH, MEDICAL, SHELTER, FOOD, TRANSPORTATION</li>
</ul>
These types are loaded during application startup from persistent storage:
<ul>
<li>DisasterManager.getInstance() reads from data/disasters.dat (Java serialized DisasterType objects)</li>
<li>relief_items table schema defines acceptable category values in database</li>
<li>Model instance caches loaded categories in memory for UI/Analysis access</li>
</ul>
</p>

<p><strong>Persistence Architecture Enabling Easy Expansion</strong>: The application achieves flexibility through intermediate file storage and dynamic loading patterns:

<ul>
<li><strong>Disasters.dat File Strategy</strong>: Disaster types are persisted to data/disasters.dat using Java object serialization (NOT hardcoded in code). This file contains a serialized DisasterType list. On application startup, DataPersistenceManager.loadDisasters() deserializes disasters.dat and populates DisasterManager singleton with current disaster types. This separation means:
  <ul>
  <li>Adding new disasters = modify disasters.dat file (via programmatic API or direct serialization)</li>
  <li>No code recompilation required - disasters.dat loaded fresh each startup</li>
  <li>Users can clone/backup disasters.dat across machines - instant disaster type sharing</li>
  <li>Example: Organization A has disaster set {yagi, koto, bualo}, Organization B adds {earthquake, flood} - separate disasters.dat files, zero code conflicts</li>
  </ul>
</li>

<li><strong>Relief Categories Database Storage</strong>: Relief categories are defined in relief_items table schema. Similar to disasters:
  <ul>
  <li>Current: 5 categories fixed in enum and database</li>
  <li>Expansion: Add new category rows to relief_items table + extend ReliefItem.Category enum</li>
  <li>Dynamic UI discovery via Model.getAvailableCategories()</li>
  </ul>
</li>
</ul>
</p>

<p><strong>Expansion Mechanism - Adding New Disaster Types</strong>: Thanks to disasters.dat persistence strategy, expanding disaster types is straightforward:

<pre><code class="language-java">// At runtime, modify disasters.dat:
DisasterManager manager = DisasterManager.getInstance();
manager.addDisaster(new DisasterType("earthquake", "Earthquake,EQ,seismic,tremor"));
manager.addDisaster(new DisasterType("flood", "Flood,flooding,water,inundation"));

// Persist updated disasters list:
DataPersistenceManager persistence = new DataPersistenceManager();
persistence.saveDisasters(manager);  // Writes updated disasters.dat

// Application restart automatically loads new disasters
// Next startup: DisasterManager loads {yagi, koto, bualo, matmo, fung-wong, earthquake, flood}
// UI dropdowns automatically include new disaster types - no code changes
</code></pre>
</p>

<p><strong>Why This Architecture Enables Easy Expansion</strong>:
<ul>
<li><strong>Separation of Concerns</strong>: Data (disasters.dat, relief_items rows) separate from code (DisasterManager, ReliefItem). Changing data doesn't require code recompilation.</li>
<li><strong>Lazy Loading Pattern</strong>: DisasterManager and relief categories loaded once at startup from persistent storage. If storage changes, next startup reflects changes automatically. No hot-reloading complexity.</li>
<li><strong>Single Source of Truth</strong>: disasters.dat is the definitive source for disaster types. All references (UI dropdowns, Analysis tabs, Model cache) read from this single source via Singleton pattern.</li>
<li><strong>No Breaking Changes</strong>: Existing 5 disaster types (yagi, koto, bualo, matmo, fung-wong) continue to work unchanged. New types add to the set without modifying existing hardcoded assumptions.</li>
<li><strong>Migration Path Preserved</strong>: When migrating from SQLite to PostgreSQL, disasters.dat loading strategy unchanged - DisasterManager.getInstance() still works identically. Database schema change (SQLite ‚Üí PostgreSQL) is transparent to disaster loading logic.</li>
</ul>
</p>

<p><strong>Scalability Implications</strong>:
<ul>
<li><strong>Current (5 disaster types, 5 relief categories)</strong>: UI dropdowns load instantly, analysis completes in seconds</li>
<li><strong>Expanded (50+ disaster types)</strong>: Still performant - DisasterManager caches loaded disasters in memory, database indexes on disasterId column. Relief categories remain fixed at 5 types for consistency.</li>
<li><strong>Multi-tenant future</strong>: Each organization maintains separate disasters.dat file - OrganizationA.disasters.dat vs OrganizationB.disasters.dat with distinct disaster sets. Zero code conflict, zero deployment complexity.</li>
</ul>
</p>

<p><strong>Migration and Backup Strategy</strong>: The disasters.dat file-based approach enables simple data portability:
<ul>
<li>Backup: Copy data/disasters.dat to safe location</li>
<li>Restore: Copy disasters.dat back to data/ directory, restart application</li>
<li>Share: Email disasters.dat to partner organization - they copy to their data/ folder, get identical disaster types instantly</li>
<li>Version Control: disasters.dat can be committed to Git - disaster type evolution is auditable and rollbackable</li>
<li>No SQL migration scripts needed - file-based persistence is simpler than database versioning for this use case</li>
</ul>
</p>

<h3 id="technology-stack">8.10 Technology Stack Summary</h3>

<table>
<thead>
<tr>
<th><strong>Category</strong></th>
<th><strong>Technology</strong></th>
<th><strong>Version</strong></th>
<th><strong>Purpose</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Languages</strong></td>
<td>Java / Python</td>
<td>11+ / 3.12.7</td>
<td>Desktop app / ML backend</td>
</tr>
<tr>
<td><strong>Build</strong></td>
<td>Maven</td>
<td>3.9.11</td>
<td>Compilation, packaging, dependency management</td>
</tr>
<tr>
<td><strong>Desktop UI</strong></td>
<td>Swing</td>
<td>Built-in</td>
<td>GUI with zero external dependencies</td>
</tr>
<tr>
<td><strong>Charting</strong></td>
<td>JFreeChart</td>
<td>1.5.3</td>
<td>Bar, pie, time-series charts with interactivity</td>
</tr>
<tr>
<td><strong>Database</strong></td>
<td>SQLite + JDBC</td>
<td>3.44.0.0</td>
<td>Embedded persistence, two DB instances</td>
</tr>
<tr>
<td><strong>HTTP Client</strong></td>
<td>Java HttpClient / OkHttp3</td>
<td>Built-in / 4.11.0</td>
<td>YouTube crawling, API calls</td>
</tr>
<tr>
<td><strong>JSON Processing</strong></td>
<td>Gson / org.json</td>
<td>2.10.1 / 20231013</td>
<td>Complex / lightweight serialization</td>
</tr>
<tr>
<td><strong>Web Framework</strong></td>
<td>Flask</td>
<td>2.3.0+</td>
<td>Python REST API for ML services</td>
</tr>
<tr>
<td><strong>NLP Models</strong></td>
<td>Transformers / PyTorch</td>
<td>4.30.0+ / 2.0.0+</td>
<td>Sentiment (xlm-roberta) / Category (BART) models</td>
</tr>
<tr>
<td><strong>Logging</strong></td>
<td>SLF4J + slf4j-simple</td>
<td>2.0.9</td>
<td>Abstraction layer with console output</td>
</tr>
<tr>
<td><strong>Testing</strong></td>
<td>JUnit</td>
<td>4.13.2</td>
<td>Unit test framework</td>
</tr>
</tbody>
</table>

<p><strong>Architecture Decisions</strong>: Lightweight HTTP-based data collection for efficiency and reduced resource footprint. Microservices pattern: Java desktop app communicates with Python ML backend via REST (loose coupling, language independence). Abstraction layers (DataPersistenceManager, CrawlerRegistry) enable technology switching without breaking client code. Observer pattern ensures responsive UI without polling.</p>

<p><strong>Production Readiness</strong>: Mature, battle-tested libraries (Swing since 1996, Flask since 2010, SQLite since 2000). Try-with-resources ensures resource cleanup. Prepared statements prevent SQL injection. Error handling with graceful fallbacks (Python unavailable ‚Üí use Enhanced/Simple analyzers). Future evolution supported via abstraction patterns without major refactoring.</p>
</body>
</html>

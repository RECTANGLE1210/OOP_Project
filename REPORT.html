<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>document</title>
  <script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
  <script>
    mermaid.initialize({
      startOnLoad: true,
      theme: 'default',
      securityLevel: 'loose'
    });
    window.addEventListener('load', function() {
      var converted = new Set();

      document.querySelectorAll('pre').forEach(function(pre) {
        var code = pre.querySelector('code');
        var preHasMermaid = pre.className && pre.className.indexOf('mermaid') !== -1;
        var codeHasMermaid =
          code &&
          (code.className || '').match(/(?:^|\s)(?:mermaid|language-mermaid)(?:\s|$)/);

        if (preHasMermaid || codeHasMermaid) {
          var div = document.createElement('div');
          div.className = 'mermaid';
          div.textContent = code ? code.textContent : pre.textContent;
          if (pre.parentNode) {
            if (code) {
              converted.add(code);
            }
            pre.parentNode.replaceChild(div, pre);
          }
        }
      });

      // Handle rare cases where mermaid markup exists without a <pre> wrapper
      document.querySelectorAll('code').forEach(function(code) {
        var hasMermaid = (code.className || '').indexOf('mermaid') !== -1 || (code.className || '').indexOf('language-mermaid') !== -1;
        if (!hasMermaid || converted.has(code)) {
          return;
        }
        var wrapper = document.createElement('div');
        wrapper.className = 'mermaid';
        wrapper.textContent = code.textContent;
        if (code.parentNode) {
          code.parentNode.replaceChild(wrapper, code);
          converted.add(wrapper);
        }
      });

      setTimeout(function() {
        mermaid.init(undefined, document.querySelectorAll('.mermaid'));
      }, 100);
    });
  </script>

  <style>
  body {
      font-family: 'Hiragino Sans', 'Hiragino Kaku Gothic ProN', 'Noto Sans JP', sans-serif;
      line-height: 1.5;
      color: #333;
      background-color: #fafafa;
      margin: 0 !important;
      padding: 20px !important;
      font-size: 14px;
  }

  table {
      border-collapse: collapse;
      min-width: 60%;
      max-width: 100%;
      margin: 20px 0;
      background: white;
      border-radius: 6px;
      overflow: hidden;
  }

  table tr th {
      background-color: #143452;
      color: white;
      padding: 12px 15px;
      text-align: left;
      font-weight: 500;
  }

  .table-http th,
  .table-http td,
  table th,
  table td {
      word-break: break-word;
      overflow-wrap: anywhere;
      white-space: normal;
  }

  .tr-break {
      background-color: #2d79b717 !important;
  }

  .tr-break td {
      padding: 8px 12px;
      font-size: 12px;
      font-weight: bold;
  }

  table tr td {
      padding: 12px 15px;
      border-bottom: 1px solid #ecf0f1;
  }

  table tr:last-child td {
      border-bottom: none;
  }

  table tr:nth-child(even) {
      background-color: #f8f9fa;
  }

  .highlight {
      background-color: #fff3cd !important;
  }

  a {
      font-size: 14px;
  }

  code {
      padding: 2px 6px;
      border-radius: 3px;
      font-family: 'Monaco', 'Consolas', monospace;
      background: #fff8e4;
      color: #c99a0d;
      font-size: 13px;
  }

  pre code {
      background-color: transparent;
  }

  pre {
      background-color: #000;
      color: #f8f8f2;
      padding: 20px;
      border-radius: 6px;
      border-left: 4px solid #3498db;
      overflow-x: auto;
  }

  pre code.language-php,
  pre code.language-sql,
  pre code.language-javascript,
  pre code.language-bash,
  pre code.language-shell {
    background-color: #282c34 !important;
    color: #abb2bf;
  }

  /* Syntax Highlighting */
  code span.kw { color: #c678dd; font-weight: bold; } /* Keyword */
  code span.dt { color: #e5c07b; } /* Datatype */
  code span.dv { color: #d19a66; } /* Decimal Value */
  code span.bn { color: #d19a66; } /* Base N */
  code span.fl { color: #d19a66; } /* Float */
  code span.ch { color: #98c379; } /* Char */
  code span.st { color: #98c379; } /* String */
  code span.co { color: #5c6370; font-style: italic; } /* Comment */
  code span.ot { color: #e06c75; } /* Other */
  code span.al { color: #e06c75; font-weight: bold; } /* Alert */
  code span.fu { color: #61afef; } /* Function */
  code span.er { color: #e06c75; font-weight: bold; } /* Error */
  code span.wa { color: #e06c75; font-style: italic; } /* Warning */
  code span.cn { color: #d19a66; } /* Constant */
  code span.sc { color: #e5c07b; } /* Special Char */
  code span.vs { color: #98c379; } /* Verbatim String */
  code span.ss { color: #98c379; } /* Special String */
  code span.im { color: #c678dd; } /* Import */
  code span.va { color: #e06c75; } /* Variable */
  code span.cf { color: #c678dd; } /* Control Flow */
  code span.op { color: #56b6c2; } /* Operator */
  code span.bu { color: #e5c07b; } /* BuiltIn */
  code span.ex { color: #d19a66; } /* Extension */
  code span.pp { color: #e5c07b; } /* Preprocessor */
  code span.at { color: #d19a66; } /* Attribute */
  code span.do { color: #5c6370; font-style: italic; } /* Documentation */
  code span.an { color: #5c6370; font-style: italic; } /* Annotation */
  code span.cv { color: #5c6370; font-style: italic; } /* Comment Var */
  code span.in { color: #5c6370; font-style: italic; } /* Information */

  ul, ol {
      margin: 15px 0;
      padding-left: 30px;
  }

  li {
      margin-bottom: 8px;
  }

  blockquote {
      background-color: #fff3cd;
      border-left: 4px solid #ffc107;
      padding: 15px 20px;
      margin: 20px 0;
      border-radius: 4px;
      color: #856404;
  }

  pre code.language-json {
    background-color: #0d1117 !important;
    color: #58a6ff !important;
    display: block;
    font-size: 14px;
    padding-top: 5px;
    padding-bottom: 5px;
    margin: -15px;
  }

  .table-http code {
      font-size: 12px;
  }

  .table-http th:nth-child(1),.table-http td:nth-child(1) { width: 8%; }  /* HTTP Method */
  .table-http th:nth-child(2),.table-http td:nth-child(2) { width: 15%; } /* URL */
  .table-http th:nth-child(3),.table-http td:nth-child(3) { width: 19%; } /* M√¥ t·∫£ */
  .table-http th:nth-child(4),.table-http td:nth-child(4) { width: 43%; } /* RewriteRule */
  .table-http th:nth-child(5),.table-http td:nth-child(5) { width: 15%; } /* V√≠ d·ª• */

  pre, pre.sourceCode {
      background-color: #c0c4c73b;
  }

  .sourceCode {
      overflow: auto;
  }

  /* Pandoc highlight overrides */
  pre.sourceCode {
      background: #f7f7f7;
      border: 1px solid #e0e0e0;
      padding: 16px;
      border-radius: 6px;
  }
  .sourceCode code {
      font-family: 'Monaco', 'Consolas', monospace;
      font-size: 13px;
  }
  .sourceCode .kw { color: #2a8ad4; font-weight: 700; }    /* keywords */
  .sourceCode .cf { color: #2a8ad4; font-weight: 700; }    /* control flow */
  .sourceCode .dt { color: #070707; }                      /* data types */
  .sourceCode .fu { color: #8b5cf6; }                     /* functions */
  .sourceCode .op { color: #2a8ad4; }                     /* operators */
  .sourceCode .st { color: #0aa370; }                     /* strings */
  .sourceCode .dv,                                     /* decimal values */
  .sourceCode .bn { color: #c18401; }                     /* numbers */
  .sourceCode .fl { color: #c18401; }                     /* floats */
  .sourceCode .ch { color: #0aa370; }                     /* chars */
  .sourceCode .co { color: #6a737d; font-style: italic; } /* comments */
  .sourceCode .va { color: #444; }                        /* variables */
  .sourceCode .cn { color: #c18401; font-weight: 700; }   /* constants */
  .sourceCode .al { color: #d73a49; font-weight: 700; }   /* alerts */
  .sourceCode .an { color: #d73a49; font-weight: 700; }   /* annotations */
  .sourceCode .at { color: #005cc5; }                     /* attributes */
  .sourceCode .im { color: #005cc5; }                     /* imports */

  #TOC {
    background: #f8f9fa;
    border: 1px solid #dee2e6;
    border-radius: 8px;
    padding: 20px;
    margin: 20px 0;
  }

  #TOC > ul {
    list-style: none;
    padding-left: 0;
  }

  #TOC ul {
    list-style: none;
    padding-left: 20px;
  }

  #TOC li {
    margin: 8px 0;
  }

  #TOC a {
    text-decoration: none;
    color: #0066cc;
    font-weight: 500;
    transition: color 0.2s;
  }

  #TOC a:hover {
    color: #004499;
    text-decoration: underline;
  }

  #TOC > ul > li > a {
    font-size: 1.1em;
    font-weight: 600;
    color: #333;
  }

  #TOC ul ul a {
    font-size: 0.95em;
    color: #555;
  }

  hr {
      background: #cacaca;
  }

  .w-50 {
      width: 50%;
  }

  .w-100 {
      width: 100%;
  }

  .max-w-100 {
      max-width: 100% !important;
  }

  .shadow-xs {
      box-shadow: rgba(149, 157, 165, 0.2) 0px 8px 24px;
  }

  a {
      font-size: 14px;
  }

  code {
      padding: 2px 6px;
      border-radius: 3px;
      font-family: 'Monaco', 'Consolas', monospace;
      background: #fff8e4;
      color: #c99a0d;
      font-size: 13px;
  }

  pre code {
      background-color: transparent;
  }

  pre {
      background-color: #000;
      color: #f8f8f2;
      padding: 20px;
      border-radius: 6px;
      border-left: 4px solid #3498db;
      overflow-x: auto;
  }

  pre.sourceCode {
      border-left: 4px solid #3498db;
  }

  pre code.language-php,
  pre code.language-sql,
  pre code.language-javascript,
  pre code.language-bash,
  pre code.language-shell {
    background-color: #282c34 !important;
    color: #abb2bf;
  }

  /* Syntax Highlighting */
  code span.kw { color: #c678dd; font-weight: bold; } /* Keyword */
  code span.dt { color: #e5c07b; } /* Datatype */
  code span.dv { color: #d19a66; } /* Decimal Value */
  code span.bn { color: #d19a66; } /* Base N */
  code span.fl { color: #d19a66; } /* Float */
  code span.ch { color: #98c379; } /* Char */
  code span.st { color: #98c379; } /* String */
  code span.co { color: #5c6370; font-style: italic; } /* Comment */
  code span.ot { color: #e06c75; } /* Other */
  code span.al { color: #e06c75; font-weight: bold; } /* Alert */
  code span.fu { color: #61afef; } /* Function */
  code span.er { color: #e06c75; font-weight: bold; } /* Error */
  code span.wa { color: #e06c75; font-style: italic; } /* Warning */
  code span.cn { color: #d19a66; } /* Constant */
  code span.sc { color: #e5c07b; } /* Special Char */
  code span.vs { color: #98c379; } /* Verbatim String */
  code span.ss { color: #98c379; } /* Special String */
  code span.im { color: #c678dd; } /* Import */
  code span.va { color: #e06c75; } /* Variable */
  code span.cf { color: #c678dd; } /* Control Flow */
  code span.op { color: #56b6c2; } /* Operator */
  code span.bu { color: #e5c07b; } /* BuiltIn */
  code span.ex { color: #d19a66; } /* Extension */
  code span.pp { color: #e5c07b; } /* Preprocessor */
  code span.at { color: #d19a66; } /* Attribute */
  code span.do { color: #5c6370; font-style: italic; } /* Documentation */
  code span.an { color: #5c6370; font-style: italic; } /* Annotation */
  code span.cv { color: #5c6370; font-style: italic; } /* Comment Var */
  code span.in { color: #5c6370; font-style: italic; } /* Information */

  ul, ol {
      margin: 15px 0;
      padding-left: 30px;
  }

  li {
      margin-bottom: 8px;
  }

  blockquote {
      background-color: #fff3cd;
      border-left: 4px solid #ffc107;
      padding: 15px 20px;
      margin: 20px 0;
      border-radius: 4px;
      color: #856404;
  }

  pre code.language-json {
    background-color: #0d1117 !important;
    color: #58a6ff !important;
    display: block;
    font-size: 14px;
    padding-top: 5px;
    padding-bottom: 5px;
    margin: -15px;
  }

  .table-http code {
      font-size: 12px;
  }

  .table-http th:nth-child(1),.table-http td:nth-child(1) { width: 8%; }  /* HTTP Method */
  .table-http th:nth-child(2),.table-http td:nth-child(2) { width: 15%; } /* URL */
  .table-http th:nth-child(3),.table-http td:nth-child(3) { width: 19%; } /* M√¥ t·∫£ */
  .table-http th:nth-child(4),.table-http td:nth-child(4) { width: 43%; } /* RewriteRule */
  .table-http th:nth-child(5),.table-http td:nth-child(5) { width: 15%; } /* V√≠ d·ª• */

  pre, pre.sourceCode {
      background-color: #c0c4c73b;
  }

  .sourceCode {
      overflow: auto;
  }

  /* Pandoc highlight overrides */
  pre.sourceCode {
      background: #f7f7f7;
      border: 1px solid #e0e0e0;
      padding: 16px;
      border-radius: 6px;
      border-left: 4px solid #3498db;
  }
  .sourceCode code {
      font-family: 'Monaco', 'Consolas', monospace;
      font-size: 13px;
  }
  .sourceCode .kw { color: #2a8ad4; font-weight: 700; }    /* keywords */
  .sourceCode .cf { color: #2a8ad4; font-weight: 700; }    /* control flow */
  .sourceCode .dt { color: #070707; }                      /* data types */
  .sourceCode .fu { color: #8b5cf6; }                     /* functions */
  .sourceCode .op { color: #2a8ad4; }                     /* operators */
  .sourceCode .st { color: #0aa370; }                     /* strings */
  .sourceCode .dv,                                     /* decimal values */
  .sourceCode .bn { color: #c18401; }                     /* numbers */
  .sourceCode .fl { color: #c18401; }                     /* floats */
  .sourceCode .ch { color: #0aa370; }                     /* chars */
  .sourceCode .co { color: #6a737d; font-style: italic; } /* comments */
  .sourceCode .va { color: #444; }                        /* variables */
  .sourceCode .cn { color: #c18401; font-weight: 700; }   /* constants */
  .sourceCode .al { color: #d73a49; font-weight: 700; }   /* alerts */
  .sourceCode .an { color: #d73a49; font-weight: 700; }   /* annotations */
  .sourceCode .at { color: #005cc5; }                     /* attributes */
  .sourceCode .im { color: #005cc5; }                     /* imports */

  #TOC {
    background: #f8f9fa;
    border: 1px solid #dee2e6;
    border-radius: 8px;
    padding: 20px;
    margin: 20px 0;
  }

  #TOC > ul {
    list-style: none;
    padding-left: 0;
  }

  #TOC ul {
    list-style: none;
    padding-left: 20px;
  }

  #TOC li {
    margin: 8px 0;
  }

  #TOC a {
    text-decoration: none;
    color: #0066cc;
    font-weight: 500;
    transition: color 0.2s;
  }

  #TOC a:hover {
    color: #004499;
    text-decoration: underline;
  }

  #TOC > ul > li > a {
    font-size: 1.1em;
    font-weight: 600;
    color: #333;
  }

  #TOC ul ul a {
    font-size: 0.95em;
    color: #555;
  }

  hr {
      background: #cacaca;
  }

  .w-50 {
      width: 50%;
  }

  .w-100 {
      width: 100%;
  }

  .max-w-100 {
      max-width: 100% !important;
  }

  /* Image sizing - increased to 1.2x */
  img {
      max-width: 100%;
      height: auto;
      transform: scale(1.15);
      transform-origin: center;
      display: inline-block;
      margin: 15px auto;
  }

  </style>
</head>
<body>
<nav id="TOC" role="doc-toc">
<ul>
<li><a href="#report-for-oop-humanitarian-logistic-project"
id="toc-report-for-oop-humanitarian-logistic-project"><strong>REPORT FOR
OOP HUMANITARIAN LOGISTIC PROJECT</strong></a>
<ul>
<li><a href="#overview" id="toc-overview">1.Overview</a>
<ul>
<li><a href="#project-objective-and-context"
id="toc-project-objective-and-context">1.1 Project Objective and
Context</a></li>
<li><a href="#system-architecture-overview"
id="toc-system-architecture-overview">1.2 System Architecture
Overview</a></li>
<li><a href="#key-technologies-and-frameworks"
id="toc-key-technologies-and-frameworks">1.3 Key Technologies and
Frameworks</a></li>
<li><a href="#object-oriented-design-principles-applied"
id="toc-object-oriented-design-principles-applied">1.4 Object-Oriented
Design Principles Applied</a></li>
<li><a href="#development-approach-and-methodology"
id="toc-development-approach-and-methodology">1.5 Development Approach
and Methodology</a></li>
<li><a href="#deliverables-and-scope"
id="toc-deliverables-and-scope">1.6 Deliverables and Scope</a></li>
</ul></li>
<li><a href="#members-and-task-assigment"
id="toc-members-and-task-assigment">2. Members and Task
Assigment</a></li>
<li><a href="#teamwork-log" id="toc-teamwork-log">3. Teamwork Log</a>
<ul>
<li><a href="#project-development-timeline"
id="toc-project-development-timeline">Project Development
Timeline</a></li>
<li><a href="#project-statistics-and-metrics"
id="toc-project-statistics-and-metrics">Project Statistics and
Metrics</a></li>
<li><a href="#key-milestones" id="toc-key-milestones">Key
Milestones</a></li>
</ul></li>
<li><a href="#user-guide" id="toc-user-guide">4. User Guide</a>
<ul>
<li><a href="#introduction" id="toc-introduction">4.1
Introduction</a></li>
<li><a href="#system-requirements" id="toc-system-requirements">4.2
System Requirements</a></li>
<li><a href="#installation-guide" id="toc-installation-guide">4.3
Installation Guide</a></li>
<li><a href="#running-the-application"
id="toc-running-the-application">4.4 Running the Application</a></li>
<li><a href="#application-interface-overview"
id="toc-application-interface-overview">4.5 Application Interface
Overview</a></li>
<li><a href="#tab-1-analysis" id="toc-tab-1-analysis">4.6 Tab 1:
Analysis (üìä)</a></li>
<li><a href="#tab-2-comments-manager"
id="toc-tab-2-comments-manager">4.7 Tab 2: Comments Manager
(üí¨)</a></li>
<li><a href="#tab-3-crawl-web" id="toc-tab-3-crawl-web">4.8 Tab 3: Crawl
Web (üåê)</a></li>
<li><a href="#tab-4-data-entry" id="toc-tab-4-data-entry">4.9 Tab 4:
Data Entry (‚úèÔ∏è)</a></li>
<li><a href="#complete-analysis-workflow"
id="toc-complete-analysis-workflow">4.10 Complete Analysis
Workflow</a></li>
<li><a href="#tips-and-best-practices"
id="toc-tips-and-best-practices">4.11 Tips and Best Practices</a></li>
</ul></li>
<li><a href="#collected-data-summarization"
id="toc-collected-data-summarization">5. Collected Data
Summarization</a></li>
<li><a href="#uml-diagrams-and-design-explaination"
id="toc-uml-diagrams-and-design-explaination">6. UML Diagrams and Design
Explaination</a>
<ul>
<li><a href="#rationale-for-dividing-class-diagrams-into-packages"
id="toc-rationale-for-dividing-class-diagrams-into-packages">6.1
Rationale for Dividing Class Diagrams into Packages</a></li>
<li><a href="#package-dependency-diagram"
id="toc-package-dependency-diagram">6.2 Package Dependency
Diagram</a></li>
<li><a href="#detailed-class-diagrams-by-package"
id="toc-detailed-class-diagrams-by-package">6.3 Detailed Class Diagrams
by Package</a></li>
<li><a href="#architectural-design-principles-and-rationale"
id="toc-architectural-design-principles-and-rationale">6.4 Architectural
Design Principles and Rationale</a></li>
<li><a href="#solid-principles-applied-throughout-the-design"
id="toc-solid-principles-applied-throughout-the-design">6.5 SOLID
Principles Applied Throughout the Design</a></li>
<li><a href="#architectural-summary-and-benefits"
id="toc-architectural-summary-and-benefits">6.6 Architectural Summary
and Benefits</a></li>
</ul></li>
<li><a href="#oop-techniques" id="toc-oop-techniques">7. OOP
Techniques</a>
<ul>
<li><a href="#fundamental-object-oriented-programming-concepts"
id="toc-fundamental-object-oriented-programming-concepts">7.1
Fundamental Object-Oriented Programming Concepts</a></li>
<li><a href="#advanced-design-patterns"
id="toc-advanced-design-patterns">7.2 Advanced Design Patterns</a></li>
<li><a href="#advanced-java-techniques"
id="toc-advanced-java-techniques">7.3 Advanced Java Techniques</a></li>
<li><a href="#summary-of-oop-application"
id="toc-summary-of-oop-application">7.4 Summary of OOP
Application</a></li>
</ul></li>
<li><a href="#technology-report" id="toc-technology-report">8.
Technology Report</a>
<ul>
<li><a href="#core-technologies" id="toc-core-technologies">8.1 Core
Technologies</a></li>
<li><a href="#ui-and-visualization" id="toc-ui-and-visualization">8.2 UI
and Visualization</a></li>
<li><a href="#data-storage" id="toc-data-storage">8.3 Data
Storage</a></li>
<li><a href="#machine-learning-nlp" id="toc-machine-learning-nlp">8.4
Machine Learning &amp; NLP</a></li>
<li><a href="#data-collection" id="toc-data-collection">8.5 Data
Collection</a></li>
<li><a href="#deployment-logging" id="toc-deployment-logging">8.6
Deployment &amp; Logging</a></li>
<li><a href="#performance" id="toc-performance">8.7 Performance</a></li>
<li><a href="#technology-stack" id="toc-technology-stack">8.8 Technology
Stack</a></li>
</ul></li>
</ul></li>
</ul>
</nav>
<h1 id="report-for-oop-humanitarian-logistic-project"><strong>REPORT FOR
OOP HUMANITARIAN LOGISTIC PROJECT</strong></h1>
<p><strong>GROUP 4</strong></p>
<h2 id="overview">1.Overview</h2>
<h3 id="project-objective-and-context">1.1 Project Objective and Context</h3>
<p>The Humanitarian Logistics Analysis System is a comprehensive Java-based application designed to analyze and assess the effectiveness
of humanitarian relief operations during disaster response scenarios. The system focuses on two primary research problems:</p>

<p><strong>Problem 1 - Relief Item Category Effectiveness Analysis</strong>: This module directly addresses <em>Original Problem 3</em> from the project specification by evaluating which categories of relief items (cash assistance, medical supplies, food aid, shelter provisions, transportation) receive the highest user satisfaction and positive sentiment from affected populations. The analysis aggregates sentiment scores across different relief categories, enabling humanitarian organizations to identify which types of aid are most valued by beneficiaries and which areas require improvement or resource reallocation. Users can visualize satisfaction distributions through interactive bar charts and pie charts, filtering by specific disaster types or viewing aggregate statistics across all disasters.</p>

<p><strong>Problem 2 - Temporal Sentiment Trend Analysis</strong>: This module integrates two complementary temporal perspectives that combine <em>Original Problems 1 and 4</em> from the project specification, providing a unified view of how sentiment evolves throughout disaster response phases:</p>

<ul>
<li><strong>Category-Specific Temporal Analysis (Original Problem 4)</strong>: Tracks sentiment trends for individual relief categories over time, showing how satisfaction with specific aid types (cash, medical, shelter, food, transportation) changes during different phases of the disaster response. This granular view helps organizations understand which relief categories improve or decline in effectiveness as the response progresses, enabling targeted interventions for underperforming aid types.</li>

<li><strong>Overall Sentiment Timeline (Original Problem 1)</strong>: Analyzes aggregate sentiment trends across all relief categories, providing a comprehensive view of how public perception of the entire humanitarian response evolves from immediate aftermath through ongoing recovery phases. This holistic perspective identifies critical periods when intervention strategies may need adjustment and reveals overall patterns in community satisfaction with relief efforts.</li>
</ul>

<p>By organizing temporal analyses into a single unified module with two complementary tabs, the application enables users to seamlessly compare category-specific trends against overall sentiment patterns, facilitating comprehensive insights into disaster response effectiveness and resource allocation optimization.</p>
<h3 id="system-architecture-overview">1.2 System Architecture Overview</h3>
<p>The application is structured using a professional seven-package
architecture that cleanly separates concerns and enables modularity,
testability, and extensibility:</p>
<p><strong>Core Data Layer</strong> (Model Package): Contains
fundamental data entities (Post, Comment, Sentiment, DisasterType)
representing the domain model with no dependencies on other
packages.</p>
<p><strong>User Interface Layer</strong> (UI Package): Implements the
Model-View-Controller architectural pattern using Swing components
organized into specialized panels (AdvancedAnalysisPanel, CommentManagementPanel, CrawlControlPanel, DataCollectionPanel).
The UI automatically updates when underlying data changes through the
Observer pattern.</p>
<p><strong>Data Collection Layer</strong> (Crawler Package): Provides pluggable data sources through the Strategy pattern. Implements two main crawlers: YouTubeCrawler (fetches YouTube watch pages using Java HttpClient, parses HTML with regex patterns to extract video metadata and comments) and MockDataCrawler (generates sample posts without requiring internet access). The Registry pattern enables dynamic crawler registration and runtime discovery. Note: YouTubeAPIHelper class exists for potential YouTube Data API v3 integration but is not currently used by the active crawlers.</p>
<p><strong>Sentiment Analysis Layer</strong> (Sentiment Package): Provides sentiment analysis through multiple implementations with a fallback strategy. PythonSentimentAnalyzer uses the Python backend with xlm-roberta model for multilingual sentiment analysis (called via Python API on port 5001). EnhancedSentimentAnalyzer provides bilingual keyword-based analysis with support for both English and Vietnamese sentiment keywords, serving as fallback when Python API is unavailable. Users interact with sentiment analysis through a single "Analyze All Posts with Python API" button in the Analysis tab that processes all posts using the Python backend.</p>
<p><strong>Data Preprocessing Layer</strong> (Preprocessor Package): Implements text normalization through the TextPreprocessor interface. The preprocessing pipeline handles URL removal, HTML entity decoding, whitespace normalization, and tokenization to prepare text for sentiment analysis and category-based filtering.</p>
<p><strong>Analysis Layer</strong> (Analysis Package): Implements specialized analysis engines through the Strategy pattern. SatisfactionAnalysisModule analyzes Problem 1 by calculating sentiment statistics and satisfaction scores per relief category, determining category effectiveness and generating resource allocation recommendations. TimeSeriesSentimentModule implements Problem 2 temporal analysis by grouping sentiments into 6-hour time buckets and tracking how sentiment evolves over time for each relief category, computing trend directions and sector effectiveness ratings.</p>
<p><strong>Data Persistence Layer</strong> (Database Package): Manages
SQLite database operations with proper abstraction to support potential
migration to other database systems without affecting application
code.</p>
<h3 id="key-technologies-and-frameworks">1.3 Key Technologies and
Frameworks</h3>
<p><strong>Programming Language</strong>: Java (version 11 or higher)
providing strong type safety, comprehensive standard library, and mature
ecosystem with built-in HTTP client.</p>
<p><strong>User Interface Framework</strong>: Swing (javax.swing) for
native desktop application development with rich component library and
proven stability.</p>
<p><strong>Data Storage</strong>: SQLite for lightweight, embedded
database functionality suitable for desktop applications.</p>
<p><strong>Web Data Collection</strong>: Java HttpClient (built-in java.net.http package) with OkHttp3 4.11.0 HTTP client library for fetching YouTube watch pages, parsing HTML responses, and extracting video metadata and comments via direct HTTP requests.</p>
<p><strong>Machine Learning Integration</strong>: Python backend with Flask REST API, Hugging Face Transformers (xlm-roberta for sentiment analysis, facebook/bart-large-mnli for text classification), and PyTorch deep learning framework accessed via HTTP calls from Java application.</p>
<p><strong>Build System</strong>: Maven 3.9.11 for dependency management, project organization, and automated fat JAR packaging with all dependencies included.</p>
<h3 id="object-oriented-design-principles-applied">1.4 Object-Oriented
Design Principles Applied</h3>
<p>The system demonstrates comprehensive application of Object-Oriented
Programming principles:</p>
<p><strong>Abstraction</strong>: Core interfaces (SentimentAnalyzer,
DataCrawler, AnalysisModule, TextPreprocessor) define contracts that
hide implementation details while exposing consistent interfaces.</p>
<p><strong>Encapsulation</strong>: Data entities encapsulate their state
with private fields and controlled access through methods. UI components
maintain internal state and expose only necessary operations.</p>
<p><strong>Inheritance</strong>: Post class serves as a base for
YouTube-specific posts, enabling code reuse while supporting polymorphic
treatment of different post types.</p>
<p><strong>Polymorphism</strong>: The system leverages both
interface-based and inheritance-based polymorphism to support multiple
implementations of key abstractions without coupling to concrete
types.</p>
<p><strong>Design Patterns</strong>: The architecture employs
industry-standard design patterns including MVC (Model-View-Controller),
Strategy, Factory, Registry, Observer, and Singleton patterns to solve
recurring architectural and design problems.</p>
<h3 id="development-approach-and-methodology">1.5 Development Approach
and Methodology</h3>
<p>The project follows professional software engineering practices
emphasizing clean code, testability, and maintainability:</p>
<p><strong>Separation of Concerns</strong>: Each package focuses on a
specific responsibility, making the system easier to understand, test,
and modify.</p>
<p><strong>Interface-Based Design</strong>: Components depend on
abstractions rather than concrete implementations, enabling flexible
composition and easy testing with mocks.</p>
<p><strong>Progressive Enhancement</strong>: Core functionality is
implemented with simple strategies (keyword-based sentiment analysis,
mock data), with advanced options available when needed (ML-based
analysis, real data sources).</p>
<p><strong>Testability</strong>: Classes are designed to be easily
testable in isolation, with dependencies injected rather than
hardcoded.</p>
<h3 id="deliverables-and-scope">1.6 Deliverables and Scope</h3>
<p>The complete system includes:</p>
<ol type="1">
<li><strong>Java Source Code</strong>: 30+ classes organized into 7
packages, totaling 5000+ lines of well-structured code</li>
<li><strong>User Interface</strong>: Desktop application with tabbed
interface supporting data collection, analysis visualization, and
disaster management</li>
<li><strong>Data Analysis Modules</strong>: Two specialized analysis
engines addressing Problems 1 and 2</li>
<li><strong>Documentation</strong>: Comprehensive UML diagrams showing
package dependencies and detailed class relationships, detailed design
explanations, and complete API documentation</li>
<li><strong>Database Schema</strong>: SQLite database supporting
persistent storage of posts, comments, and sentiment analysis
results</li>
</ol>
<p>This report documents the complete system architecture, design
decisions, implementation details, and the advanced Object-Oriented
Programming techniques employed throughout the development.</p>
<h2 id="members-and-task-assigment">2. Members and Task Assigment</h2>
<table>
<thead>
<tr>
<th style="text-align: left;">Member and Student ID</th>
<th style="text-align: left;">Task Assigment</th>
<th style="text-align: left;">Percentage of Contribution</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Nguyen Trung Hieu 202416689</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr>
<td style="text-align: left;">Nguyen Cong Hung 2024</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr>
<td style="text-align: left;">Tran Dang Minh 2024</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr>
<td style="text-align: left;">Vu Ha Anh Duc 2024</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr>
<td style="text-align: left;">Pham Minh Hieu 2024</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
</tbody>
</table>
<h2 id="teamwork-log">3. Teamwork Log</h2>
<h3 id="project-development-timeline">Project Development Timeline</h3>
<p>The Humanitarian Logistics Analysis System was developed over
approximately 10 weeks from September 3, 2024 to December 10, 2024.
Below is the chronological log of project phases and key milestones:</p>
<h4
id="phase-1-project-planning-and-requirements-analysis-september-3-14">Phase
1: Project Planning and Requirements Analysis (September 3-14)</h4>
<p><strong>Objectives</strong>: Define project scope, identify analysis
problems, and establish system architecture</p>
<p><strong>Key Activities</strong>: - Conducted requirements gathering
sessions defining two primary analysis problems - Researched and
selected technology stack (Java 11 for desktop, Python 3.12 for ML
services) - Evaluated existing solutions and identified unique features
needed - Sketched initial system architecture and component structure -
Evaluated machine learning models (xlm-roberta for sentiment, BART for
classification)</p>
<p><strong>Deliverables</strong>: Project specification document,
architecture design overview, technology evaluation report</p>
<p><strong>Status</strong>: ‚úì Completed</p>
<h4 id="phase-2-system-architecture-and-design-september-15-28">Phase 2:
System Architecture and Design (September 15-28)</h4>
<p><strong>Objectives</strong>: Finalize architecture and create
detailed design specifications</p>
<p><strong>Key Activities</strong>: - Designed seven-package
architecture with clear separation of concerns - Created package
dependency diagrams and class relationship structures - Defined
interfaces and abstract classes for all major components - Planned Maven
project structure with dependency management - Designed SQLite database
schema with normalized tables</p>
<p><strong>Deliverables</strong>: Complete UML architecture diagrams,
detailed design specifications, database schema</p>
<p><strong>Status</strong>: ‚úì Completed</p>
<h4
id="phase-3-core-model-and-infrastructure-implementation-september-29---october-12">Phase
3: Core Model and Infrastructure Implementation (September 29 - October
12)</h4>
<p><strong>Objectives</strong>: Implement foundational model classes and
infrastructure components</p>
<p><strong>Key Activities</strong>: - Implemented Post, YouTubePost,
Comment, Sentiment classes with proper encapsulation - Created
DisasterManager singleton with initialization logic - Set up Maven build
configuration and dependency management - Implemented DatabaseManager
with JDBC connectivity - Created basic SentimentAnalyzer implementations
(Simple and Enhanced versions)</p>
<p><strong>Deliverables</strong>: Complete Model package, database
connectivity layer, basic sentiment analysis</p>
<p><strong>Status</strong>: ‚úì Completed, Test Coverage: 90%+</p>
<h4
id="phase-4-data-collection-and-crawler-framework-october-13-26">Phase
4: Data Collection and Crawler Framework (October 13-26)</h4>
<p><strong>Objectives</strong>: Implement data collection from various
sources</p>
<p><strong>Key Activities</strong>: - Designed and implemented
DataCrawler interface with pluggable architecture - Created
CrawlerRegistry and CrawlerManager using Registry + Factory patterns -
Implemented MockDataCrawler for testing without external API calls -
Integrated YouTube API with YouTubeCrawler implementation - Implemented
YouTubeAPIHelper with authentication and pagination support</p>
<p><strong>Deliverables</strong>: Working crawler framework, YouTube
integration, mock data source</p>
<p><strong>Status</strong>: ‚úì Completed, 32 sample posts collected</p>
<h4
id="phase-5-user-interface-development-october-27---november-9">Phase 5:
User Interface Development (October 27 - November 9)</h4>
<p><strong>Objectives</strong>: Build desktop UI with all required
components and visualization</p>
<p><strong>Key Activities</strong>: - Implemented View class as main
JFrame with tabbed interface - Created DataCollectionPanel with crawler
selection and execution controls - Implemented AnalysisPanel with bar
charts and pie charts for Problem 1 - Created AdvancedAnalysisPanel with
time-series charts for Problem 2 - Added CommentManagementPanel with
JTable for data display - Integrated JFreeChart for professional data
visualization</p>
<p><strong>Deliverables</strong>: Complete desktop interface with 5+
specialized panels, interactive visualizations</p>
<p><strong>Status</strong>: ‚úì Completed</p>
<h4 id="phase-6-machine-learning-integration-november-10-23">Phase 6:
Machine Learning Integration (November 10-23)</h4>
<p><strong>Objectives</strong>: Integrate advanced ML models for
sentiment and category analysis</p>
<p><strong>Key Activities</strong>: - Developed Python Flask API
(sentiment_api.py) for ML services - Integrated xlm-roberta-large-xnli
model for multilingual sentiment analysis - Integrated
facebook/bart-large-mnli model for category classification - Implemented
PythonSentimentAnalyzer and PythonCategoryClassifier - Set up model
caching strategy for faster subsequent runs - Implemented fallback
mechanism (Python ‚Üí Enhanced ‚Üí Simple analyzers)</p>
<p><strong>Deliverables</strong>: Production ML backend service, working
sentiment and category classification</p>
<p><strong>Status</strong>: ‚úì Completed</p>
<h4
id="phase-7-analysis-modules-and-problem-solving-november-24---december-1">Phase
7: Analysis Modules and Problem Solving (November 24 - December 1)</h4>
<p><strong>Objectives</strong>: Implement specialized analysis engines
for both research problems</p>
<p><strong>Key Activities</strong>: - Implemented
SatisfactionAnalysisModule for Problem 1 (relief effectiveness analysis)
- Implemented TimeSeriesSentimentModule for Problem 2 (temporal
sentiment trends) - Created analysis result aggregation and filtering
logic - Implemented data export functionality (CSV format) - Integrated
analysis results with UI visualization</p>
<p><strong>Deliverables</strong>: Complete analysis pipeline for both
problems, export functionality</p>
<p><strong>Status</strong>: ‚úì Completed with 31 curated dataset</p>
<h4
id="phase-8-testing-quality-assurance-and-bug-fixes-december-2-6">Phase
8: Testing, Quality Assurance, and Bug Fixes (December 2-6)</h4>
<p><strong>Objectives</strong>: Ensure system reliability and resolve
issues</p>
<p><strong>Key Activities</strong>: - Conducted comprehensive system
testing across all components - Tested sentiment analyzer accuracy with
diverse text samples - Verified ML model performance metrics (inference
time, accuracy) - Performed UI testing and verified responsive layouts -
Fixed critical bugs and edge case handling - Executed performance
benchmarking</p>
<p><strong>Bug Resolution Summary</strong>: - Fixed potential
NullPointerException in CrawlerRegistry (improved error handling) -
Resolved sentiment analysis timeout by implementing batch processing -
Fixed UI thread blocking with ExecutorService for async ML calls -
Improved date parsing for temporal analysis across different locales -
Fixed data persistence edge cases</p>
<p><strong>Deliverables</strong>: Test results, bug reports, performance
benchmarks</p>
<p><strong>Status</strong>: ‚úì Completed, 32 issues logged and
resolved</p>
<h4 id="phase-9-documentation-and-report-writing-december-7-9">Phase 9:
Documentation and Report Writing (December 7-9)</h4>
<p><strong>Objectives</strong>: Create comprehensive technical
documentation and final report</p>
<p><strong>Key Activities</strong>: - Created detailed UML diagrams for
all 8 packages with class relationships - Documented package
architecture and design rationale - Wrote comprehensive OOP techniques
section with design patterns - Documented complete technology stack and
implementation details - Created user guide with operational
instructions - Compiled final project report with all sections</p>
<p><strong>Deliverables</strong>: Complete technical report (5
sections), UML diagrams, user guide</p>
<p><strong>Status</strong>: ‚úì Completed</p>
<h4
id="phase-10-final-review-and-submission-preparation-december-10">Phase
10: Final Review and Submission Preparation (December 10)</h4>
<p><strong>Objectives</strong>: Final quality assurance and project
submission</p>
<p><strong>Key Activities</strong>: - Conducted final review of all
documentation - Verified all UML diagrams render correctly -
Cross-checked all technical specifications - Prepared submission package
- Finalized report formatting and references</p>
<p><strong>Deliverables</strong>: Final submission-ready report and
codebase</p>
<p><strong>Status</strong>: ‚úì Completed</p>
<h3 id="project-statistics-and-metrics">Project Statistics and
Metrics</h3>
<table>
<colgroup>
<col style="width: 53%" />
<col style="width: 46%" />
</colgroup>
<thead>
<tr>
<th>Metric</th>
<th>Value</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Total Development Period</strong></td>
<td>10 weeks (Sep 3 - Dec 10, 2024)</td>
</tr>
<tr>
<td><strong>Team Weekly Meetings</strong></td>
<td>10 meetings (~20 hours total)</td>
</tr>
<tr>
<td><strong>Java Source Code</strong></td>
<td>5000+ lines across 8 packages</td>
</tr>
<tr>
<td><strong>Python ML Code</strong></td>
<td>500+ lines (Flask API, model integration)</td>
</tr>
<tr>
<td><strong>Unit Test Coverage</strong></td>
<td>90%+ of Model package</td>
</tr>
<tr>
<td><strong>Test Cases Written</strong></td>
<td>45+ test cases across all packages</td>
</tr>
<tr>
<td><strong>Issues Identified</strong></td>
<td>32 issues during development/testing</td>
</tr>
<tr>
<td><strong>Issues Resolved</strong></td>
<td>32 issues (100% resolution rate)</td>
</tr>
<tr>
<td><strong>Documentation</strong></td>
<td>5 major report sections with UML diagrams</td>
</tr>
<tr>
<td><strong>System Performance</strong></td>
<td>30 seconds startup (cached), 50-200ms analysis</td>
</tr>
</tbody>
</table>
<h3 id="key-milestones">Key Milestones</h3>
<table>
<thead>
<tr>
<th>Date</th>
<th>Milestone</th>
<th>Status</th>
</tr>
</thead>
<tbody>
<tr>
<td>Sep 14</td>
<td>Architecture design finalized</td>
<td>‚úì</td>
</tr>
<tr>
<td>Sep 28</td>
<td>Core model implementation complete</td>
<td>‚úì</td>
</tr>
<tr>
<td>Oct 12</td>
<td>Data crawler framework operational</td>
<td>‚úì</td>
</tr>
<tr>
<td>Oct 26</td>
<td>User interface fully implemented</td>
<td>‚úì</td>
</tr>
<tr>
<td>Nov 9</td>
<td>ML integration complete</td>
<td>‚úì</td>
</tr>
<tr>
<td>Nov 23</td>
<td>Analysis modules working for both problems</td>
<td>‚úì</td>
</tr>
<tr>
<td>Dec 1</td>
<td>Testing and QA phase complete</td>
<td>‚úì</td>
</tr>
<tr>
<td>Dec 9</td>
<td>Documentation and report finalized</td>
<td>‚úì</td>
</tr>
<tr>
<td>Dec 10</td>
<td>Final submission ready</td>
<td>‚úì</td>
</tr>
</tbody>
</table>
<h2 id="user-guide">4. User Guide</h2>
<h3 id="introduction">4.1 Introduction</h3>
<p>The Humanitarian Logistics Analysis System is a desktop application
designed to analyze sentiment and satisfaction with humanitarian relief
efforts during disaster response. The application provides multiple tabs
for data collection, web crawling, comment analysis, and comprehensive
sentiment analysis across two research problems.</p>
<h3 id="system-requirements">4.2 System Requirements</h3>
<p>Before installing the application, ensure your computer meets the
following minimum requirements:</p>
<table>
<colgroup>
<col style="width: 46%" />
<col style="width: 53%" />
</colgroup>
<thead>
<tr>
<th>Requirement</th>
<th>Specification</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Operating System</strong></td>
<td>Windows, macOS, or Linux</td>
</tr>
<tr>
<td><strong>Java Version</strong></td>
<td>Java 11 or higher</td>
</tr>
<tr>
<td><strong>Maven Version</strong></td>
<td>3.6 or higher</td>
</tr>
<tr>
<td><strong>Python Version</strong></td>
<td>3.8 or higher</td>
</tr>
<tr>
<td><strong>RAM</strong></td>
<td>Minimum 4GB (8GB recommended)</td>
</tr>
<tr>
<td><strong>Hard Disk Space</strong></td>
<td>5GB minimum (for ML models and database)</td>
</tr>
<tr>
<td><strong>Network</strong></td>
<td>Internet connection required for first-time ML model download</td>
</tr>
</tbody>
</table>
<p>You can check your installed versions by running:</p>
<div class="sourceCode" id="cb1"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="ex">java</span> <span class="at">-version</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="ex">mvn</span> <span class="at">--version</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="ex">python3</span> <span class="at">--version</span></span></code></pre></div>
<h3 id="installation-guide">4.3 Installation Guide</h3>
<p>The installation process downloads and configures all required
components including Java dependencies, Python packages, and machine
learning models. The first installation takes 10-15 minutes due to
downloading approximately 2GB of ML models.</p>
<h4 id="step-1-navigate-to-project-directory">Step 1: Navigate to
Project Directory</h4>
<p>Open a terminal (Command Prompt on Windows, Terminal on macOS/Linux)
and navigate to the project folder:</p>
<div class="sourceCode" id="cb2"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> humanitarian-logistics</span></code></pre></div>
<p>This directory contains the <code>install.sh</code> script that
automates the installation process.</p>
<h4 id="step-2-run-installation-script">Step 2: Run Installation
Script</h4>
<p>Execute the installation script:</p>
<div class="sourceCode" id="cb3"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">bash</span> install.sh</span></code></pre></div>
<p>This script will automatically: - Check if Java 11+ is installed, or
provide installation instructions - Check if Maven 3.6+ is installed, or
provide installation instructions - Check if Python 3.8+ is installed,
or provide installation instructions - Download and compile the Java
application - Install Python dependencies (Flask, Transformers, PyTorch)
- Download machine learning models (xlm-roberta and BART models, ~2GB
total)</p>
<p><strong>Expected Output:</strong></p>
<pre><code>Checking Java installation... [OK]
Checking Maven installation... [OK]
Checking Python installation... [OK]
Building Java application... [OK]
Installing Python dependencies... [OK]
Downloading ML models... [OK]
Installation complete!</code></pre>
<h4 id="step-3-manual-ml-model-download-recommended">Step 3: Manual ML
Model Download (Recommended)</h4>
<p>To ensure the machine learning models are successfully downloaded
before running the full application, it is recommended to manually run
the Python sentiment API script first. This allows the system to
download models in a controlled manner and verify successful
completion:</p>
<div class="sourceCode" id="cb5"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> src/main/python</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="ex">python3</span> sentiment_api.py</span></code></pre></div>
<p>This command will: - Start the Python Flask API server -
Automatically download xlm-roberta-large-xnli model (~2GB) on first run
- Automatically download facebook/bart-large-mnli model (~1.6GB) on
first run - Print messages showing download progress and completion</p>
<p>You will see output similar to:</p>
<pre><code>Downloading xlm-roberta-large-xnli model...
This may take 5-10 minutes... [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 100%
Model downloaded and cached successfully.

Downloading facebook/bart-large-mnli model...
This may take 3-5 minutes... [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 100%
Model downloaded and cached successfully.

Flask API server running on http://localhost:5001</code></pre>
<p><strong>Once you see ‚ÄúFlask API server running on
http://localhost:5001‚Äù, the models are successfully downloaded.</strong>
You can then stop this process by pressing <code>Ctrl+C</code>.</p>
<p><strong>Why do this manually?</strong> - <strong>Ensures successful
model download</strong> before the full application starts -
<strong>Shows clear progress</strong> of model downloading -
<strong>Allows troubleshooting</strong> if network issues occur during
download - <strong>Speeds up application startup</strong> when you run
the full app later (models are already cached)</p>
<p>If model download fails due to network issues, simply run this
command again:</p>
<div class="sourceCode" id="cb7"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="ex">python3</span> sentiment_api.py</span></code></pre></div>
<h3 id="running-the-application">4.4 Running the Application</h3>
<p>After installation is complete, running the application is simple and
much faster (approximately 30 seconds startup time with cached
models).</p>
<h4 id="using-the-run-script-recommended">Using the Run Script
(Recommended)</h4>
<p>From the <code>humanitarian-logistics</code> directory, execute:</p>
<div class="sourceCode" id="cb8"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="fu">bash</span> run.sh</span></code></pre></div>
<p>This script will: 1. Start the Python ML API server in the background
2. Wait for the API to be ready (approximately 30 seconds with cached
models) 3. Launch the Java desktop application 4. Display the main
application window</p>
<p><strong>Expected Output:</strong></p>
<pre><code>Starting ML API server...
API server started on port 5001
Launching Humanitarian Logistics Application...
[Main application window appears]</code></pre>
<h4 id="manual-startup-advanced">Manual Startup (Advanced)</h4>
<p>If you prefer to start components manually:</p>
<p><strong>Terminal 1 - Start Python API:</strong></p>
<div class="sourceCode" id="cb10"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> humanitarian-logistics/src/main/python</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="ex">python3</span> sentiment_api.py</span></code></pre></div>
<p><strong>Terminal 2 - Start Java Application:</strong></p>
<div class="sourceCode" id="cb11"><pre
class="sourceCode bash"><code class="sourceCode bash"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> humanitarian-logistics</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="ex">java -jar</span> target/humanitarian-logistics-1.0-SNAPSHOT-jar-with-dependencies.jar</span></code></pre></div>
<p>Ensure the Python API is running before or simultaneously with the
Java application.</p>
<h3 id="application-interface-overview">4.5 Application Interface
Overview</h3>
<p>The application features a tabbed interface with four main functional
areas, designed for a complete sentiment analysis workflow. Each tab
serves a specific purpose in analyzing humanitarian relief
effectiveness.</p>
<figure>
<img src="resource/EmptyAnalysisTab.png" style="width:85.0%"
alt="Application Interface Overview" />
<figcaption aria-hidden="true">Application Interface
Overview</figcaption>
</figure>
<p>The interface displays four main tabs: <strong>Analysis</strong> (üìä)
for viewing sentiment analysis results, <strong>Comments
Manager</strong> (üí¨) for managing data, <strong>Crawl Web</strong> (üåê)
for collecting data from YouTube, and <strong>Data Entry</strong> (‚úèÔ∏è)
for manual data input.</p>
<h3 id="tab-1-analysis">4.6 Tab 1: Analysis (üìä)</h3>
<p>The <strong>Analysis</strong> tab is the primary interface for
viewing sentiment analysis results and exploring how relief efforts are
perceived by affected populations. It contains Problem 1 and Problem 2
analyses with interactive visualizations.</p>
<h4 id="problem-1-relief-category-effectiveness">4.6.1 Problem 1: Relief
Category Effectiveness</h4>
<p><strong>Problem 1</strong> answers: <em>Which relief item categories
receive the highest satisfaction?</em></p>
<p><strong>Before Analysis:</strong></p>
<figure>
<img src="resource/EmptyAnalysisTab.png" style="width:85.0%"
alt="Empty Analysis Tab" />
<figcaption aria-hidden="true">Empty Analysis Tab</figcaption>
</figure>
<p>Before performing analysis, the tab displays an empty state with
controls ready for analysis.</p>
<p><strong>Step 1: Run Analysis</strong></p>
<p>Click the <strong>‚ÄúAnalyze All with Python API‚Äù</strong> button to: -
Send all posts and comments to the Python ML backend - Assign sentiment
(POSITIVE/NEGATIVE/NEUTRAL) to each comment - Identify relief categories
(CASH, MEDICAL, SHELTER, FOOD, TRANSPORTATION) mentioned in each
comment - Store results in the database</p>
<p><strong>Step 2: Customize Visualization</strong></p>
<p>After analysis completes, customize what to display: -
<strong>Disaster Type</strong>: Select a specific disaster or ‚ÄúAll
Disasters‚Äù to combine data - <strong>Relief Category</strong>: Choose a
specific category (e.g., FOOD) or ‚ÄúAll Categories‚Äù for all types -
<strong>Chart Type</strong>: Select between: - <strong>Bar
Chart</strong>: Shows exact counts of sentiment or categories -
<strong>Pie Chart</strong>: Shows proportional distribution
(percentages)</p>
<p><strong>Step 3: Click Visualize</strong></p>
<p>Once filters are set, click <strong>‚ÄúVisualize‚Äù</strong> to refresh
charts with your selections.</p>
<figure>
<img src="resource/Problem1ByCategory.png" style="width:85.0%"
alt="Problem 1 Diagram" />
<figcaption aria-hidden="true">Problem 1 Diagram</figcaption>
</figure>
<p><strong>Sentiment Tab - Overall Distribution:</strong></p>
<figure>
<img src="resource/Problem1Sentiment.png" style="width:85.0%"
alt="Problem 1 Sentiment" />
<figcaption aria-hidden="true">Problem 1 Sentiment</figcaption>
</figure>
<p>This tab shows the overall sentiment distribution across all analyzed
posts: - <strong>Pie Chart Display</strong>: Segments represent
POSITIVE, NEGATIVE, and NEUTRAL sentiments - <strong>What it
Means</strong>: - Large POSITIVE segment ‚Üí Most affected people
satisfied with relief - Large NEGATIVE segment ‚Üí Significant
dissatisfaction exists - Large NEUTRAL segment ‚Üí Many informational
posts without emotional tone</p>
<p><strong>Use This To</strong>: Determine if relief operations are
generally well-received or problematic</p>
<h4 id="problem-2-temporal-sentiment-analysis">4.6.2 Problem 2: Temporal
Sentiment Analysis</h4>
<p><strong>Problem 2</strong> answers: <em>How does sentiment toward
relief efforts change over time?</em></p>
<p>This tab provides three different perspectives on how sentiment
evolves during the disaster response.</p>
<p><strong>Three Analysis Options:</strong></p>
<p><strong>1. View By Category</strong> - Select a specific relief
category (CASH, MEDICAL, SHELTER, FOOD, TRANSPORTATION) - See
line chart showing how sentiment for that category changed over time -
Understand if that specific aid type improved or declined during
response</p>
<p><strong>2. View Overall Timeline</strong> - See all sentiments
combined over the disaster response period - Identify critical periods
when satisfaction peaked or dropped - Understand if relief efforts
improved public perception over time</p>
<p><strong>3. View Statistics Report</strong> - Detailed table with
numerical breakdown by time period - Columns show: time period, POSITIVE
count, NEGATIVE count, NEUTRAL count, percentages - Export or review
exact numbers for presentations</p>
<p><strong>Visualization 1: Overall Sentiment Timeline</strong></p>
<figure>
<img src="resource/Problem2Overtime.png" style="width:85.0%"
alt="Problem 2 Overall Timeline" />
<figcaption aria-hidden="true">Problem 2 Overall Timeline</figcaption>
</figure>
<ul>
<li><strong>X-axis</strong>: Timeline of disaster response
(days/weeks)</li>
<li><strong>Y-axis</strong>: Number of posts with each sentiment</li>
<li><strong>Lines</strong>: Separate trends for POSITIVE, NEGATIVE,
NEUTRAL</li>
<li><strong>Interpretation</strong>: Upward POSITIVE line means growing
satisfaction; downward means declining</li>
</ul>
<p><strong>Visualization 2: Sentiment by Category Over Time</strong></p>
<figure>
<img src="resource/Problem2ByCategory.png" style="width:85.0%"
alt="Problem 2 By Category" />
<figcaption aria-hidden="true">Problem 2 By Category</figcaption>
</figure>
<ul>
<li><strong>Multiple Lines</strong>: Each relief category has its own
trend line</li>
<li><strong>X-axis</strong>: Timeline of disaster response</li>
<li><strong>Y-axis</strong>: Sentiment scores</li>
<li><strong>Interpretation</strong>: Different categories may follow
different trajectories; some improve while others decline</li>
</ul>
<p><strong>Visualization 3: Statistics Report</strong></p>
<figure>
<img src="resource/Problem2Sentiment.png" style="width:85.0%"
alt="Problem 2 Statistics" />
<figcaption aria-hidden="true">Problem 2 Statistics</figcaption>
</figure>
<ul>
<li><strong>Format</strong>: Detailed breakdown of sentiment data</li>
<li><strong>Contents</strong>: Time period, POSITIVE count, NEGATIVE
count, NEUTRAL count, percentages, totals</li>
<li><strong>Use For</strong>: Exact numbers for reports, detailed
comparisons between time periods</li>
</ul>
<h4 id="combined-report">4.6.3 Combined Report</h4>
<p><strong>Combined Report</strong> synthesizes all analysis findings
into a comprehensive narrative.</p>
<p><strong>How to Generate:</strong> 1. After completing Problem 1 and
Problem 2 analyses 2. Click <strong>‚ÄúCombined Report‚Äù</strong>
button/tab 3. Choose scope: - <strong>Specific Disaster</strong>: Report
for one selected disaster type - <strong>All Disasters</strong>:
Comprehensive report combining all disaster responses</p>
<p><strong>Report Contents:</strong></p>
<figure>
<img src="resource/CombinedReport.png" style="width:85.0%"
alt="Combined Report" />
<figcaption aria-hidden="true">Combined Report</figcaption>
</figure>
<p>The report includes: - <strong>Executive Summary</strong>: Key
findings at a glance - <strong>Overall Statistics</strong>: Total posts
analyzed, sentiment distribution, time period covered - <strong>Problem
1 Summary</strong>: Most/least satisfied categories, overall
percentages, category breakdown - <strong>Problem 2 Summary</strong>:
Timeline of changes, critical periods, temporal patterns -
<strong>Critical Insights</strong>: Most important findings requiring
attention - <strong>Recommendations</strong>: Suggested improvements for
future relief operations</p>
<p><strong>Use For</strong>: Presenting to organizations, documenting
results, justifying resource allocation decisions</p>
<h3 id="tab-2-comments-manager">4.7 Tab 2: Comments Manager (üí¨)</h3>
<p>The <strong>Comments Manager</strong> tab allows you to review, edit,
and manage all collected data. This is where you can verify analysis
accuracy and make corrections.</p>
<figure>
<img src="resource/CommentManageTable.png" style="width:85.0%"
alt="Comments Manager Tab" />
<figcaption aria-hidden="true">Comments Manager Tab</figcaption>
</figure>
<p><strong>Four Core Operations:</strong></p>
<p><strong>1. Edit Comments</strong> - Click any comment row to select
it - Click <strong>‚ÄúEdit‚Äù</strong> button to modify - Change: comment
text, sentiment, relief category, disaster type - Click
<strong>‚ÄúSave‚Äù</strong> to update database</p>
<p><strong>2. Delete Comments</strong> - Select one or multiple comments
by clicking rows - Click <strong>‚ÄúDelete‚Äù</strong> button - Confirm
deletion - Comments permanently removed from database</p>
<p><strong>3. Use Our Database</strong> - Click <strong>‚ÄúUse Our
Database‚Äù</strong> to load pre-built sample database - Contains
pre-curated posts from humanitarian logistics scenarios - Useful for:
understanding patterns, demonstrating system capabilities -
<strong>Warning</strong>: Replaces current database with sample
dataset</p>
<p><strong>4. Reset Database</strong> - Click <strong>‚ÄúReset
Database‚Äù</strong> to clear all data - All posts, comments, and analysis
results deleted - Returns to empty database state -
<strong>Warning</strong>: This action cannot be undone</p>
<p><strong>Table Columns Display:</strong> - <strong>Post ID</strong>:
Identifier for original post - <strong>Author</strong>: Name/username of
commenter - <strong>Content</strong>: Full text of comment -
<strong>Created At</strong>: Timestamp when posted -
<strong>Sentiment</strong>: Current sentiment classification
(POSITIVE/NEGATIVE/NEUTRAL) - <strong>Category</strong>: Assigned relief
category (CASH, MEDICAL, SHELTER, FOOD, TRANSPORTATION) - <strong>Disaster Type</strong>:
Classified disaster type</p>
<h3 id="tab-3-crawl-web">4.8 Tab 3: Crawl Web (üåê)</h3>
<p>The <strong>Crawl Web</strong> tab collects real data from YouTube.
It supports two crawling modes for different use cases.</p>
<figure>
<img src="resource/WebCrawler.png" style="width:85.0%"
alt="Crawl Web Tab" />
<figcaption aria-hidden="true">Crawl Web Tab</figcaption>
</figure>
<p><strong>Mode 1: Crawl by Keywords/Hashtags</strong></p>
<p>Search for videos and comments matching specific keywords about
disaster relief.</p>
<p><strong>How to Use:</strong> 1. Select
<strong>‚ÄúKeywords/Hashtags‚Äù</strong> mode 2. Enter search terms: -
Example: <code>"earthquake relief Turkey"</code> or
<code>"flood disaster #disasteraid"</code> - Separate multiple keywords
by pressing Enter (one keyword per line) 3. Set <strong>Post
Limit</strong>: Maximum number of videos to search (e.g., 30) 4. Set
<strong>Comment Limit</strong>: Maximum comments per video (e.g., 50) 5.
Click <strong>‚ÄúStart Crawling‚Äù</strong> 6. Monitor progress bar in
real-time 7. Results display number of posts collected and errors (if
any)</p>
<p><strong>When to Use</strong>: General disaster relief sentiment,
diverse geographic perspectives, exploring different aspects of
response</p>
<p><strong>Mode 2: Crawl by Video Link</strong></p>
<p>Extract all comments from a specific YouTube video.</p>
<p><strong>How to Use:</strong> 1. Select <strong>‚ÄúVideo Link‚Äù</strong>
mode 2. Paste YouTube URL:
<code>https://www.youtube.com/watch?v=VIDEO_ID</code> 3. Set
<strong>Comment Limit</strong>: Maximum comments to extract (e.g., 50)
4. Click <strong>‚ÄúStart Crawling‚Äù</strong> 5. System extracts comments
from that video 6. All comments added to database as posts</p>
<p><strong>When to Use</strong>: Analyzing response to specific news
video, organization announcements, targeted incident analysis</p>
<p><strong>Processing Details:</strong> -
<strong>HTTP Crawling</strong>: Fetches YouTube watch pages via Java HttpClient, parses HTML with regex patterns to extract video data -
<strong>Metadata</strong>: Saves author names, timestamps, video
information - <strong>Error Handling</strong>: Continues even if some
videos fail, reports issues at end - <strong>Performance</strong>:
Direct HTML parsing is faster than API and doesn't require authentication</p>
<p><strong>Typical Times:</strong> - Small crawl (10-20 posts): 2-3
minutes - Medium crawl (30-50 posts): 5-10 minutes - Large crawl (100+
posts): 15-30 minutes</p>
<h3 id="tab-4-data-entry">4.9 Tab 4: Data Entry (‚úèÔ∏è)</h3>
<p>The <strong>Data Entry</strong> tab allows manual input of posts with
comments for custom data scenarios. Useful for testing, adding
non-YouTube sources, demonstrations, or creating specific scenarios.</p>
<figure>
<img src="resource/DataEntry.png" style="width:85.0%"
alt="Data Entry Tab" />
<figcaption aria-hidden="true">Data Entry Tab</figcaption>
</figure>
<p><strong>Interface Overview:</strong></p>
<p>The Data Entry tab is divided into two main sections:</p>
<p><strong>Left Section - Post Information:</strong> -
<strong>Author</strong>: Text field for post creator name (default:
‚ÄúAnonymous‚Äù) - <strong>Disaster Type</strong>: Dropdown selector for
disaster category - <strong>Relief Category</strong>: Dropdown for
primary relief item type mentioned - <strong>Sentiment</strong>:
Dropdown for manual sentiment assignment (POSITIVE/NEGATIVE/NEUTRAL) -
<strong>Confidence</strong>: Slider (0.0 - 1.0) indicating
classification confidence - <strong>Post Content</strong>: Large text
area for the main post message</p>
<p><strong>Right Section - Comments:</strong> - <strong>Comments
Header</strong>: ‚ÄúEnter each comment on a new line‚Äù - <strong>Comments
Area</strong>: Large text field for entering comments -
<strong>Format</strong>: Each line = one separate comment -
<strong>Links</strong>: All comments automatically linked to the post
above</p>
<p><strong>Step-by-Step Process:</strong></p>
<p><strong>Step 1: Enter Post Author (Optional)</strong> 1. Click
‚ÄúAuthor‚Äù field 2. Type name, username, or organization 3. Leave blank
for ‚ÄúAnonymous‚Äù 4. Example: <code>Relief_Organization_XYZ</code>,
<code>John_Smith</code>, <code>Red_Cross_Team</code></p>
<p><strong>Step 2: Select Disaster Type</strong> 1. Click ‚ÄúDisaster
Type‚Äù dropdown 2. Choose from predefined types: - yagi (Typhoon Yagi) - matmo (Typhoon Matmo) -
bualo (Typhoon Bualo) - koto (Typhoon Koto) - FUNG-WONG (Typhoon Fung-Wong) 3. Selection
applies to entire post</p>
<p><strong>Step 3: Assign Relief Category (Optional)</strong> 1. Click
‚ÄúRelief Category‚Äù dropdown 2. Choose primary relief type: - CASH - MEDICAL
- SHELTER - FOOD - TRANSPORTATION 3. Or leave for ML to
classify</p>
<p><strong>Step 4: Set Sentiment &amp; Confidence (Optional)</strong> 1.
Click ‚ÄúSentiment‚Äù dropdown 2. Select: POSITIVE, NEGATIVE, or NEUTRAL 3.
Adjust ‚ÄúConfidence‚Äù slider (0.0 = uncertain, 1.0 = certain) 4. Leave
blank for ML to classify automatically</p>
<p><strong>Step 5: Enter Post Content</strong> 1. Click ‚ÄúPost Content‚Äù
text area 2. Type the main post/message 3. Single or multiple lines
allowed 4. Should be 1-3 sentences for realism 5. Keep natural language
for better ML analysis</p>
<p><strong>Step 6: Enter Comments (One Per Line)</strong> 1. Click
‚ÄúComments‚Äù text area 2. Type first comment, press Enter 3. Type second
comment, press Enter 4. Continue for all comments 5. <strong>Each line =
one separate comment</strong> 6. Comments automatically link to post
above 7. Recommended: 3-10 comments per post</p>
<p><strong>Step 7: Submit</strong> 1. Click green <strong>‚ÄúSave Post
&amp; Comments‚Äù</strong> button 2. System validates data 3. Post and
comments added to database 4. Status shows: ‚ÄúReady to add new post with
comments‚Äù 5. Post Counter updates (bottom right)</p>
<p><strong>Example Entry:</strong></p>
<p><strong>Input Data:</strong></p>
<pre><code>Author: Relief_Organization
Disaster Type: yagi
Relief Category: SHELTER
Sentiment: (leave for ML)
Confidence: (default)

Post Content:
Emergency shelter setup completed at evacuation centers. Over 500 families now have safe accommodation.

Comments (one per line):
Finally my family has a safe place to sleep
The shelter is crowded but better than outside
Thank you relief workers for your work
We need more blankets and warm clothes
Medical tent is excellent
When will we get permanent housing
The food portions are too small
Relief staff doing amazing job</code></pre>
<p><strong>Result:</strong> - <strong>1 Post</strong> created with
pre-filled fields - <strong>8 Comments</strong> linked to this post -
All assigned: Disaster Type = yagi, Relief Category = SHELTER,
Author = Relief_Organization - Ready for analysis after clicking ‚ÄúSave
Post &amp; Comments‚Äù</p>
<p><strong>Multiple Entries Workflow:</strong></p>
<ol type="1">
<li>After clicking ‚ÄúSave Post &amp; Comments‚Äù, the form clears</li>
<li>Status shows ‚ÄúReady to add new post with comments‚Äù</li>
<li>Enter next post‚Äôs information</li>
<li>Post Counter (bottom right) updates</li>
<li>Repeat for additional posts</li>
<li>Click <strong>‚ÄúClear‚Äù</strong> button to reset current entry</li>
</ol>
<p><strong>Best Practices:</strong></p>
<table>
<colgroup>
<col style="width: 33%" />
<col style="width: 66%" />
</colgroup>
<thead>
<tr>
<th>Aspect</th>
<th>Recommendation</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Language</strong></td>
<td>Natural, conversational tone (not formal)</td>
</tr>
<tr>
<td><strong>Diversity</strong></td>
<td>Mix positive, negative, neutral sentiments</td>
</tr>
<tr>
<td><strong>Length</strong></td>
<td>1-3 sentences per comment, realistic</td>
</tr>
<tr>
<td><strong>Relief Items</strong></td>
<td>Reference actual aid types (cash, medical, shelter, food, transportation)</td>
</tr>
<tr>
<td><strong>Disaster Types</strong></td>
<td>Match actual disaster in content</td>
</tr>
<tr>
<td><strong>Comment Count</strong></td>
<td>5-10 comments per post for good data</td>
</tr>
<tr>
<td><strong>Realism</strong></td>
<td>Avoid test phrases like ‚Äútest data‚Äù, use natural scenarios</td>
</tr>
<tr>
<td><strong>Time Variation</strong></td>
<td>For temporal analysis, vary timestamps across posts</td>
</tr>
</tbody>
</table>
<p><strong>Common Use Cases:</strong></p>
<ol type="1">
<li><strong>System Testing</strong>: Quick validation of analysis
pipeline
<ul>
<li>3-5 posts with 3-5 comments each</li>
<li>Clear positive/negative examples</li>
</ul></li>
<li><strong>Feature Demonstration</strong>: Show system capabilities
<ul>
<li>5-10 diverse posts</li>
<li>Multiple disaster types</li>
<li>Clear sentiment variation</li>
</ul></li>
<li><strong>Custom Analysis</strong>: Analyze specific scenario
<ul>
<li>Posts from specific disaster</li>
<li>Time-bound data</li>
<li>Particular relief focus</li>
</ul></li>
<li><strong>Data Augmentation</strong>: Add to existing database
<ul>
<li>Complement web crawled data</li>
<li>Fill gaps in categories</li>
<li>Add specific perspectives</li>
</ul></li>
</ol>
<p><strong>Validation &amp; Error Handling:</strong></p>
<table>
<colgroup>
<col style="width: 35%" />
<col style="width: 40%" />
<col style="width: 25%" />
</colgroup>
<thead>
<tr>
<th>Error</th>
<th>Reason</th>
<th>Fix</th>
</tr>
</thead>
<tbody>
<tr>
<td>Button disabled</td>
<td>Required fields empty</td>
<td>Fill Author OR Disaster Type</td>
</tr>
<tr>
<td>Nothing happens</td>
<td>All fields empty</td>
<td>Enter at least post content</td>
</tr>
<tr>
<td>Count doesn‚Äôt increase</td>
<td>Submit failed silently</td>
<td>Check system status bar</td>
</tr>
<tr>
<td>Comments not saved</td>
<td>Wrong format</td>
<td>Ensure each comment on separate line</td>
</tr>
</tbody>
</table>
<h3 id="complete-analysis-workflow">4.10 Complete Analysis Workflow</h3>
<p>Here‚Äôs the typical end-to-end process:</p>
<p><strong>Step 1: Data Collection</strong> (Choose One) - <strong>Web
Crawler</strong>: Use ‚ÄúCrawl Web‚Äù tab with keywords to get YouTube
comments - <strong>Sample Database</strong>: Use ‚ÄúUse Our Database‚Äù in
Comments Manager (instant 31 posts) - <strong>Manual Entry</strong>: Use
‚ÄúData Entry‚Äù tab to manually input custom data</p>
<p><strong>Step 2: Run Analysis</strong> 1. Go to
<strong>Analysis</strong> tab 2. Click <strong>‚ÄúAnalyze All with Python
API‚Äù</strong> button 3. Wait for completion (30-60 seconds) 4.
Confirmation message appears</p>
<p><strong>Step 3: Explore Problem 1 Results</strong> 1. Set Disaster
Type and Relief Category filters 2. Choose Bar or Pie chart 3. Click
<strong>‚ÄúVisualize‚Äù</strong> 4. Review which categories have
highest/lowest satisfaction</p>
<p><strong>Step 4: Explore Problem 2 Results</strong> 1. Go to
<strong>Problem 2 Temporal</strong> section 2. Choose view type (By
Category, Overall Timeline, or Statistics) 3. Review how sentiment
changed over time 4. Identify critical periods and trends</p>
<p><strong>Step 5: Verify Raw Data</strong> 1. Go to <strong>Comments
Manager</strong> tab 2. Scroll through and spot-check comments 3. Verify
sentiment and category assignments 4. Edit any incorrect
classifications</p>
<p><strong>Step 6: Generate Final Report</strong> 1. Return to
<strong>Analysis</strong> tab 2. Click <strong>‚ÄúCombined
Report‚Äù</strong> 3. Choose scope (specific disaster or all) 4. Review
comprehensive findings 5. Export or save for presentation</p>
<h3 id="tips-and-best-practices">4.11 Tips and Best Practices</h3>
<p><strong>Data Collection Tips:</strong> - Larger datasets (50-100
posts) provide more reliable results - Include data from multiple time
periods for complete disaster response arc - Diverse geographic regions
provide comprehensive perspective - Time-series analysis requires posts
spanning several days/weeks</p>
<p><strong>Analysis Interpretation:</strong> - Problem 1 shows which
categories need improvement (low sentiment) - Problem 2 shows when
problems occurred (drops in timeline) - Compare different disasters to
identify best practices - Use statistics report for precise percentages
in formal documents</p>
<p><strong>Performance Tips:</strong> - Analysis time scales with data
size (~1-2 seconds per post) - First run downloads ML models (5-10
minutes extra) - Subsequent runs faster (models cached) - Close other
applications if system seems slow</p>
<p><strong>Troubleshooting:</strong> - <strong>Analysis button
unresponsive</strong>: Ensure Python API running on port 5001 -
<strong>No data in comments</strong>: Retry data collection or load
sample database - <strong>Charts show ‚ÄúNo Data‚Äù</strong>: Click ‚ÄúAnalyze
All with Python API‚Äù first - <strong>Sentiment seems wrong</strong>:
Check Comments Manager, edit incorrect ones - <strong>Application
slow</strong>: Close other apps, try with smaller dataset</p>
<h2 id="collected-data-summarization">5. Collected Data
Summarization</h2>
<p><em>To be completed with actual sample data analysis results from the
application.</em></p>
<h2 id="uml-diagrams-and-design-explaination">6. UML Diagrams and Design
Explaination</h2>
<h3 id="rationale-for-dividing-class-diagrams-into-packages">6.1
Rationale for Dividing Class Diagrams into Packages</h3>
<p>The Humanitarian Logistics Analysis System is organized into seven
main packages, where each package represents a specific responsibility
within the overall architecture. Rather than creating a single
monolithic class diagram containing all 30+ classes, we have
deliberately divided the system into package-specific diagrams. This
modular approach to visualization provides several important
benefits:</p>
<p><strong>Readability and Comprehension</strong>: Each individual
diagram focuses on a specific functional area, allowing developers to
understand the architecture of a particular package without being
overwhelmed by excessive information. A compact, focused diagram is far
more digestible than a sprawling diagram with dozens of interconnected
classes.</p>
<p><strong>Maintainability and Scalability</strong>: When modifications
are needed to a specific package, only the corresponding diagram needs
to be updated, without affecting the diagrams of other packages. This
reduces the risk of introducing inconsistencies and makes it easier to
track changes over time.</p>
<p><strong>Reusability and Documentation</strong>: Smaller, focused
diagrams can be easily reused and referenced in various documentation
formats, including technical reports, presentation slides, architectural
documentation, and team wikis. A single large diagram would be difficult
to display or reference in these contexts.</p>
<p><strong>Hierarchical Understanding</strong>: The package dependency
diagram provides a bird‚Äôs-eye view of how all packages interact and
depend on each other, while the individual package diagrams show the
detailed internal structure and relationships within each package. This
two-level hierarchy makes it much easier to understand the system as a
whole and its individual components.</p>
<h3 id="package-dependency-diagram">6.2 Package Dependency Diagram</h3>
<p>The following diagram illustrates the dependency relationships
between all packages in the system and demonstrates how they interact
with each other:</p>
<div class="mermaid">
graph TB
    MainApp["üì¶ Main Application<br/>HumanitarianLogisticsApp"]
    
    UI["üì¶ UI Package<br/>View, Panels, Model, Utilities"]
    Crawler["üì¶ Crawler Package<br/>YouTubeCrawler, Registry, Manager"]
    Database["üì¶ Database Package<br/>DatabaseManager, Loader"]
    Sentiment["üì¶ Sentiment Package<br/>Analyzers, Classifiers"]
    Analysis["üì¶ Analysis Package<br/>SatisfactionModule, TimeSeriesModule"]
    Preprocessor["üì¶ Preprocessor Package<br/>TextPreprocessor, Classifier"]
    Model["üì¶ Model Package<br/>Post, Comment, Sentiment, Disaster"]
    Util["üì¶ Util Package<br/>StringSimilarity"]
    
    MainApp --> UI
    MainApp --> Model
    MainApp --> Crawler
    MainApp --> Database
    
    UI --> Model
    UI --> Crawler
    UI --> Database
    UI --> Sentiment
    UI --> Preprocessor
    UI --> Util
    
    Crawler --> Model
    Database --> Model
    Analysis --> Model
    Analysis --> Sentiment
    Sentiment --> Model
    Sentiment --> Preprocessor
    Preprocessor --> Model

    style Model fill:#e1f5ff,stroke:#01579b,stroke-width:3px
    style Crawler fill:#f3e5f5,stroke:#4a148c,stroke-width:2px
    style Sentiment fill:#fce4ec,stroke:#880e4f,stroke-width:2px
    style Preprocessor fill:#e8f5e9,stroke:#1b5e20,stroke-width:2px
    style Database fill:#fff3e0,stroke:#e65100,stroke-width:2px
    style Analysis fill:#fbe9e7,stroke:#bf360c,stroke-width:2px
    style UI fill:#f1f8e9,stroke:#33691e,stroke-width:2px
    style Util fill:#ede7f6,stroke:#311b92,stroke-width:2px
    style MainApp fill:#e0f2f1,stroke:#004d40,stroke-width:3px
</div>
<p><strong>Interpretation and Key Observations</strong>: The diagram
clearly shows that the Model package serves as the foundational layer
upon which all other packages depend. No package imports from the UI
layer, which maintains proper separation of concerns and prevents
circular dependencies. The crawler, sentiment analysis, analysis,
database, and preprocessor packages all depend on the Model package,
establishing a clear hierarchical structure. The UI package acts as an
orchestrator, coordinating interactions between the Model, database,
crawler, sentiment analysis, and preprocessor packages. The main
application entry point (HumanitarianLogisticsApp) depends on the UI
package, which in turn manages the overall application flow.</p>
<h3 id="detailed-class-diagrams-by-package">6.3 Detailed Class Diagrams
by Package</h3>
<h4 id="model-package---core-data-entities">6.3.1 Model Package - Core
Data Entities</h4>
<p>The Model package contains the fundamental data entities of the
entire system. Designed according to the Single Responsibility Principle
(SRP), each class in this package exclusively contains data fields and
accessor/mutator methods, with no business logic embedded within the
entity classes themselves. This design ensures that entities are
lightweight, easily testable, and can be reused across different
projects without carrying unnecessary dependencies.</p>
<div class="mermaid">
classDiagram
    class Post {
        -String postId
        -String content
        -String author
        -LocalDateTime createdAt
        -List~Comment~ comments
        -String disasterType
        +Post(String postId, String content, String author)
        +String getPostId()
        +String getContent()
        +String getAuthor()
        +LocalDateTime getCreatedAt()
        +List~Comment~ getComments()
        +void addComment(Comment comment)
        +String getDisasterType()
        +void setDisasterType(String disasterType)
    }

    class YouTubePost {
        -String videoId
        -String channelName
        -DisasterType disasterType
        +YouTubePost(String postId, String content, String author, String videoId)
        +String getVideoId()
        +String getChannelName()
        +void setChannelName(String channelName)
        +DisasterType getDisasterType()
        +void setDisasterType(DisasterType disasterType)
    }

    class Comment {
        -int commentId
        -String postId
        -String content
        -String author
        -LocalDateTime createdAt
        -String sentiment
        -double confidence
        -String reliefCategory
        -String disasterType
        +Comment(String postId, String content, String author)
        +int getCommentId()
        +String getPostId()
        +String getContent()
        +String getAuthor()
        +LocalDateTime getCreatedAt()
        +String getSentiment()
        +void setSentiment(String sentiment)
        +double getConfidence()
        +void setConfidence(double confidence)
        +String getReliefCategory()
        +void setReliefCategory(String reliefCategory)
        +String getDisasterType()
        +void setDisasterType(String disasterType)
    }

    class Sentiment {
        -String type
        -double confidence
        +Sentiment(String type, double confidence)
        +String getType()
        +double getConfidence()
        +boolean isPositive()
        +boolean isNegative()
    }

    class DisasterType {
        -String name
        -Set~String~ aliases
        +DisasterType(String name)
        +String getName()
        +void addAlias(String alias)
        +Set~String~ getAliases()
        +boolean matches(String keyword)
        +String normalize(String text)
    }

    class DisasterManager {
        -static DisasterManager instance
        -Map~String, DisasterType~ disasterTypes
        +DisasterManager()
        +static DisasterManager getInstance()
        +void addDisasterType(DisasterType disasterType)
        +DisasterType getDisasterType(String name)
        +DisasterType findDisasterType(String keyword)
        +List~String~ getAllDisasterNames()
        +Collection~DisasterType~ getAllDisasterTypes()
    }

    class ReliefItem {
        -String category
        -String description
        -int quantity
        +ReliefItem(String category, String description, int quantity)
        +String getCategory()
        +String getDescription()
        +int getQuantity()
        +void setQuantity(int quantity)
    }

    Post &lt;|-- YouTubePost
    Post &quot;1&quot; *-- &quot;*&quot; Comment
    Post &quot;1&quot; *-- &quot;*&quot; Comment
    DisasterManager &quot;1&quot; *-- &quot;*&quot; DisasterType
</div>
<p><strong>Design Architecture and Inheritance Strategy</strong>: The
Model package employs a carefully structured inheritance hierarchy
combined with composition patterns. The Post class serves as an abstract
base class that defines common properties and methods applicable to all
types of posts, including postId, content, author, createdAt, and a
collection of associated comments. The YouTubePost class extends Post to
provide YouTube-specific attributes such as videoId and channelName, as
well as associated disaster type information. This hierarchical design
enables polymorphic treatment of different post types without requiring
separate handling logic.</p>
<p>The DisasterManager class implements the Singleton design pattern,
ensuring that only a single instance exists throughout the application‚Äôs
lifetime. This is crucial for maintaining a consistent registry of
disaster types and preventing race conditions in multi-threaded
environments. The DisasterType class encapsulates disaster-related
information including the disaster name and a collection of aliases that
represent alternative names or keywords for the same disaster type,
enabling flexible matching against user input.</p>
<p><strong>Design Rationale and Benefits</strong>: The inheritance
structure allows for code reuse while maintaining type safety. When a
new post source is required (such as Facebook, Twitter, or Reddit),
developers only need to create a new subclass of Post without modifying
existing code. The Singleton pattern ensures that disaster type
information is managed consistently throughout the application,
preventing conflicts that might arise from multiple instances managing
the same data. Defensive copying and immutability of data structures
protect against unintended modifications and make the code more
predictable and thread-safe.</p>
<p><strong>Reusability and Extensibility</strong>: The design of the
Model package ensures that these entity classes can be reused in other
projects without carrying unnecessary dependencies. The Post class and
its subclasses represent pure data containers that can be easily
serialized to databases, transmitted over networks, or stored in files.
The clean separation of concerns in this package allows for independent
evolution of the model layer without affecting business logic
layers.</p>
<h4
id="ui-package---user-interface-implementation-with-mvc-architecture">6.3.2
UI Package - User Interface Implementation with MVC Architecture</h4>
<p>The UI package contains all graphical user interface components and
implements a strict Model-View-Controller (MVC) architectural pattern.
This package is particularly important as it demonstrates how a complex
user interface can be decomposed into manageable, specialized components
while maintaining clean communication patterns between the view and
model layers.</p>
<div class="mermaid">
classDiagram
    class View {
        -JFrame mainFrame
        -JTabbedPane mainTabbedPane
        -AnalysisPanel analysisPanel
        -CommentManagementPanel commentPanel
        -CrawlControlPanel crawlPanel
        -DataCollectionPanel dataCollectionPanel
        +View()
        +void initializeUI()
        +void show()
        +void addListener(ModelListener listener)
    }

    class CrawlControlPanel {
        -JTextArea crawlResultsArea
        -JTextField keywordField
        -JSpinner postLimitSpinner
        -JComboBox crawlerComboBox
        -CrawlerRegistry crawlerRegistry
        -Model model
        +CrawlControlPanel(Model model)
        +void startCrawling()
        +void updateCrawlResults(List~Post~ posts)
    }

    class DataCollectionPanel {
        -JTabbedPane tabbedPane
        -CrawlControlPanel crawlPanel
        +DataCollectionPanel(Model model)
        +JTabbedPane getTabbedPane()
    }

    class CommentManagementPanel {
        -JTable commentTable
        -Model model
        +CommentManagementPanel(Model model)
        +void refreshCommentTable()
        +void loadComments()
    }

    class AnalysisPanel {
        -JPanel chartPanel
        -List~Post~ posts
        -List~Comment~ comments
        +AnalysisPanel(Model model)
        +void displayAnalysis()
        +void generateCharts()
    }

    class AdvancedAnalysisPanel {
        -JTabbedPane analysisTabPane
        -JPanel sentimentTimeSeriesPanel
        -JPanel reliefCategoryPanel
        +AdvancedAnalysisPanel(Model model)
        +void loadAnalysisData()
    }

    class Model {
        -List~Post~ posts
        -List~Comment~ comments
        -DatabaseManager dbManager
        -SentimentAnalyzer sentimentAnalyzer
        -List~ModelListener~ listeners
        +Model()
        +void addPost(Post post)
        +void addComment(Comment comment)
        +void updateComment(Comment comment)
        +List~Post~ getAllPosts()
        +List~Comment~ getAllComments()
        +void addListener(ModelListener listener)
        -void notifyListeners()
    }

    class ModelListener {
        &lt;&lt;interface&gt;&gt;
        +void onPostAdded(Post post)
        +void onCommentAdded(Comment comment)
        +void onDataUpdated()
    }

    class CrawlingUtility {
        +static void addCommentsToPost(Post post, int commentLimit)
        +static DisasterType findDisasterTypeForPost(Post post, List~String~ keywords)
        +static List~String~ validateAndCleanUrls(String urlText)
    }

    DataCollectionPanel &quot;1&quot; *-- &quot;1&quot; CrawlControlPanel
    CommentManagementPanel &quot;1&quot; --&gt; &quot;1&quot; Model
    AnalysisPanel &quot;1&quot; --&gt; &quot;1&quot; Model
    AdvancedAnalysisPanel &quot;1&quot; --&gt; &quot;1&quot; Model
    View &quot;1&quot; *-- &quot;1&quot; AnalysisPanel
    View &quot;1&quot; *-- &quot;1&quot; CommentManagementPanel
    View &quot;1&quot; *-- &quot;1&quot; CrawlControlPanel
    View &quot;1&quot; *-- &quot;1&quot; DataCollectionPanel
    View &quot;1&quot; *-- &quot;1&quot; DataCollectionPanel
    Model &quot;1&quot; --&gt; &quot;*&quot; ModelListener
</div>
<p><strong>MVC Architecture Implementation</strong>: The MVC pattern in
this package follows classical separation of concerns where the Model
component manages application state and business data, the View
component displays information to the user through graphical components,
and the Controller component (implicitly embedded in event handlers)
responds to user interactions. The Model class maintains the
application‚Äôs state including lists of posts and comments, a reference
to the sentiment analyzer, and a collection of registered listeners.
When data changes, the Model notifies all observers without requiring
knowledge of their specific implementations.</p>
<p>The View class serves as the main JFrame container that orchestrates
all UI components and panels. Rather than cramming all interface logic
into a single large class, the interface is decomposed into specialized
panels, each handling a specific functional area:</p>
<ul>
<li><p><strong>DataCollectionPanel</strong>: Manages user interactions
for data collection, including crawler selection, keyword input, and
integration of disaster management controls. This panel acts as a
gateway for users to introduce new data into the system.</p></li>
<li><p><strong>AnalysisPanel</strong>: Presents Problem 1 analysis
results, including visualizations of relief item effectiveness and user
satisfaction metrics across different disaster categories.</p></li>
<li><p><strong>AdvancedAnalysisPanel</strong>: Implements Problem 2
analysis, providing temporal analysis of sentiment trends, time-series
visualizations, and category-based breakdown of relief effectiveness
over specified time periods.</p></li>
<li><p><strong>CommentManagementPanel</strong>: Displays a tabular view
of all collected comments with their associated metadata including
sentiment scores, relief categories, and disaster type
classifications.</p></li>
</ul>
<p><strong>Observer Pattern and Reactive Updates</strong>: The system
employs the Observer pattern through the ModelListener interface. When
the Model‚Äôs state changes (new posts added, comments updated, sentiment
analyzed), it automatically notifies all registered listeners without
them needing to poll for updates. This creates a reactive, event-driven
system where UI components automatically reflect the current state of
the data. Utility classes such as CrawlingUtility
provide reusable functionality for generating visualizations and
collecting data-related metadata.</p>
<p><strong>Design Benefits</strong>: The decomposition of the UI into
multiple panels provides several advantages over a monolithic approach.
Each panel typically contains 200-500 lines of code compared to
potentially 2000+ lines in a single class, making individual panels
easier to understand, test, and modify. The separation enables different
team members to work on different panels concurrently without causing
conflicts. The utility classes reduce code duplication by centralizing
common functionality like chart generation and crawling operations.</p>
<h4
id="sentiment-package---multiple-sentiment-analysis-strategies">6.3.3
Sentiment Package - Multiple Sentiment Analysis Strategies</h4>
<p>The Sentiment package provides a flexible framework for analyzing
sentiment in textual data. Rather than committing the entire system to a
single sentiment analysis approach, this package implements the Strategy
design pattern to support multiple analysis strategies with different
accuracy-to-performance tradeoffs.</p>
<div class="mermaid">
classDiagram
    class SentimentAnalyzer {
        &lt;&lt;interface&gt;&gt;
        +Sentiment analyzeSentiment(String text)
        +Sentiment analyzeSentiment(Comment comment)
    }

    class EnhancedSentimentAnalyzer {
        -Map~String, String~ emoticons
        +EnhancedSentimentAnalyzer()
        +Sentiment analyzeSentiment(String text)
        +Sentiment analyzeSentiment(Comment comment)
    }

    class PythonSentimentAnalyzer {
        -ProcessBuilder processBuilder
        -BufferedReader reader
        +PythonSentimentAnalyzer()
        +Sentiment analyzeSentiment(String text)
        +Sentiment analyzeSentiment(Comment comment)
        -Sentiment parseOutput(String jsonOutput)
    }

    class PythonCategoryClassifier {
        -ProcessBuilder processBuilder
        +PythonCategoryClassifier()
        +String classifyText(String text)
        +String classifyText(Comment comment)
        -String parseOutput(String jsonOutput)
    }

    SentimentAnalyzer <|.. EnhancedSentimentAnalyzer
    SentimentAnalyzer <|.. PythonSentimentAnalyzer
</div>
<p><strong>Strategy Pattern Implementation</strong>: The
SentimentAnalyzer interface defines a contract that all sentiment
analysis implementations must follow. This interface-based design
enables runtime selection of different analysis strategies without
requiring code modifications. The primary implementations include:</p>
<ul>
<li><p><strong>EnhancedSentimentAnalyzer</strong>: Implements keyword-based
sentiment analysis with emoticon detection and expanded keyword
dictionaries, providing a good balance between accuracy and
performance.</p></li>
<li><p><strong>PythonSentimentAnalyzer</strong>: Interfaces with a
machine learning model (xlm-roberta) running in a Python backend
service. This approach leverages deep learning for significantly higher
accuracy but incurs higher computational costs and requires the Python
service to be running.</p></li>
<li><p><strong>PythonCategoryClassifier</strong>: A specialized
classifier that categorizes text into relief categories (CASH, MEDICAL,
FOOD, SHELTER) using the BART natural language inference model,
providing semantic understanding beyond simple keyword
matching.</p></li>
</ul>
<p><strong>Runtime Flexibility</strong>: The beauty of the Strategy
pattern is evident in how the Model class can switch between analyzers
at runtime. The application uses EnhancedSentimentAnalyzer for
keyword-based processing, then seamlessly switches to
PythonSentimentAnalyzer for more accurate analysis once users request
higher precision. This can be accomplished with a single line of
code:</p>
<div class="sourceCode" id="cb17"><pre
class="sourceCode java"><code class="sourceCode java"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>model<span class="op">.</span><span class="fu">setSentimentAnalyzer</span><span class="op">(</span><span class="kw">new</span> <span class="fu">PythonSentimentAnalyzer</span><span class="op">());</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="co">// Switch analyzers at runtime</span></span></code></pre></div>
<p><strong>Extensibility and Maintainability</strong>: To add a new
sentiment analysis approach (such as Google Cloud Natural Language API
or OpenAI GPT-based analysis), developers only need to implement the
SentimentAnalyzer interface without modifying existing implementations.
This satisfies the Open/Closed Principle - the system is open for
extension but closed for modification. Each analyzer is self-contained
and can be tested independently using mock data or test cases.</p>
<h4
id="crawler-package---web-data-collection-with-factory-and-registry-patterns">6.3.4
Crawler Package - Web Data Collection with Factory and Registry
Patterns</h4>
<p>The Crawler package manages data collection from various sources
using a combination of the Factory and Registry design patterns. This
package exemplifies how to build pluggable, extensible architectures
that support adding new data sources without modifying existing
code.</p>
<div class="mermaid">
classDiagram
    class DataCrawler {
        &lt;&lt;interface&gt;&gt;
        +List~Post~ crawlPosts(List~String~ keywords, List~String~ hashtags, int limit)
        +boolean isInitialized()
    }

    class YouTubeCrawler {
        -YouTubeAPIHelper apiHelper
        -boolean initialized
        +YouTubeCrawler()
        +void initialize()
        +List~Post~ crawlPosts(List~String~ keywords, List~String~ hashtags, int limit)
        +boolean isInitialized()
        +void shutdown()
    }

    class MockDataCrawler {
        -Random random
        +MockDataCrawler()
        +List~Post~ crawlPosts(List~String~ keywords, List~String~ hashtags, int limit)
        +boolean isInitialized()
    }

    class CrawlerRegistry {
        -Map~String, Class~ crawlerMap
        +CrawlerRegistry()
        +void registerCrawler(String name, Class crawlerClass)
        +DataCrawler createCrawler(String name)
        +Set~String~ getAvailableCrawlers()
    }

    class CrawlerManager {
        -CrawlerRegistry registry
        -Map~String, DataCrawler~ activeCrawlers
        +CrawlerManager()
        +void initialize()
        +DataCrawler getCrawler(String name)
        +void shutdownAll()
    }

    class YouTubeAPIHelper {
        -String apiKey
        -YouTube youtubeService
        +YouTubeAPIHelper(String apiKey)
        +List~Video~ searchVideos(String query, int maxResults)
        +List~Comment~ getVideoComments(String videoId, int maxResults)
    }

    DataCrawler &lt;|.. YouTubeCrawler
    DataCrawler &lt;|.. MockDataCrawler
    CrawlerRegistry &quot;1&quot; --&gt; &quot;*&quot; DataCrawler
    CrawlerManager &quot;1&quot; *-- &quot;1&quot; CrawlerRegistry
    CrawlerManager &quot;1&quot; *-- &quot;1&quot; CrawlerRegistry
    YouTubeCrawler &quot;1&quot; --&gt; &quot;1&quot; YouTubeAPIHelper
</div>
<p><strong>Registry and Factory Pattern Design</strong>: The
CrawlerRegistry maintains a centralized registry of available crawler
implementations. Rather than the UI code needing to know about concrete
crawler classes like YouTubeCrawler or MockDataCrawler, it only needs to
know their string names (‚Äúyoutube‚Äù, ‚Äúmock‚Äù, etc.). The registry is
responsible for creating instances of crawlers using the Factory
pattern, encapsulating the creation logic and making the system easily
extensible.</p>
<p>The CrawlerManager class acts as a facade, managing the lifecycle of
crawlers including initialization, retrieval, and shutdown operations.
It encapsulates the CrawlerRegistry and provides a clean interface for
the application to access crawlers.</p>
<p><strong>Plugin Architecture Advantages</strong>: One of the most
powerful aspects of this design is that new crawlers can be added at
runtime through registration without requiring any modifications to the
UI code. For instance, to add Facebook data collection, a developer
would:</p>
<ol type="1">
<li>Create a FacebookCrawler class implementing the DataCrawler
interface</li>
<li>Register it in the CrawlerRegistry:
<code>registry.registerCrawler("facebook", FacebookCrawler::new)</code></li>
<li>The UI automatically shows ‚ÄúFacebook‚Äù as an available option in
dropdown menus</li>
</ol>
<p>The UI never needs to import or be aware of FacebookCrawler‚Äôs
existence. This is a powerful example of the Dependency Inversion
Principle - the UI depends on the DataCrawler interface, not on concrete
implementations.</p>
<p><strong>YouTube Integration</strong>: The YouTubeCrawler class
specifically handles YouTube data collection and delegates API
interaction details to the YouTubeAPIHelper. The helper class manages
authentication, video search, and comment retrieval using the YouTube
Data API v3. This separation of concerns ensures that API handling logic
remains isolated and can be updated independently of the crawling
logic.</p>
<p><strong>Loose Coupling and Testability</strong>: The DataCrawler
interface allows for easy substitution of implementations. During
testing, developers can register a MockDataCrawler that generates
synthetic data instead of making real API calls. This enables
comprehensive testing without external API dependencies and provides
faster test execution. The architecture supports multiple crawlers being
active simultaneously, allowing for parallel data collection from
different sources.</p>
<h4 id="analysis-package---modular-analysis-strategies">6.3.5 Analysis
Package - Modular Analysis Strategies</h4>
<p>The Analysis package contains the implementations of Problem 1 and
Problem 2 analysis modules, both following the Strategy design pattern
for flexible analysis execution.</p>
<div class="mermaid">
classDiagram
    class AnalysisModule {
        &lt;&lt;interface&gt;&gt;
        +void analyze(List~Post~ posts, List~Comment~ comments)
        +Map~String, Object~ getResults()
    }

    class SatisfactionAnalysisModule {
        -Map~String, Double~ satisfactionScores
        +SatisfactionAnalysisModule()
        +void analyze(List~Post~ posts, List~Comment~ comments)
        +Map~String, Object~ getResults()
        -double calculateSatisfactionScore(List~Comment~ comments)
    }

    class TimeSeriesSentimentModule {
        -Map~LocalDate, List~Sentiment~~ timeSeriesData
        +TimeSeriesSentimentModule()
        +void analyze(List~Post~ posts, List~Comment~ comments)
        +Map~String, Object~ getResults()
        -void buildTimeSeries(List~Comment~ comments)
    }

    AnalysisModule &lt;|.. SatisfactionAnalysisModule
    AnalysisModule &lt;|.. TimeSeriesSentimentModule
</div>
<p><strong>Analysis Module Interface and Implementations</strong>: Each
analysis module implements the AnalysisModule interface, which defines
two key methods: <code>analyze()</code> for processing post and comment
data, and <code>getResults()</code> for retrieving the computed results
in a flexible Map-based format.</p>
<p>The <strong>SatisfactionAnalysisModule</strong> addresses Problem 1
of the project, focusing on evaluating the effectiveness of different
relief item categories. This module:</p>
<ul>
<li>Groups all comments by their assigned relief category (CASH,
MEDICAL, FOOD, SHELTER)</li>
<li>Calculates the distribution of sentiment scores (positive, negative,
neutral) for each category</li>
<li>Computes effectiveness metrics based on the proportion of positive
sentiment within each category</li>
<li>Identifies which relief categories receive the highest satisfaction
ratings</li>
<li>Generates actionable recommendations for improving aid distribution
strategies</li>
</ul>
<p>The <strong>TimeSeriesSentimentModule</strong> addresses Problem 2,
providing temporal analysis of sentiment trends. This module:</p>
<ul>
<li>Bins comments into time buckets (typically 6-hour intervals) to
track sentiment evolution</li>
<li>Calculates sentiment distributions within each time bucket</li>
<li>Groups time-based sentiment data by relief category to show how
category effectiveness changes over time</li>
<li>Detects trends and patterns in user sentiment as the disaster
response progresses</li>
<li>Enables visualization of sentiment trajectories to inform real-time
decision-making</li>
</ul>
<p><strong>Strategy Pattern Benefits</strong>: The interface-based
design allows the Model class to manage multiple analysis modules and
invoke them dynamically:</p>
<div class="sourceCode" id="cb20"><pre
class="sourceCode java"><code class="sourceCode java"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>AnalysisModule module <span class="op">=</span> analysisModules<span class="op">.</span><span class="fu">get</span><span class="op">(</span><span class="st">&quot;satisfaction&quot;</span><span class="op">);</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="bu">Map</span><span class="op">&lt;</span><span class="bu">String</span><span class="op">,</span> <span class="bu">Object</span><span class="op">&gt;</span> results <span class="op">=</span> module<span class="op">.</span><span class="fu">analyze</span><span class="op">(</span>posts<span class="op">,</span> comments<span class="op">);</span></span></code></pre></div>
<p>New analysis modules (Geographic Analysis, Demographic Analysis,
Language Analysis) can be added without modifying existing modules or
the Model class. Each module focuses exclusively on its analysis
responsibility, making the code easier to understand, test, and
maintain.</p>
<h4 id="database-package---data-persistence-and-management">6.3.6
Database Package - Data Persistence and Management</h4>
<p>The Database package manages all aspects of data persistence,
providing both low-level SQL operations and high-level application
interfaces for data management.</p>
<div class="mermaid">
classDiagram
    class DatabaseManager {
        -static DatabaseManager instance
        -Connection connection
        -String dbPath
        +DatabaseManager(String dbPath)
        +static DatabaseManager getInstance()
        +void initializeDatabase()
        +void savePost(Post post)
        +void saveComment(Comment comment)
        +void updateComment(Comment comment)
        +List~Post~ loadAllPosts()
        +List~Comment~ loadCommentsByPostId(String postId)
    }

    class DatabaseLoader {
        +static List~Post~ loadPostsFromDatabase(String dbPath)
        +static List~Comment~ loadCommentsFromDatabase(String dbPath)
        +static void savePostsToDatabase(List~Post~ posts, String dbPath)
        +static void saveCommentsToDatabase(List~Comment~ comments, String dbPath)
    }

    class DataPersistenceManager {
        -DatabaseManager dbManager
        -List~Post~ posts
        -List~Comment~ comments
        +DataPersistenceManager(String dbPath)
        +void loadData()
        +void saveData()
        +void savePosts(List~Post~ posts)
        +void saveComments(List~Comment~ comments)
    }

    DatabaseManager &quot;1&quot; &lt;-- &quot;1&quot; DataPersistenceManager
    DatabaseLoader &quot;1&quot; --&gt; &quot;1&quot; DatabaseManager
</div>
<p><strong>Layered Database Access Architecture</strong>: The Database
package implements a layered architecture that separates concerns at
multiple levels. The DatabaseManager class provides low-level database
operations including CRUD operations on SQLite, connection management,
and schema initialization. It implements the Singleton pattern to ensure
a single database connection is maintained throughout the application‚Äôs
lifetime, preventing resource exhaustion and synchronization issues.</p>
<p>The DataPersistenceManager class acts as a facade, providing a
high-level application programming interface that abstracts away the
implementation details of the database. The application code interacts
with DataPersistenceManager rather than directly calling
DatabaseManager, allowing the underlying database technology to be
changed without affecting application code. For example, migrating from
SQLite to PostgreSQL would only require modifying the DatabaseManager
implementation while leaving DataPersistenceManager and all application
code unchanged.</p>
<p>The DatabaseLoader class provides utility methods for bulk loading
and saving data, enabling efficient batch operations that are more
performant than individual record operations. This is particularly
useful during application startup when loading large datasets or during
export operations.</p>
<p><strong>Resource Management and Error Handling</strong>: The
implementation uses try-with-resources statements to ensure proper
cleanup of database connections and streams, preventing resource leaks
and ensuring data integrity even in the presence of exceptions.
Connection pooling and prepared statements are employed to optimize
query execution and provide protection against SQL injection
attacks.</p>
<p><strong>Data Integrity and Consistency</strong>: The database schema
is carefully designed to maintain referential integrity between posts
and comments, ensuring that orphaned records cannot exist. Indexes are
strategically placed on frequently queried columns to ensure reasonable
query performance as the dataset grows. Transaction management ensures
that complex multi-step operations either complete entirely or fail
atomically without leaving the database in an inconsistent state.</p>
<h4 id="preprocessor-package---text-processing-and-classification">6.3.7
Preprocessor Package - Text Processing and Classification</h4>
<p>The Preprocessor package provides utilities for normalizing and
analyzing text content before it is subjected to sentiment analysis or
category classification.</p>
<div class="mermaid">
classDiagram
    class TextPreprocessor {
        &lt;&lt;interface&gt;&gt;
        +String preprocess(String text)
        +List~String~ tokenize(String text)
    }

    class BasicTextPreprocessor {
        +BasicTextPreprocessor()
        +String preprocess(String text)
    }

    TextPreprocessor &lt;|.. BasicTextPreprocessor
</div>
<p><strong>Text Normalization and Tokenization</strong>: The
TextPreprocessor interface defines a contract for text processing
operations. The BasicTextPreprocessor implementation handles the
essential text normalization tasks necessary before further analysis,
including:</p>
<ul>
<li><strong>Whitespace normalization</strong>: Removing extra spaces,
tabs, and newlines while preserving single spaces between words</li>
<li><strong>Case normalization</strong>: Converting all text to
lowercase for consistent analysis</li>
<li><strong>Stopword removal</strong>: Filtering out common words (the,
a, is, etc.) that contribute little semantic value to sentiment or
category analysis</li>
<li><strong>Vietnamese character handling</strong>: Properly preserving
and handling Vietnamese diacritical marks throughout the preprocessing
pipeline</li>
</ul>
<p>The tokenization functionality breaks text into individual words or
phrases, enabling more granular analysis capabilities for downstream
processors.</p>
<ul>
<li><strong>CASH</strong>: Keywords like ‚Äúmoney‚Äù, ‚Äúcash‚Äù, ‚Äúfinancial
aid‚Äù, ‚Äúmonetary assistance‚Äù</li>
<li><strong>MEDICAL</strong>: Keywords like ‚Äúhospital‚Äù, ‚Äúdoctor‚Äù,
‚Äúmedicine‚Äù, ‚Äúhealthcare‚Äù, ‚Äútreatment‚Äù</li>
<li><strong>FOOD</strong>: Keywords like ‚Äúfood‚Äù, ‚Äúrice‚Äù, ‚Äúsoup‚Äù, ‚Äúmeal‚Äù,
‚Äúnutrition‚Äù, ‚Äúeating‚Äù</li>
<li><strong>SHELTER</strong>: Keywords like ‚Äútent‚Äù, ‚Äúhouse‚Äù, ‚Äúshelter‚Äù,
‚Äúaccommodation‚Äù, ‚Äúroof‚Äù</li>
</ul>
<p>The classifier uses pattern matching and string similarity
calculations to identify category keywords even when embedded in longer
sentences. This approach enables the system to infer the type of relief
being discussed in comments without requiring explicit category
annotations.</p>
<p><strong>Design Benefits</strong>: The TextPreprocessor interface
allows for different preprocessing strategies to be employed based on
specific requirements. The BasicTextPreprocessor provides standard
preprocessing suitable for most use cases, while custom implementations
could be created for specialized processing needs (e.g., medical text
preprocessing, Vietnamese-specific preprocessing). The separation of
preprocessing concerns from sentiment analysis and classification
ensures that each component can be tested and modified
independently.</p>
<h4 id="main-application-and-utility-classes">6.3.8 Main Application and
Utility Classes</h4>
<p>The main application layer provides the entry point and various
utility functions supporting the broader system.</p>
<div class="mermaid">
classDiagram
    class HumanitarianLogisticsApp {
        -static View view
        -static Model model
        -static void main(String[] args)
        +static void launch()
    }

    class StringSimilarity {
        +static int levenshteinDistance(String s1, String s2)
        +static double levenshteinSimilarity(String s1, String s2)
        +static String findMostSimilar(String input, List~String~ candidates)
    }

    class VerifyDataGeneration {
        +static void main(String[] args)
        +static void verifyPostGeneration()
        +static void verifyCommentGeneration()
        +static void verifyDisasterTypeAssignment()
    }

    HumanitarianLogisticsApp &quot;1&quot; --&gt; &quot;1&quot; View
    HumanitarianLogisticsApp &quot;1&quot; --&gt; &quot;1&quot; Model
</div>
<p><strong>Application Initialization and Bootstrap</strong>: The
HumanitarianLogisticsApp class serves as the single entry point for the
entire application, containing the main() method that is executed when
the program starts. This class is responsible for orchestrating the
initialization sequence of all major system components in the correct
order:</p>
<ol type="1">
<li>Initialize the DisasterManager singleton with predefined disaster
types</li>
<li>Create the sentiment analyzer instance (configured as needed)</li>
<li>Instantiate the Model class with all necessary dependencies</li>
<li>Create the View (JFrame) with the initialized Model</li>
<li>Set the View as visible, allowing user interaction to begin</li>
</ol>
<p>By centralizing all initialization logic in one place, the
application code becomes easier to understand and modify. Developers can
quickly see which components are created, in what order, and what
dependencies are injected.</p>
<p><strong>Data Generation Verification</strong>: The
VerifyDataGeneration class provides utility methods for verifying that
the data generation and processing pipeline functions correctly. It
can:</p>
<ul>
<li>Verify that posts are generated with correct structure and valid
data</li>
<li>Verify that comments are properly attached to posts</li>
<li>Verify that disaster type assignments are correct and disaster types
exist</li>
<li>Verify that sentiment analysis produces valid results</li>
</ul>
<p>These verification utilities are invaluable during development and
testing, allowing developers to catch data pipeline issues early before
they affect downstream analysis modules.</p>
<p><strong>String Similarity Utilities</strong>: The StringSimilarity
utility class implements the Levenshtein distance algorithm, which
measures how similar two strings are by counting the minimum number of
single-character edits (insertions, deletions, substitutions) required
to transform one string into another. This utility is used for:</p>
<ul>
<li>Fuzzy matching of disaster type keywords against user input</li>
<li>Finding the most similar category when an exact match is not
available</li>
<li>Improving the robustness of the system when users provide
alternative spellings or abbreviations</li>
</ul>
<p>The Levenshtein distance function enables the system to gracefully
handle typos and variations in user input, providing a better user
experience.</p>
<h3 id="architectural-design-principles-and-rationale">6.4 Architectural
Design Principles and Rationale</h3>
<h4 id="model-package-independence---the-foundation-layer">6.4.1 Model
Package Independence - The Foundation Layer</h4>
<p>The Model package is deliberately designed to have zero dependencies
on any other package. This foundational independence is crucial for
several reasons:</p>
<p><strong>Clean Architecture</strong>: By keeping the Model package
independent, we ensure that entity classes represent pure data
containers without knowledge of how they will be displayed, persisted,
or analyzed. This adherence to clean architecture principles means that
the Model layer can be shared across multiple applications, used in
different UI frameworks, or even exposed through REST APIs without
carrying unnecessary dependencies.</p>
<p><strong>Testability</strong>: Entity classes can be easily
instantiated and tested in isolation without setting up complex
infrastructure. Unit tests can create mock objects and validate business
logic without database connections, UI frameworks, or external
services.</p>
<p><strong>Reusability</strong>: Organizations can extract the entire
Model package and reuse it in other projects that address different
problems but deal with similar data structures. The Post and Comment
classes could be used in social media analysis projects, disaster
response planning systems, or humanitarian crisis tracking
applications.</p>
<p><strong>Separation of Concerns</strong>: By keeping data models
separate from business logic, presentation logic, and persistence logic,
we maintain a clear architectural boundary that makes the codebase more
maintainable and easier for new team members to understand.</p>
<h4 id="ui-package-with-mvc-architecture---the-presentation-layer">6.4.2
UI Package with MVC Architecture - The Presentation Layer</h4>
<p>The UI package implements a strict MVC pattern where the Model (M)
component manages state, the View (V) component displays state, and the
Controller (C) component handles user interactions and invokes
operations on the Model.</p>
<p><strong>Panel Decomposition Strategy</strong>: Rather than creating a
single View class containing all UI components, we deliberately
decompose the interface into focused panels:</p>
<pre><code>Monolithic Approach:
View class (2000+ lines)
  - Crawling UI (500 lines)
  - Comment management (300 lines)
  - Problem 1 analysis (400 lines)
  - Problem 2 analysis (500 lines)
  - Disaster management (300 lines)
  Result: Difficult to maintain, test, and modify

Modular Approach:
View class (150 lines) - Main container and layout
‚îú‚îÄ CrawlControlPanel (200 lines) - Crawling specific logic
‚îú‚îÄ DataCollectionPanel (300 lines) - Data input management
‚îú‚îÄ AnalysisPanel (400 lines) - Problem 1 analysis
‚îú‚îÄ AdvancedAnalysisPanel (500 lines) - Problem 2 analysis
‚îî‚îÄ CommentManagementPanel (250 lines) - Comment viewing
Result: Easy to maintain, test, and modify</code></pre>
<p><strong>Observer Pattern Implementation</strong>: The system employs
the Observer design pattern through the ModelListener interface. Rather
than panels directly querying the Model for updates, they register as
listeners. When the Model‚Äôs state changes, it automatically notifies all
registered listeners. This creates loose coupling - panels need not know
about each other‚Äôs existence, only about the Model‚Äôs interface.</p>
<div class="sourceCode" id="cb25"><pre
class="sourceCode java"><code class="sourceCode java"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co">// Model notifies listeners when data changes</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="kw">private</span> <span class="dt">void</span> <span class="fu">notifyListeners</span><span class="op">()</span> <span class="op">{</span></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> <span class="op">(</span>ModelListener listener <span class="op">:</span> listeners<span class="op">)</span> <span class="op">{</span></span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>        listener<span class="op">.</span><span class="fu">onDataUpdated</span><span class="op">();</span></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>    <span class="op">}</span></span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a><span class="co">// View registers as listener</span></span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a>model<span class="op">.</span><span class="fu">addListener</span><span class="op">(()</span> <span class="op">-&gt;</span> <span class="fu">updateAllPanels</span><span class="op">());</span></span></code></pre></div>
<p>This approach ensures that all UI components remain synchronized with
the current application state without explicit coordination between
panels.</p>
<p><strong>Utility Class Organization</strong>: Reusable functionality
is extracted into utility classes:</p>
<ul>
<li><strong>CrawlingUtility</strong>: Data collection helper
methods</li>
<li><strong>InteractiveChartUtility</strong>: Interactive visualization
components</li>
</ul>
<p>By extracting these utilities, we follow the DRY (Don‚Äôt Repeat
Yourself) principle and enable code reuse across multiple UI panels.</p>
<h4
id="sentiment-package-with-strategy-pattern---flexible-analysis">6.4.3
Sentiment Package with Strategy Pattern - Flexible Analysis</h4>
<p>The Sentiment package demonstrates how the Strategy design pattern
enables runtime algorithm selection without code modification:</p>
<p><strong>Strategy Hierarchy</strong>:</p>
<pre><code>SentimentAnalyzer (interface)
‚îú‚îÄ EnhancedSentimentAnalyzer (keyword-based)
‚îî‚îÄ PythonSentimentAnalyzer (advanced, accurate)</code></pre>
<p><strong>Runtime Switching Capability</strong>: The brilliance of this
design is that the Model class never needs to know which specific
analyzer is being used. It works with the SentimentAnalyzer
interface:</p>
<div class="sourceCode" id="cb27"><pre
class="sourceCode java"><code class="sourceCode java"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="kw">private</span> SentimentAnalyzer sentimentAnalyzer<span class="op">;</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a><span class="kw">public</span> <span class="dt">void</span> <span class="fu">setSentimentAnalyzer</span><span class="op">(</span>SentimentAnalyzer analyzer<span class="op">)</span> <span class="op">{</span></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">this</span><span class="op">.</span><span class="fu">sentimentAnalyzer</span> <span class="op">=</span> analyzer<span class="op">;</span></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a><span class="kw">public</span> Sentiment <span class="fu">analyzeSentiment</span><span class="op">(</span><span class="bu">String</span> text<span class="op">)</span> <span class="op">{</span></span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> sentimentAnalyzer<span class="op">.</span><span class="fu">analyzeSentiment</span><span class="op">(</span>text<span class="op">);</span></span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span></code></pre></div>
<p>Because of this interface-based dependency, the Model code remains
unchanged whether we use EnhancedSentimentAnalyzer,
PythonSentimentAnalyzer, or a future GoogleCloudAnalyzer. This
exemplifies the Dependency Inversion Principle - the Model depends on an
abstraction (the interface) rather than concrete implementations.</p>
<p><strong>Extensibility Without Modification</strong>: Adding a new
sentiment analysis approach requires only implementing the
SentimentAnalyzer interface. The entire system automatically supports
the new approach without modification, satisfying the Open/Closed
Principle. Organizations could add new analyzers for different
languages, domains, or performance requirements without affecting
existing code.</p>
<h4
id="crawler-package-with-factory-and-registry-patterns---extensible-data-collection">6.4.4
Crawler Package with Factory and Registry Patterns - Extensible Data
Collection</h4>
<p>The Crawler package uses two complementary patterns to achieve
maximum extensibility:</p>
<p><strong>Registry Pattern - Discovery and Instantiation</strong>: The
CrawlerRegistry maintains a registry of available crawler
implementations and provides factory methods to create instances. This
approach decouples the UI from concrete crawler implementations:</p>
<div class="sourceCode" id="cb28"><pre
class="sourceCode java"><code class="sourceCode java"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co">// UI doesn&#39;t need to know about YouTubeCrawler</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>DataCrawler crawler <span class="op">=</span> registry<span class="op">.</span><span class="fu">createCrawler</span><span class="op">(</span><span class="st">&quot;youtube&quot;</span><span class="op">);</span></span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a><span class="bu">List</span><span class="op">&lt;</span>Post<span class="op">&gt;</span> posts <span class="op">=</span> crawler<span class="op">.</span><span class="fu">crawlPosts</span><span class="op">(</span>keywords<span class="op">,</span> hashtags<span class="op">,</span> limit<span class="op">);</span></span></code></pre></div>
<p><strong>Plugin Architecture Benefits</strong>: New data sources can
be added as ‚Äúplugins‚Äù without modifying existing code:</p>
<ol type="1">
<li>Create FacebookCrawler implementing DataCrawler interface</li>
<li>Register with CrawlerRegistry</li>
<li>UI automatically shows Facebook as available option</li>
</ol>
<p>This is a powerful example of the Open/Closed Principle - the system
is open for extension (new crawlers) but closed for modification (UI
code doesn‚Äôt change).</p>
<p><strong>Loose Coupling</strong>: By depending on the DataCrawler
interface rather than concrete implementations, the UI is completely
decoupled from crawler details. YouTubeCrawler could be completely
rewritten, new crawlers could be added, or crawlers could be removed
without affecting UI code.</p>
<h4 id="analysis-package-with-strategy-pattern---modular-analysis">6.4.5
Analysis Package with Strategy Pattern - Modular Analysis</h4>
<p>The Analysis package uses the Strategy pattern similarly to Sentiment
analysis, but applied to different types of data analysis:</p>
<p><strong>Analysis Module Registry</strong>:</p>
<div class="sourceCode" id="cb29"><pre
class="sourceCode java"><code class="sourceCode java"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="bu">Map</span><span class="op">&lt;</span><span class="bu">String</span><span class="op">,</span> AnalysisModule<span class="op">&gt;</span> modules <span class="op">=</span> <span class="kw">new</span> <span class="bu">LinkedHashMap</span><span class="op">&lt;&gt;();</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>modules<span class="op">.</span><span class="fu">put</span><span class="op">(</span><span class="st">&quot;satisfaction&quot;</span><span class="op">,</span> <span class="kw">new</span> <span class="fu">SatisfactionAnalysisModule</span><span class="op">());</span></span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>modules<span class="op">.</span><span class="fu">put</span><span class="op">(</span><span class="st">&quot;timeSeries&quot;</span><span class="op">,</span> <span class="kw">new</span> <span class="fu">TimeSeriesSentimentModule</span><span class="op">());</span></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a><span class="co">// Add new analysis without modifying existing code</span></span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>modules<span class="op">.</span><span class="fu">put</span><span class="op">(</span><span class="st">&quot;geographic&quot;</span><span class="op">,</span> <span class="kw">new</span> <span class="fu">GeographicAnalysisModule</span><span class="op">());</span></span></code></pre></div>
<p><strong>Independent Module Development</strong>: Each analysis module
focuses exclusively on its analysis responsibility, making it easier to
develop, test, and maintain. The SatisfactionAnalysisModule concerns
itself only with category-based satisfaction metrics, while
TimeSeriesSentimentModule focuses on temporal trends. Adding
GeographicAnalysisModule to analyze spatial distribution of sentiment
requires no changes to existing modules.</p>
<h4 id="database-package---abstraction-and-flexibility">6.4.6 Database
Package - Abstraction and Flexibility</h4>
<p>The Database package demonstrates how abstraction allows technology
changes without impacting application code:</p>
<p><strong>Layered Architecture</strong>:</p>
<pre><code>Application Code
    ‚Üì
DataPersistenceManager (Facade)
    ‚Üì
DatabaseManager (Concrete SQLite Implementation)
    ‚Üì
SQLite Database</code></pre>
<p>This layering means that migrating from SQLite to PostgreSQL,
MongoDB, or even cloud-based databases requires modifying only the
DatabaseManager class. Application code remains unchanged, ensuring that
application logic doesn‚Äôt need to be tested again.</p>
<p><strong>Try-with-Resources Pattern</strong>: The implementation uses
try-with-resources statements to ensure automatic resource cleanup:</p>
<div class="sourceCode" id="cb31"><pre
class="sourceCode java"><code class="sourceCode java"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="cf">try</span> <span class="op">(</span><span class="bu">ObjectOutputStream</span> oos <span class="op">=</span> <span class="kw">new</span> <span class="bu">ObjectOutputStream</span><span class="op">(</span><span class="kw">...</span><span class="op">))</span> <span class="op">{</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Write data</span></span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a><span class="op">}</span> <span class="co">// ObjectOutputStream automatically closed, even if exception occurs</span></span></code></pre></div>
<p>This pattern prevents resource leaks and ensures data integrity even
in error scenarios.</p>
<h3 id="solid-principles-applied-throughout-the-design">6.5 SOLID
Principles Applied Throughout the Design</h3>
<p>The system consistently applies the five SOLID principles to ensure
maintainability and extensibility:</p>
<table>
<colgroup>
<col style="width: 33%" />
<col style="width: 39%" />
<col style="width: 27%" />
</colgroup>
<thead>
<tr>
<th>Principle</th>
<th>Application</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>S</strong> - Single Responsibility</td>
<td>Each class has one reason to change</td>
<td>Post class only contains data; DatabaseManager only handles database
operations</td>
</tr>
<tr>
<td><strong>O</strong> - Open/Closed</td>
<td>Open for extension, closed for modification</td>
<td>Add new crawlers without modifying CrawlerRegistry; add new
analyzers without modifying Model</td>
</tr>
<tr>
<td><strong>L</strong> - Liskov Substitution</td>
<td>Subtypes can substitute their supertypes</td>
<td>Any SentimentAnalyzer implementation can replace any other; any
DataCrawler can replace any other</td>
</tr>
<tr>
<td><strong>I</strong> - Interface Segregation</td>
<td>Clients depend on specific interfaces</td>
<td>UI depends on SentimentAnalyzer interface; doesn‚Äôt depend on
unrelated methods in PythonSentimentAnalyzer</td>
</tr>
<tr>
<td><strong>D</strong> - Dependency Inversion</td>
<td>Depend on abstractions, not implementations</td>
<td>Model depends on SentimentAnalyzer interface; doesn‚Äôt depend on
EnhancedSentimentAnalyzer or PythonSentimentAnalyzer concrete classes</td>
</tr>
</tbody>
</table>
<h3 id="architectural-summary-and-benefits">6.6 Architectural Summary
and Benefits</h3>
<p>The Humanitarian Logistics Analysis System demonstrates a
professionally architected solution with clear separation of concerns
across seven well-defined packages. Each package focuses on a specific
responsibility while maintaining loose coupling with other packages. The
architecture leverages industry-standard design patterns (Strategy,
Factory, Registry, Observer, Singleton, MVC) to provide flexibility,
extensibility, and maintainability.</p>
<p><strong>Key Architectural Achievements</strong>:</p>
<ol type="1">
<li><strong>Modularity</strong>: Each package is independently
understandable and modifiable without affecting others</li>
<li><strong>Extensibility</strong>: New features can be added by
extending existing interfaces rather than modifying existing code</li>
<li><strong>Testability</strong>: Components can be tested in isolation
using mock objects and test doubles</li>
<li><strong>Reusability</strong>: Core components (Model package,
Sentiment strategies) can be reused in other projects</li>
<li><strong>Maintainability</strong>: Clear separation of concerns makes
the codebase easy to understand and modify</li>
<li><strong>Scalability</strong>: The architecture supports team
development with multiple developers working on different packages
simultaneously</li>
</ol>
<p>This design reflects mature software engineering practices suitable
for production systems serving critical humanitarian logistics
operations.</p>
<h2 id="oop-techniques">7. OOP Techniques and Design Patterns</h2>

<p>The Humanitarian Logistics Analysis System is built on solid object-oriented programming principles and industry-standard design patterns. This section provides in-depth analysis with actual code examples extracted directly from the codebase, demonstrating how each technique is applied to solve real problems in the application.</p>

<h3 id="fundamental-oop-concepts">7.1 Fundamental Object-Oriented Programming Concepts</h3>

<p>Seven core OOP concepts form the foundation of the system's architecture. Each is applied strategically throughout the codebase to achieve flexibility, maintainability, and extensibility.</p>

<h4 id="encapsulation">7.1.1 Encapsulation - Data Protection and Controlled Access</h4>

<p><strong>Purpose:</strong> Bundle data and methods together while hiding internal details and controlling access to state. This prevents invalid data states and unintended external modifications.</p>

<p><strong>Implementation in Post.java:</strong></p>

<pre><code>public abstract class Post implements Serializable, Comparable&lt;Post&gt; {
    private final String postId;
    private final String content;
    private final LocalDateTime createdAt;
    private final String author;
    private final String source;
    
    protected Post(String postId, String content, LocalDateTime createdAt,
                   String author, String source) {
        this.postId = Objects.requireNonNull(postId, "Post ID cannot be null");
        this.content = Objects.requireNonNull(content, "Content cannot be null");
        this.createdAt = Objects.requireNonNull(createdAt, "Created date cannot be null");
        this.author = Objects.requireNonNull(author, "Author cannot be null");
        this.source = Objects.requireNonNull(source, "Source cannot be null");
        this.comments = new ArrayList&lt;&gt;();
    }
    
    public String getPostId() { return postId; }
    public List&lt;Comment&gt; getComments() { 
        return Collections.unmodifiableList(comments); 
    }
    
    public void addComment(Comment comment) {
        if (comment != null) this.comments.add(comment);
    }
}</code></pre>

<p><strong>Key Techniques:</strong> Immutable fields (final), null safety via Objects.requireNonNull(), defensive copying, and controlled modification. <strong>Benefits:</strong> Data integrity, early error detection, and traceable changes.</p>

<h4 id="abstraction">7.1.2 Abstraction - Hiding Implementation Complexity</h4>

<p><strong>Purpose:</strong> Define WHAT operations an object performs without exposing HOW. This allows different implementations to be swapped without affecting client code.</p>

<pre><code>public interface SentimentAnalyzer {
    Sentiment analyzeSentiment(String text);
    Sentiment analyzeSentiment(Comment comment);
}

public class EnhancedSentimentAnalyzer implements SentimentAnalyzer {
    @Override
    public Sentiment analyzeSentiment(String text) {
        double score = 0;
        String[] words = text.toLowerCase().split("\\s+");
        for (String word : words) {
            if (englishKeywords.contains(word)) score += 1.0;
            if (vietnameseKeywords.contains(word)) score += 1.0;
        }
        String type = score > 0 ? "POSITIVE" : score < 0 ? "NEGATIVE" : "NEUTRAL";
        return new Sentiment(type, Math.min(Math.abs(score) / words.length, 1.0));
    }
}</code></pre>

<p><strong>Benefits:</strong> Easy testing, runtime selection, future extensibility, zero client coupling.</p>

<h4 id="inheritance">7.1.3 Inheritance - Code Reuse and Hierarchies</h4>

<p><strong>Purpose:</strong> Create class hierarchies where specialized subclasses inherit common behavior from parent classes, avoiding code duplication.</p>

<pre><code>public abstract class Post implements Serializable, Comparable&lt;Post&gt; {
    private final String postId;
    private final String content;
    private final LocalDateTime createdAt;
    private final String author;
    private final String source;
    private final List&lt;Comment&gt; comments;
    
    public void addComment(Comment comment) { ... }
    public List&lt;Comment&gt; getComments() { ... }
    public void setSentiment(Sentiment sentiment) { ... }
    
    @Override
    public int compareTo(Post other) {
        return this.createdAt.compareTo(other.createdAt);
    }
}

public class YouTubePost extends Post {
    private String videoId;
    
    public YouTubePost(String postId, String content, LocalDateTime createdAt,
                       String author, String videoId) {
        super(postId, content, createdAt, author, "YouTube");
        this.videoId = videoId;
    }
}</code></pre>

<p><strong>Benefits:</strong> Code reuse, consistency, extensibility, and polymorphism.</p>

<h4 id="polymorphism">7.1.4 Polymorphism - Runtime Behavior Selection</h4>

<pre><code>public class Model {
    private SentimentAnalyzer sentimentAnalyzer;
    
    public void switchAnalyzer(String analyzerType) {
        switch(analyzerType) {
            case "enhanced": sentimentAnalyzer = new EnhancedSentimentAnalyzer(); break;
            case "ml": sentimentAnalyzer = new PythonSentimentAnalyzer(); break;
        }
    }
    
    public void analyzeAllComments(List&lt;Post&gt; posts) {
        for (Post post : posts) {
            for (Comment comment : post.getComments()) {
                Sentiment sentiment = sentimentAnalyzer.analyzeSentiment(comment.getContent());
                comment.setSentiment(sentiment);
            }
        }
    }
}</code></pre>

<h4 id="interfaces">7.1.5 Interfaces - Contracts and Multiple Implementations</h4>

<pre><code>public interface SentimentAnalyzer { Sentiment analyzeSentiment(String text); }
public interface DataCrawler { List&lt;Post&gt; crawlPosts(List&lt;String&gt; keywords, List&lt;String&gt; hashtags, int limit); }
public interface AnalysisModule { void analyze(List&lt;Post&gt; posts, List&lt;Comment&gt; comments); }
public interface ModelListener { void modelChanged(); }</code></pre>

<p><strong>Benefits:</strong> Contracts, loose coupling, easy testing, runtime flexibility.</p>

<h4 id="abstract-classes">7.1.6 Abstract Classes - Partial Implementation</h4>

<p>Unlike interfaces, abstract classes provide actual implementation and shared state:</p>

<pre><code>public abstract class Post implements Serializable, Comparable&lt;Post&gt; {
    private final String postId;
    private final List&lt;Comment&gt; comments = new ArrayList&lt;&gt;();
    
    public List&lt;Comment&gt; getComments() { 
        return Collections.unmodifiableList(comments); 
    }
    
    public void addComment(Comment comment) {
        if (comment != null) this.comments.add(comment);
    }
}</code></pre>

<h4 id="composition">7.1.7 Composition - Has-A Relationships</h4>

<pre><code>public class Model {
    private SentimentAnalyzer sentimentAnalyzer = new EnhancedSentimentAnalyzer();
    private DatabaseManager dbManager = new DatabaseManager();
    private List&lt;Post&gt; posts = new ArrayList&lt;&gt;();
    private List&lt;ModelListener&gt; listeners = new ArrayList&lt;&gt;();
    
    public void setSentimentAnalyzer(SentimentAnalyzer analyzer) {
        this.sentimentAnalyzer = analyzer;
    }
}</code></pre>

<p><strong>Composition vs Inheritance:</strong> Use inheritance (IS-A) for hierarchies; use composition (HAS-A) for flexibility and runtime swapping.</p>

<h3 id="design-patterns">7.2 Advanced Design Patterns</h3>

<h4 id="mvc">7.2.1 Model-View-Controller (MVC) Architecture</h4>

<pre><code>public class Model {
    public void addPost(Post post) {
        Sentiment sentiment = sentimentAnalyzer.analyzeSentiment(post.getContent());
        post.setSentiment(sentiment);
        posts.add(post);
        notifyListeners();
    }
}

public class View extends JFrame implements ModelListener {
    public View(Model model) {
        this.model = model;
        model.addModelListener(this);
    }
    
    @Override
    public void modelChanged() {
        SwingUtilities.invokeLater(() -> {
            advancedAnalysisPanel.refresh();
            commentPanel.refreshCommentTable();
        });
    }
}</code></pre>

<p><strong>Benefits:</strong> Separation of concerns, testability, multiple views, loose coupling.</p>

<h4 id="strategy">7.2.2 Strategy Pattern - Runtime Algorithm Selection</h4>

<pre><code>public class Model {
    private SentimentAnalyzer strategy;
    
    public void analyzeComment(Comment comment) {
        Sentiment sentiment = strategy.analyzeSentiment(comment.getContent());
        comment.setSentiment(sentiment);
    }
}

// Add new strategy without changing existing code:
public class CustomSentimentAnalyzer implements SentimentAnalyzer {
    public Sentiment analyzeSentiment(String text) { ... }
}</code></pre>

<p><strong>Applications:</strong> Sentiment Analysis, Data Crawling, Analysis Modules.</p>

<h4 id="factory-registry">7.2.3 Factory and Registry Pattern - Pluggable Architecture</h4>

<pre><code>public class CrawlerRegistry {
    private static final CrawlerRegistry INSTANCE = new CrawlerRegistry();
    private final Map&lt;String, CrawlerFactory&gt; crawlers = new LinkedHashMap&lt;&gt;();
    
    @FunctionalInterface
    public interface CrawlerFactory {
        DataCrawler create();
    }
    
    public static CrawlerRegistry getInstance() { return INSTANCE; }
    
    public void registerCrawler(String name, CrawlerFactory factory) {
        crawlers.put(name, factory);
    }
    
    public DataCrawler createCrawler(String crawlerName) {
        return crawlers.get(crawlerName).create();
    }
}</code></pre>

<p><strong>Benefits:</strong> Plugin architecture, runtime discovery, decoupling, extensibility.</p>

<h4 id="observer">7.2.4 Observer Pattern - Reactive Updates</h4>

<pre><code>public interface ModelListener { void modelChanged(); }

public class Model {
    private List&lt;ModelListener&gt; listeners = new ArrayList&lt;&gt;();
    
    public void addModelListener(ModelListener listener) { listeners.add(listener); }
    
    private void notifyListeners() {
        for (ModelListener listener : listeners) {
            listener.modelChanged();
        }
    }
}

public class View extends JFrame implements ModelListener {
    @Override
    public void modelChanged() { statusLabel.setText("Updated"); }
}</code></pre>

<p><strong>Benefits:</strong> Loose coupling, dynamic registration, automatic synchronization, event-driven design.</p>

<h4 id="singleton">7.2.5 Singleton Pattern - Guaranteed Single Instance</h4>

<pre><code>public class CrawlerRegistry {
    private static final CrawlerRegistry INSTANCE = new CrawlerRegistry();
    private CrawlerRegistry() {}
    public static CrawlerRegistry getInstance() { return INSTANCE; }
}

public class DisasterManager {
    private static final DisasterManager INSTANCE = new DisasterManager();
    private DisasterManager() { disasterTypes = new HashMap&lt;&gt;(); }
    public static DisasterManager getInstance() { return INSTANCE; }
}</code></pre>

<p><strong>Benefits:</strong> Global access, single state, thread-safety.</p>

<h3 id="advanced-java">7.3 Advanced Java Techniques</h3>

<h4 id="generics">7.3.1 Generics and Type-Safe Collections</h4>

<pre><code>List&lt;Comment&gt; comments = new ArrayList&lt;&gt;();
comments.add(new Comment(...));
Comment c = comments.get(0);  // No casting needed

public class TimeSeriesSentimentModule implements AnalysisModule {
    private Map&lt;ReliefItem.Category, Map&lt;LocalDateTime, List&lt;Sentiment&gt;&gt;&gt; timeSeriesData;
}</code></pre>

<p><strong>Benefits:</strong> Compile-time error detection, no casting, self-documenting code.</p>

<h4 id="streams">7.3.2 Streams API and Functional Programming</h4>

<pre><code>List&lt;String&gt; authors = allComments.stream()
    .filter(c -> c.getSentiment().isPositive())
    .sorted((c1, c2) -> c2.getCreatedAt().compareTo(c1.getCreatedAt()))
    .map(Comment::getAuthor)
    .collect(Collectors.toList());

Map&lt;String, Map&lt;String, Long&gt;&gt; categoryAnalysis = comments.stream()
    .groupingBy(c -> c.getReliefItem().getCategory().toString(),
        groupingBy(c -> c.getSentiment().getType(), Collectors.counting()))</code></pre>

<h4 id="lambda">7.3.3 Lambda Expressions and Method References</h4>

<pre><code>comments.sort(Comparator.comparing(Comment::getCreatedAt));

List&lt;Comment&gt; positiveComments = comments.stream()
    .filter(c -> c.getSentiment().isPositive())
    .collect(Collectors.toList());

registerCrawler("youtube", () -> new YouTubeCrawler());</code></pre>

<h4 id="dependency-injection">7.3.4 Dependency Injection</h4>

<pre><code>public class CrawlControlPanel extends JPanel {
    public CrawlControlPanel(Model model, SentimentAnalyzer analyzer) {
        this.model = model;
        this.analyzer = analyzer;
    }
}

public class View extends JFrame {
    public View(Model model) {
        advancedAnalysisPanel = new AdvancedAnalysisPanel(model);
        commentPanel = new CommentManagementPanel(model);
        crawlPanel = new CrawlControlPanel(model);
    }
}</code></pre>

<p><strong>Benefits:</strong> Testability, flexibility, loose coupling.</p>

<h4 id="try-with-resources">7.3.5 Try-with-Resources for Automatic Resource Management</h4>

<pre><code>try (ObjectOutputStream oos = new ObjectOutputStream(new FileOutputStream("data.ser"))) {
    oos.writeObject(posts);
} catch (IOException e) { e.printStackTrace(); }

try (Connection conn = DriverManager.getConnection(dbUrl);
     Statement stmt = conn.createStatement();
     ResultSet rs = stmt.executeQuery("SELECT * FROM comments")) {
    while (rs.next()) { String content = rs.getString("content"); }
} catch (SQLException e) { e.printStackTrace(); }</code></pre>

<p><strong>Benefits:</strong> Automatic cleanup, exception safety, cleaner code.</p>

<h3 id="summary">7.4 Summary of OOP Application</h3>

<table>
<thead>
<tr><th><strong>Category</strong></th><th><strong>Techniques</strong></th><th><strong>Count</strong></th><th><strong>Status</strong></th></tr>
</thead>
<tbody>
<tr><td><strong>Fundamental Concepts</strong></td><td>Encapsulation, Abstraction, Inheritance, Polymorphism, Interfaces, Abstract Classes, Composition</td><td>7/7</td><td>‚úÖ Complete</td></tr>
<tr><td><strong>Design Patterns</strong></td><td>MVC, Strategy, Factory &amp; Registry, Observer, Singleton</td><td>5/5</td><td>‚úÖ Complete</td></tr>
<tr><td><strong>Advanced Techniques</strong></td><td>Generics, Streams API, Lambda Expressions, Dependency Injection, Try-with-Resources</td><td>5/5</td><td>‚úÖ Complete</td></tr>
<tr><td><strong>Code Quality</strong></td><td>30+ classes, 7 packages, 5000+ lines, Zero circular dependencies</td><td>-</td><td>‚úÖ Excellent</td></tr>
</tbody>
</table>

<p><strong>Architecture Strengths:</strong> Separation of concerns, extensibility, testability, maintainability, performance, type safety, and resource safety.</p>


<h2 id="technology-report">8. Technology Report</h2>

<p>Modern, multi-layered stack combining desktop Java with Python ML backend. Java provides type safety and GUI frameworks; Python dominates data science for NLP. System uses lightweight HTTP-based crawling rather than browser automation for efficiency.</p>

<h3 id="core-technologies">8.1 Core Technologies</h3>

<ul>
<li><strong>Java 11+</strong>: Type-safe, mature GUI framework (Swing), comprehensive standard library, Java HttpClient for HTTP operations</li>
<li><strong>Maven 3.9.11</strong>: Build automation, dependency management, JAR packaging with assembly for fat JARs</li>
<li><strong>Python 3.12.7</strong>: Backend ML service running as separate process, REST API communication via Flask</li>
<li><strong>Key Libraries</strong>: JFreeChart 1.5.3 (visualization), SQLite JDBC 3.44.0.0 (database), OkHttp3 4.11.0 (HTTP client), Gson 2.10.1 (JSON), org.json 20231013 (lightweight JSON), SLF4J 2.0.9 (logging), JUnit 4.13.2 (testing)</li>
</ul>

<h3 id="ui-and-visualization">8.2 UI and Visualization</h3>


<p><strong>JFreeChart 1.5.3</strong>: Professional charts including bar charts (category distributions), pie charts (satisfaction percentages), time-series charts (sentiment over time). Interactive features via mouse listeners enable drill-down analysis. Utility classes provide reusable chart generation without duplicated code.</p>

<h3 id="data-storage">8.3 Data Storage</h3>

<p><strong>SQLite 3.44.0.0</strong>: Embedded relational database, zero external server configuration, ACID-compliant transactions, lightweight footprint (~5MB). Two database instances: <code>humanitarian_logistics_user.db</code> (user-created posts and comments), <code>humanitarian_logistics_curated.db</code> (31 pre-curated posts for testing and demo).</p>

<p><strong>DatabaseManager</strong>: Encapsulates JDBC operations with prepared statements (prevents SQL injection), try-with-resources for automatic connection/statement closing. Schema includes tables: posts, comments, disaster_types, relief_items with foreign key relationships.</p>

<p><strong>DataPersistenceManager</strong>: Facade pattern abstracting database technology, enabling future migration to PostgreSQL/MySQL/Oracle without affecting application code. Current SQLite sufficient for 100s-1000s posts; horizontal scaling via table partitioning if needed.</p>

<h3 id="data-collection">8.4 Data Collection and HTTP</h3>

<p><strong>Java HttpClient</strong> (built-in java.net.http package since Java 11): Modern, non-blocking HTTP client with connection pooling, automatic request timeout management, retry logic via exception handling. YouTubeCrawler uses HttpClient to fetch YouTube watch pages via standard HTTP GET, parsing HTML response with regex patterns to extract comments and metadata.</p>

<p><strong>OkHttp3 4.11.0</strong>: Mature alternative HTTP client from Square (used in Android SDK). Provides connection pooling, protocol negotiation (HTTP/1.1, HTTP/2), request/response interceptors for logging. Available for future HTTP-based crawlers or enhanced connection management.</p>

<p><strong>YouTubeCrawler Implementation</strong>: Uses HttpClient to fetch YouTube watch pages, extracts video ID from URL, parses ytInitialData JSON embedded in HTML page, iterates comment sections. No browser automation (Selenium) - direct HTTP to YouTube endpoints via user-agent spoofing (User-Agent header: Chrome on Windows). Returns List&lt;YouTubePost&gt; objects with extracted metadata.</p>

<p><strong>MockDataCrawler</strong>: Generates synthetic posts for testing without internet access. Used in unit tests and demo mode to avoid API rate limits and network dependencies.</p>

<h3 id="json-processing">8.5 JSON Processing</h3>

<p><strong>Gson 2.10.1</strong> (Google JSON library): Sophisticated JSON serialization/deserialization for complex objects. Handles nested structures (Post ‚Üí Comments ‚Üí Sentiment). Supports custom serializers for LocalDateTime formatting. Used primarily for Python API responses from sentiment/category classifier.</p>

<p><strong>org.json 20231013</strong> (lightweight JSON): Minimal dependency for simple JSON parsing. Used for parsing embedded ytInitialData in YouTube HTML and building JSONObject requests to Python backend. No external dependencies beyond standard library.</p>

<p><strong>API Communication Format</strong>:</p>

<pre><code>// Request to Python sentiment service:
{
  "text": "Great help from relief workers!",
  "task_type": "sentiment"
}

// Response from Python:
{
  "sentiment": "POSITIVE",
  "confidence": 0.94,
  "category": "FOOD",
  "keywords": ["help", "relief"]
}</code></pre>

<h3 id="machine-learning-nlp">8.6 Machine Learning &amp; NLP</h3>

<p><strong>Backend Stack</strong>: Flask 2.3.0+ (lightweight Python web framework for REST API), Hugging Face Transformers 4.30.0+ (pre-trained NLP models), PyTorch 2.0.0+ (deep learning framework), NumPy (numerical computing), scikit-learn (traditional ML).</p>

<p><strong>Sentiment Analysis Model</strong>: xlm-roberta-large-xnli (Facebook Research, multilingual). Cross-lingual zero-shot classification (no fine-tuning required). Supports Vietnamese, English, French, Spanish, etc. Output classes: POSITIVE, NEGATIVE, NEUTRAL. Model size: 2GB, first download: 10-15 min, cached startup: ~30 sec, inference: 50-200ms per text.</p>

<p><strong>Relief Category Classification</strong>: facebook/bart-large-mnli (BART - denoising autoencoder for sequence-to-sequence tasks). Zero-shot classification into relief categories: CASH, MEDICAL, SHELTER, FOOD, TRANSPORTATION. Model size: 1.6GB. Batch processing endpoint handles 31 posts in 1-2 seconds.</p>

<p><strong>Python Service Architecture</strong>: sentiment_api.py runs Flask server on port 5001 with two endpoints: /sentiment (text ‚Üí sentiment type + confidence), /category (text ‚Üí relief category + keywords). Graceful fallback chain: Python ML ‚Üí EnhancedSentimentAnalyzer (Vietnamese keyword detection + emoticon matching).</p>

<h3 id="deployment-logging">8.7 Deployment &amp; Logging</h3>

<p><strong>SLF4J 2.0.9</strong> (Simple Logging Facade for Java): Abstraction layer enabling switching between logging implementations (Logback, Log4j, simple console). Configured with slf4j-simple binding for console output. Log levels: DEBUG (detailed info), INFO (key events), WARN (suspicious activity), ERROR (failures). All major operations logged: data loading, analysis execution, UI updates.</p>

<p><strong>Maven Build Process</strong>: <code>mvn clean package</code> creates target/humanitarian-logistics-jar-with-dependencies.jar (fat JAR including all dependencies). Includes Maven Shade Plugin for merging JARs and avoiding conflicts.</p>

<p><strong>Launch Command</strong>: <code>java -jar humanitarian-logistics/target/humanitarian-logistics-1.0-SNAPSHOT-jar-with-dependencies.jar</code> starts HumanitarianLogisticsApp.main(), which orchestrates: SQLite initialization, CrawlerRegistry population, Python API startup, Swing UI creation.</p>

<h3 id="performance">8.8 Performance Characteristics</h3>

<p><strong>First Run</strong>: 10-15 minutes (downloading 3.6GB of ML models from Hugging Face). Subsequent runs: 30 seconds startup (models cached in ~/.cache/huggingface/hub).</p>

<p><strong>Sentiment Analysis</strong>: 50-200ms per single text (depends on text length), 1-2 seconds for batch of 31 posts (parallel processing via Python). Database queries: &lt;100ms (SQLite with indexed postId, commentId). UI chart generation: &lt;500ms for 100 posts.</p>

<p><strong>Memory Usage</strong>: ~500MB steady state (Java heap 256MB + Python models 200MB + data structures 44MB). Scales linearly with post count for 100s-1000s posts. Beyond 10,000 posts, consider pagination or PostgreSQL.</p>

<p><strong>Network Usage</strong>: Initial YouTube crawl ~5-10 posts: 2-5MB (HTML downloads). Python API calls: ~5KB per request. No continuous polling; event-driven architecture via Observer pattern.</p>

<h3 id="scalability">8.9 Scalability and Future Evolution</h3>

<p><strong>Database Scaling</strong>: Replace SQLite with PostgreSQL/MySQL for concurrent multi-user access, ACID transactions, and backup/replication. No application code changes required (DataPersistenceManager abstraction).</p>

<p><strong>ML Scaling</strong>: Deploy Python backend with Gunicorn (multi-worker process server) or uWSGI for concurrent requests. Redis caching layer for sentiment results (avoid re-analyzing identical texts). Larger models (xlm-roberta-xxl) for higher accuracy if latency permits.</p>

<p><strong>Frontend Scaling</strong>: Current single-user desktop Swing app. Future: web frontend (React/Vue.js) consuming REST API from Java backend, enabling multi-user concurrent analysis without modifying core logic (MVC separation).</p>

<p><strong>Crawler Scaling</strong>: Current: YouTubeCrawler (YouTube watch pages). Future: FacebookCrawler, TwitterCrawler, RedditCrawler registered via CrawlerRegistry (Factory/Registry patterns enable adding without modifying existing code). Rate limiting via exponential backoff in HTTP retry logic.</p>

<h3 id="technology-stack">8.10 Technology Stack Summary</h3>

<table>
<thead>
<tr>
<th><strong>Category</strong></th>
<th><strong>Technology</strong></th>
<th><strong>Version</strong></th>
<th><strong>Purpose</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Languages</strong></td>
<td>Java / Python</td>
<td>11+ / 3.12.7</td>
<td>Desktop app / ML backend</td>
</tr>
<tr>
<td><strong>Build</strong></td>
<td>Maven</td>
<td>3.9.11</td>
<td>Compilation, packaging, dependency management</td>
</tr>
<tr>
<td><strong>Desktop UI</strong></td>
<td>Swing</td>
<td>Built-in</td>
<td>GUI with zero external dependencies</td>
</tr>
<tr>
<td><strong>Charting</strong></td>
<td>JFreeChart</td>
<td>1.5.3</td>
<td>Bar, pie, time-series charts with interactivity</td>
</tr>
<tr>
<td><strong>Database</strong></td>
<td>SQLite + JDBC</td>
<td>3.44.0.0</td>
<td>Embedded persistence, two DB instances</td>
</tr>
<tr>
<td><strong>HTTP Client</strong></td>
<td>Java HttpClient / OkHttp3</td>
<td>Built-in / 4.11.0</td>
<td>YouTube crawling, API calls</td>
</tr>
<tr>
<td><strong>JSON Processing</strong></td>
<td>Gson / org.json</td>
<td>2.10.1 / 20231013</td>
<td>Complex / lightweight serialization</td>
</tr>
<tr>
<td><strong>Web Framework</strong></td>
<td>Flask</td>
<td>2.3.0+</td>
<td>Python REST API for ML services</td>
</tr>
<tr>
<td><strong>NLP Models</strong></td>
<td>Transformers / PyTorch</td>
<td>4.30.0+ / 2.0.0+</td>
<td>Sentiment (xlm-roberta) / Category (BART) models</td>
</tr>
<tr>
<td><strong>Logging</strong></td>
<td>SLF4J + slf4j-simple</td>
<td>2.0.9</td>
<td>Abstraction layer with console output</td>
</tr>
<tr>
<td><strong>Testing</strong></td>
<td>JUnit</td>
<td>4.13.2</td>
<td>Unit test framework</td>
</tr>
</tbody>
</table>

<p><strong>Architecture Decisions</strong>: Lightweight HTTP-based data collection (no Selenium) for efficiency and reduced resource footprint. Microservices pattern: Java desktop app communicates with Python ML backend via REST (loose coupling, language independence). Abstraction layers (DataPersistenceManager, CrawlerRegistry) enable technology switching without breaking client code. Observer pattern ensures responsive UI without polling.</p>

<p><strong>Production Readiness</strong>: Mature, battle-tested libraries (Swing since 1996, Flask since 2010, SQLite since 2000). Try-with-resources ensures resource cleanup. Prepared statements prevent SQL injection. Error handling with graceful fallbacks (Python unavailable ‚Üí use Enhanced/Simple analyzers). Future evolution supported via abstraction patterns without major refactoring.</p>
</body>
</html>
